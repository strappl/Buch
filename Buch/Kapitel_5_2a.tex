%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Neue Politische Ökonomie}
\label{Neue_Politik}

Der Ökonomie-Zweig "`Politische Ökonomie"' ist nicht so einfach zu erfassen. Wie der Begriff selbst schon ausdrückt, handelt es sich hierbei um die Beschreibung gesamtwirtschaftlicher Zusammenhänge unter dem Einfluss von zentralen Entscheidungsträgern. Die meisten Klassiker (vgl. Kapitel \ref{Klassik}) interpretierten die Volkswirtschaftslehre in genau diesem Sinne und bezeichneten, oder beschrieben, ihre Werke als Arbeiten in "`Politischer Ökonomie"'. Paradebeispiele hierfür sind vor allem die Arbeiten von David Ricardo, John Stuart Mill, aber auch Karl Marx. Mit dem Aufstieg der Neoklassik seit 1870 wurde die Volkswirtschaftslehre immer stärker zu einer positiven Wissenschaft und ebenso zu einer Volkswirtschafts\textit{theorie}, in welcher der politische Einfluss weniger bedeutsam war. Damit einher ging die wachsende Marktgläubigkeit, also die Überzeugung, dass die allermeisten Märkte gut funktionieren und keinen staatlichen Eingriff benötigen. Damit verbunden waren niedrige Staatsquoten um die Jahrhundertwende. Die Staatsquote drückt aus, wie hoch der Anteil der Staatsausgaben am Bruttoinlandsprodukt ist. Damit ist die Staatsquote ein Maß dafür, an welchem Anteil der gesamten wirtschaftlichen Tätigkeiten die öffentliche Hand beteiligt ist. Um 1900 betrug dieser Wert für die damaligen Industriestaaten zwischen 10\% und 15\%. Den Einfluss des Staates zu vernachlässigen, war in der hohen Zeit der Neoklassik also eine nicht allzu unrealistische Vereinfachung. Vor der Corona-Krise\footnote{Während der Corona-Krise stiegen die Staatsquote stark an. Zum Einen, weil das BIP sank, vor allem aber aufgrund der teilweise sehr hohen Staatshilfen.} lag die Staatsquote in den westlichen Industriestaaten zwischen 40\% in den angelsächsischen Ländern und 50\% in den kontinental-europäischen Sozialstaaten. Der Anteil - aber auch der Einfluss - der öffentlichen Hand an der gesamten Wertschöpfung ist in den letzten hundert Jahren also enorm gestiegen. Dafür gibt es verschiedene Erklärungsansätze. \textcite{Wagner1892} bereits hatte eine fortlaufend steigende Staatsquote theoretisch postuliert. Mit wirtschaftlicher Entwicklung steige nämlich der Bedarf an den typischen Leistungen des Sozialstaates. Die Vorhersage Wagner's ist beeindruckend und bewahrheitete sich zwischen 1900 und 1975 für praktisch alle entwickelten Länder. Die Gründe hierfür waren allerdings nicht nur wachsende Sozialausgaben, sondern auch die beiden Weltkriege, in Folge deren der Staat wesentliche Aufgaben übernahm. Aus unserer wirtschafts-theoretischen Sicht allerdings, ist vor allem der Aufstieg des Keynesianismus (vgl. Kapitel \ref{Keynes}) von Interesse. Mit der Geburt der Makroökonomie durch die Veröffentlichung von \textcite{Keynes1936}  wurden der öffentlichen Hand nämlich auch wichtige wirtschaftspolitische Aufgaben in Form von aktiver Fiskal- und Geldpolitik zugeschrieben. In der folgenden hohen Zeit der Neoklassischen Synthese (vgl. Kapitel \ref{Synthese}) wurden aktive Staatseingriffe in die Gesamtwirtschaft sogar noch weiter forciert (vgl. Kapitel \ref{cha: Marktversagen}). Wer aber dieser Staat ist und ob seine Handlungen tatsächlich immer optimal für die Gesellschaft sind, wurde dabei nicht thematisiert. Interessanterweise hatte Keynes selbst Zeit seines Lebens eine recht bescheidene Meinung über Politiker \parencite[S. 519]{Snowdon2005}. Obwohl er mehr als die meisten anderen Ökonomen mit Politikern eng zusammenarbeitete und sein erstes berühmtes Werk (\textcite{Keynes1919}: "`The Economic Consequences of the Peace"') direkt auf das Versagen von Politikern verwies, postulierte er, dass durch staatliche Eingriffe die reinen Marktlösungen verbessert werden können, ohne daran zu denken, dass auch diese staatlichen Eingriffe letztendlich von Menschen durchgeführt werden müssen, die wiederum Interessen verfolgen könnten, die nicht der Allgemeinheit dienen, sondern ausschließlich ihnen selbst. Richtigerweise relativiert Alberto Alesina - einer der führenden Vertreter der Neuen Politischen Ökonomie - allerdings, dass niemand, auch nicht Keynes, bei einer revolutionären Ausarbeitung alle Eventualitäten bis zum Ende durchdenken könne \parencite[S. 569]{Snowdon2005}. Erst ab den 1970er Jahren, mit dem Auftreten von Stagflation und dem Wiedererstarken \textit{theoretischer}, liberaler Wirtschaftsschulen (vgl. Kapitel \ref{Monetarismus} und Kapitel \ref{Neue Makro}), kamen auch Fragen zur uneingeschränkten wirtschafts\textit{politischen} Sinnhaftigkeit staatlicher Eingriffe auf. 

Aber auch auf mikroökonomischer Ebene wurden Fragen zur Bedeutung des Staates immer wichtiger. Wie in Kapitel \ref{sec: Pigou} bereits dargestellt, wurde in den 1920er Jahren innerhalb der Neoklassischen Schule die Notwendigkeit von Staatseingriffen im Falle von Marktversagen erkannt und diskutiert. Daraus entwickelte sich die Disziplin der "`Wohlfahrtsökonomie"', bzw. nach dem Zweiten Weltkrieg die "`Neue Wohlfahrtsökonomie"', dargestellt in Kapitel \ref{Wohlfahrt}. Die Aussagen dieser Schule waren in der wissenschaftlichen Community stets recht umstritten, weil es sich dabei um weitgehend normative Theorien handelt. Wohlfahrtsökonomen rangen immer mit der Frage, ob Werturteile in der Ökonomie zulässig sind. Im Hinblick auf wirtschaftlichen Tätigkeiten des Staates sprachen im Zeitraum nach 1945 alle führenden Ökonomen recht unbestimmt und unspezifisch von staatlichen Eingriffen. Wie im Kapitel \ref{cha: Marktversagen} dargestellt, war es unter Ökonomen recht unumstritten, dass im Falle von Marktversagen und insbesondere beim Problem Öffentlicher Güter (vgl. Kapitel \ref{Offentliche Guter}) der Staat in den Markt eingreifen und als Anbieter auftreten sollte. Genau hier setzt die "`Neue Politische Ökonomie"' an, indem sie sich dieser Ansicht entschieden gegenüberstellt. In der der "`Theorie der öffentlichen Wirtschaft"' wird der Staat als allmächtiger und allwissender Übervater dargestellt, der stets das beste für die Gesamtheit seiner Bewohner will. In Modellen wird der Staat also stets als exogener Heilsbringer implementiert. Das stellt die "`Neue Politische Ökonomie"' vehement in Frage. Sie stellt in Aussicht, dass Marktversagen nicht immer durch die öffentliche Hand behoben werden kann, dass also auch "`Staatsversagen"' möglich ist.

Konkret untersucht sie "`Wer ist denn eigentlich der Staat?"' und "`Wie trifft dieser seine Entscheidungen?"' Schon anhand dieser beiden Fragen sieht man: \textit{Den Staat} als kollektives Entscheidungsorgan gibt es in demokratischen Gesellschaften nicht. Stattdessen gibt es viele Individuen, die über individuell-nutzenmaximierendes Verhalten ihre Volksvertreter wählen, die wiederum den Staat repräsentieren. Dieser Prozess von "`individuellen Werten"' zu "`politischen Entscheidungen"' kann nicht einfach durch die Annahme eines "`Staates"' übergangen werden \parencite[S. 11]{Buchanan1962}. Genau diesem Problem und den daraus resultierenden Fragen nahm sich die "`Neue Politische Ökonomie"' an. Es handelt sich hierbei um keine geschlossene ökonomische Denkrichtung, sondern um eine recht lose Sammlung verschiedener Ansätze. Die Neue Politische Ökonomie blickt sozusagen hinter die Kulissen der Staatseingriffe. Sie untersucht nicht, \textit{ob} Staatseingriffe in einer gewissen Situation zu befürworten sind, sondern, \textit{wie} deren Durchführung zustande kommt und erst in weiterer Folge, ob zu erwarten ist, dass durch den Eingriff schlussendlich tatsächlich das reine Marktergebnis verbessert wird.

Die Neue Politische Ökonomie behandelt damit auch ähnliche Fragen wie die Wohlfahrtstheorie (vgl. Kapitel \ref{Wohlfahrt}), steht aber gleichzeitig auch zu dieser im Spannungsverhältnis. Beide Schulen suchen nach Antworten darauf, wie der gesamtgesellschaftliche Nutzen maximal wird. Die Wohlfahrtstheorie ist dabei allerdings eher eine normative Theorie, gibt also vor wie die Dinge idealerweise sein \textit{sollen} damit maximale Wohlfahrt für die Gesellschaft entsteht. Die Wohlfahrtstheorie sucht nach einer "`gesamtwirtschaftlichen Nutzenfunktion"' ("`Social Welfare Function"'). Die Neue Politische Ökonomie sah sich, zumindest in ihren Anfängen, überwiegend als positive Theorie. Auch ihr geht es darum zu analysieren, wie in Gesellschaften nutzenmaximierende Entscheidungen getroffen werden. Allerdings ist die Neue Politische Ökonomie nüchterner was den Weg dorthin betrifft und geht davon aus, dass Wähler, Politiker und Institutionen primär ihren individuellen Nutzen maximieren, was zu gesamtgesellschaftlich nicht optimalen Ergebnissen führen kann. Sie zeichnet der sogenannte "`Methodische Individualismus"' aus, das heißt es gibt keine kollektiven Entscheidungen und keine gesamtwirtschaftliche Nutzenfunktion. Jede Entscheidung, auch die von großen Gruppen, ist im Endeffekt das Ergebnis aus einer Summe individuell-nutzenmaximierenden Einzelentscheidungen. Die Schule, die dieses Spannungsverhältnis zwischen Wohlfahrtsökonomie und Neuer Politischer Ökonomie konkret behandelt, ist die "`Social Choice Theorie"', die von \textcite{Arrow1950, Arrow1951} begründet wurde und bereits im Kapitel \ref{Wohlfahrt} behandelt wurde.

Als Vorläufer wird häufig Joseph Schumpeter genannt (\textcite[S. 519]{Snowdon2005}, \textcite[S. 95]{Warsh}), der bereits früh nach dem Erscheinen von Keynes' General Theory darauf hinwies, dass sich Politiker in Demokratien  um ihre Jobs immer wieder bei den Wählern bewerben müssen und dies ihre Handlungen - nicht immer zum Wohlergehen der Gesellschaft - beeinflusst \parencite{Schumpeter1942}. Bereits noch früher schlug der, seiner Zeit in vielen Belangen voraus gewesene, schwedische Ökonom Knut Wicksell (vgl. Kapitel \ref{Wicksell}) in eine ähnliche Kerbe. In seinen "`Finanztheoretischen Untersuchungen"' \parencite{Wicksell1896} bezeichnet er Wahlen als "`quid pro quo"'-Geschäft, also als Tauschgeschäft, in dem die Wähler von den Politikern etwas zurück bekommen wollen. Seine theoretischen Ansätze nannten \textcite[S. 8]{Buchanan1962} später als sehr inspirierendes Werk für ihre eigene bahnbrechende Arbeit.

Als moderne Begründer, bzw. verschiedene Zweige der Neuen Politischen Ökonomie werden daher heute verschiedene Ökonomen und deren Werke angeführt \parencite[S. 31]{Grofman2004} bzw. \parencite{Mitchell1988}:
\begin{itemize}
	\item \textcite{Arrow1951, Arrow1950}, der mit der Begründung der "`Social Choice Theory"' und dem darin postulierten "`Unmöglichkeitstheorem"' die grundlegenden Konzepte der damaligen Wohlfahrtstheorie, wie die Existenz einer "`Sozialen Wohlfahrtsfunktion"', widerlegte. Dieser Zweig wurde bereits in Kapitel \ref{Wohlfahrt} behandelt.
	\item \textcite{Black1948a, Black1958}, der neben Arrow als Begründer der "`Social Choice Theory"' gilt, aber erst durch dessen Arbeiten bekannt wurde. Er griff als erster Probleme beim Abstimmungsverhalten theoretisch und begründete das Medianwähler-Modell \parencite{Black1948a}.
	\item \textcite{Downs1957b, Downs1957}, der als erster demokratische Wahlen als Markt interpretierte, auf dem Politiker Wahlversprechen anbieten um die nachfragenden Wähler zu überzeugen. Diese Schule etablierte einen sehr umfangreichen Forschungszweig, der bis heute recht aktiv ist und sich damit beschäftigt, inwieweit Politiker an Regeln gebunden werden sollen \parencite[S. 523]{Snowdon2005}.
	\item \textcite{Buchanan1962} sind die vielleicht bekanntesten Vertreter der Neuen Politischen Ökonomie. Sie vertieften die Idee, dass Politiker an bestimmte Regeln gebunden werden sollen und etablierten damit die Ideen einer Wirtschaftsverfassung ("`constitutional economics"'). Gordon Tullock analysierte als erster das Problem des "`rent seekings"', also das Bestreben durch Lobbyismus selbst aufwandsloses Einkommen zu beziehen (Der Begriff selbst wurde durch \textcite{Krueger1974} geprägt).
	\item \textcite{Riker1962}, der politische Prozesses primär als spieltheoretische Anwendungsbeispiele verstand und einen beträchtlichen Beitrag zur Entwicklung des quantitativen Zweigs der Neuen Politischen Ökonomie leistete. Dieser Zweig verstand Politische Ökonomie zudem als streng positive Theorie.
	\item Das Ehepaar Ostrom erarbeitete gemeinsam mit Charles Tiebout Modelle, die zeigen, dass dezentralisierte Entscheidungen der öffentlichen Hand effizienter sein können, als zentrale Entscheidungen. Mit anderen Worten: Die öffentliche Hand sollte in nicht auf gesamtstaatlicher, sondern auf lokaler Ebene Entscheidungen treffen \parencite{Ostrom1961, Ostrom1971}.
\end{itemize}

Die Entwicklung der Neuen Politischen Ökonomie verlief nicht linear. Die genannten frühen Arbeiten von \textcite{Arrow1951}, \textcite{Black1948a} und \textcite{Downs1957} führten nicht unmittelbar zur Begründung der wissenschaftlichen Richtung. Also solche wurde sie eher ab Anfang der 1960er-Jahre wahrgenommen. Vor allem das Werk von \textcite{Buchanan1962} gilt als sehr einflussreich. Das liegt auch am Auftritt der Autoren James Buchanan und Gordon Tullock. Die beiden gelten als Begründer der "`Virginia School"' oder "`Public Choice Theory"'. Der zweitgenannte Begriff wird oft äquivalent mit dem Begriff "`Neue Politische Ökonomie"' verwendet. Ein Ansatz, dem hier nicht gefolgt wird. Als "`Public Choice Theory"' wird hier ausschließlich die Schule von Buchannan und Tullock bezeichnet. Beide waren extrem Markt-fundamental eingestellt, indem sie die Möglichkeit des "`Staatsversagens"' und des Scheiterns politischer Entscheidungsprozesse hervorhoben. Auch verließen beide bald den Weg die Neue Politische Ökonomie als positive Theorie zu betrachten \parencite[S. 105]{Mitchell1988}. Sie lehnten die Mainstream-Ökonomie vehement ab. Und zwar sowohl die makroökonomische dominierende "`Neoklassische Synthese"', wie auch die "`Neoklassik"', wobei sie hier vor allem die dort übliche mathematisch-quantitative Methodik ablehnten \parencite[S. 106]{Mitchell1988}. Vehement kritisierten sie die Ansätze der "`Wohlfahrtstheorie"' und der "`Theorie der Öffentlichen Wirtschaft"'. Letzteres mündete sogar in einer Streitschrift mit Richard Musgrave: \textcite{Musgrave1999}. Stattdessen näherte sich die "`Virginia School"' ideologisch und methodisch der "`Österreichischen Schule"' an. Dies führte allerdings dazu, dass ihre späteren Werke innerhalb der Mainstream-Ökonomie nicht akzeptiert wurden. Die Schüler von Buchanan und Tullock scheiterten weitgehend daran in der akademischen Welt Fuß zu fassen und wurden stattdessen in den 1980er-Jahren überproportional häufig zu Beratern und Mitarbeitern der wirtschaftsliberalen politischen Bewegung des späteren US-Präsidenten Ronald Reagan. Nichtsdestotrotz stellt ihr frühes Werk bis heute ein wichtiges Werk der "`Neuen Politischen Ökonomie"' dar, dass wichtige Fragen zum politischen Entscheidungsprozess  und zum "`Rent Seeking"' aufwirft und behandelt.

Ähnlich einflussreich, wenn auch weniger lautstark, war die fast parallel entstandene "`Rochester School"'. Deren früher Hauptvertreter William Riker behandelte die Neue Politische Ökonomie als streng positive Theorie. Er setzte sein Hauptwerk \parencite{Riker1962} auf den mathematisch-analytischen Arbeiten von \textcite{Black1948a} und \textcite{Arrow1951} auf. Tatsächlich erlangten die frühen Arbeiten von \textcite{Black1948a, Black1948b} erst durch Riker - und später noch verstärkt durch \textcite{Nordhaus1975} (siehe unten) - seinen heutigen Bekanntheitsgrad. Riker's vielleicht wichtigster Schritt war allerdings politische Prozesse als Anwendungsbeispiele der Spieltheorie zu sehen. Diese war Anfang der 1960er-Jahre im frühen Stadium seiner fortlaufenden Verbreitung. Mit ihrer mathematisch-quantitativen Ausrichtung der Neuen Politischen Ökonomie als positive Schule etablierte Riker eine formale und Mainstream-taugliche Schule der Politische Ökonomie.

Als extrem einflussreich erwies sich schließlich die Theorie der Politischen Konjunkturzyklen. Angestoßen wurde dieser Forschungszweig durch die Arbeit von \textcite{Nordhaus1975}. Aufbauend auf die Arbeiten von \textcite{Black1948a} und \textcite{Downs1957} argumentierte er, dass Politiker als individuell-nutzenmaximierende Individuen primär ihre Wiederwahl anstreben und daher ihre Tätigkeiten ausschließlich darauf ausrichten. \textcite{Hibbs1977} widersprach dem, da Nordhaus' Modell Politikern ja jegliche inhaltliche Überzeugung absprach und empirisch schwer haltbar schien. Stattdessen erstellte er ein "`ideologisches Modell"', wonach im Zwei-Parteien-System die Parteien jeweils ihre Präferenzen hinsichtlich makroökonomischer Variablen durchsetzen. Beide Modelle erhielten Mitte der 1970er für kurze Zeit sehr viel Zuspruch. Mit der Revolution in Folge der "`Lukas Kritik"' verschwanden die Modelle allerdings recht rasch wieder. Erst Ende der 1980er Jahre erlebte die Theorie der Politischen Konjunkturzyklen ein Revival. \textcite{Rogoff1986} und \textcite{Alesina1987} betteten die Modelle von Nordhaus bzw. Hibbs in die Theorie der rationalen Erwartungen ein. Vor allem Alberto Alesina wurde in den 1990er Jahren zu einer prägenden Figur der Neuen Politischen Ökonomie. Er brachte Geldpolitik - in der Form von Überlegungen zur Unabhängigkeit von Zentralbanken - und Fiskalpolitik - in der Form von Überlegungen zur Bedeutung von Staatsschulden - aus Sicht der politischen Ökonomie in das Zentrum der Forschung in diesem Bereich. Die Neue Politische Ökonomie behandelt - vor allem mit der Konzentration auf Geldpolitik - damit Themen, die auch in der Makroökonomie an zentraler Stelle stehen. Damit ist die Schule in diesem Bereich mitten in der Mainstream-Ökonomie angekommen.

Alesina erweiterte seine Analysen auch auf die Themen Einkommensverteilung \parencite{Hirschman1973} und politische Elemente des Wirtschaftswachstums, bevor er 2020 im Alter von 63 Jahren überraschend verstarb. Alle zuletzt genannten Bereiche zählen heute zu den aktivsten in der wirtschaftswissenschaftlichen Forschung. Allerdings spricht man in diesem Zusammenhang nicht mehr von "`Neuer Politischer Ökonomie"'. Aktuell findet man mit Dani Rodrik, Philippe Aghion, Kenneth Rogoff und Carmen Reinhart (u.a) eine ganze Liste von Ökonomen unter den meistzitierten Wirtschaftswissenschaftler, die allesamt in einem Bereich tätig sind, den man auch in der "`Neuen Politischen Ökonomie"' unterbringen könnte. Daneben entwickelte sich der "`Neue Institutionalismus"' (vgl. Kapitel \ref{sec: Neue Inst}) um Daron Acemoglu, den man auch innerhalb der Politischen Ökonomie ansiedeln könnte, auf jeden Fall aber mit diesem eng verbunden ist.

Betrachten wir nun die Entwicklungsschritte der Neuen Politischen Ökonomie im Detail.


\section{Black: Das Medianwähler-Modell}

Der Geburtsstunde der "`Public Choice Theory"' gelten heute weitgehend die frühen Arbeiten von Duncan \textcite{Black1948a, Black1948b} und Kenneth \textcite{Arrow1951}. Beide Arbeiten - vor allem jene von Arrow - sind uns schon aus Kapitel \ref{Wohlfahrt} bekannt. Gelten sie doch auch als Ausgangspunkt der "`Social Choice Theory"'. Dies ist insofern paradox als die späteren Vertreter der beiden Schulen "`Social Choice Theory"' und "`Neue Politische Ökonomie"' geradezu gegensätzliche ideologische Standpunkte vertraten.

Die Etablierung der Neuen Politischen Ökonomie verlief dabei alles andere als geradlinig. Die heute als bahnbrechend angesehenen Arbeiten von \textcite{Black1948a, Black1948b} blieben längere Zeit unentdeckt. Laut \textcite{Grofman2004} hatte Duncan Black auch Probleme seine Arbeiten in wissenschaftlichen Journalen zu platzieren. Wenn man diese frühen Arbeiten liest verwundert dies zunächst wenig. Black thematisiert die Problematiken, die im Rahmen von demokratischen Abstimmungen entstehen und verweist darauf, dass dies in ökonomischen Abhandlungen noch nicht thematisiert wurde. Er macht als eine Problem, das man wohl zunächst einmal in den Politikwissenschaften verorten würde zu einem ökonomischen Problem. Seine Zeitgenossen dürften den Zusammenhang zur Ökonomie zunächst unterschätzt haben \parencite[S. 33]{Grofman2004}. Ein weiterer amüsanter Aspekt ist, das bereits vor dem Zweiten Weltkrieg Harold \textcite{Hotelling1929} ganz ähnliche Fragen wie Duncan Black thematisiert hat und  schon im späten 18. Jahrhundert der Franzose Marie-Jean Marquis de Condorcet potentielle Probleme bei Abstimmungen identifiziert hatte, allerdings natürlich ohne den ökonomischen Zusammenhang zu thematisieren. Erst durch die Beiträge von Anthony Downs und William Riker, die in den nächsten Kapiteln behandelt werden, bekam auch Black die entsprechende Wertschätzung.
Als am bekanntesten gilt heute sein zusammenfassendes Werk \textcite{Black1958}: "`The Theory of Committees and Elections"'. Was waren die wesentlichen Erkenntnisse der Werke \textcite{Black1948a, Black1948b, Black1958}? Bereits in den früheren Werken entdeckt er das in Kapitel \ref{Wohlfahrt} angeführte Condorcet-Paradoxon (auch Paradox der zyklischen Mehrheiten) selbständig wieder, erweitert dies allerdings entscheidend um seine praktische Relevanz in politischen Entscheidungsprozessen. Erst später - und dann auch in seinem Werk \textcite{Black1958} entsprechend angeführt und aufgearbeitet - war ihm die Arbeit von \textcite{Condorcet1785} bekannt \parencite[S. 14]{Tullock1981}. Die Relevanz seiner Theorie wurde in weiterer Folge von ein großen Zahl von Ökonomen untersucht \parencite[S. 17f]{Tullock1981}.

Als noch wesentlich relevanterer Beitrag erwies sich allerdings das Medianwähler-Modell, das Black, unter der recht strikten Annahmen eingipfliger Präferenzen, in der gleichen Arbeit \parencite[S. 28ff]{Black1948a} ableitete. Dazu definiert \textcite[S. 26]{Black1948a} zunächst die "`Eingipfligkeit"'. Dazu muss jeder Wähler zu den verschiedenen Alternativen einer Abstimmung eine Rangordnung vornehmen, die seine Präferenz eindeutig anzeigt. Ein Beispiel verdeutlicht dies. Angenommen ein Wähler muss seine Präferenzen zur Bereitstellung eines öffentlichen Gutes durch den Staat angeben. Es gibt drei Alternativen. Ein Kommunist würde wohl folgende Rangordnung bevorzugen: 1. Viele öffentliche Güter, 2. durchschnittlich viele öffentlichen Güter, 3. keine öffentlichen Güter. Ein liberaler Bürger würde wahrscheinlich eine genau gegenteilige Rangordnung angeben. Und eine moderater Bürger würde vielleicht meinen, dass ihm durchschnittlich viele öffentliche Güter am liebsten sind, da er beide extreme ablehnt. Alle drei genannten Bürger haben eine eindeutige Präferenz der Rangordnung. Man spricht eben von eingipfligen Präferenzen. Ein vierter Bürger, der die "`Extreme liebt"' und am liebsten Viele öffentliche Güter bereitgestellt bekommt und am zweitliebsten gar keine öffentlichen Güter und erst an dritter Stelle seiner persönlichen Rangordnung  durchschnittlich viele öffentlichen Güter angibt, hat hingegen zweigipfelige Präferenzen. Da in der Realität die Anzahl der Alternativen nicht auf drei beschränkt ist, sprich man in diesem Fall von mehrgipfeligen Präferenzen. Der entscheidende Punkt ist nun, dass \textcite[S. 27]{Black1948a} mathematisch zeigen kann, dass - unter der Voraussetzung, dass alle Bürger eingipfelige Präferenzen aufweisen - demokratische Wahlen in größeren Gesellschaften (das heißt ohne größere Absprachemöglichkeiten) stets dazu führen, dass als demokratisches Ergebnis die "`mittlere"' Alternative gewählt wird. Die mittlere Alternative ist jene, bei der 50\% der Wähler eine "`Idealalternative"' haben, bei der - wenn man im oben angeführten Beispiel bleibt -  mehr öffentliche Güter bereitgestellt würden und umgekehrt. Dieses formale Ergebnis hatte - mit etwas zeitlicher Verzögerung - enorme Auswirkung auf die ökonomische Forschung. Die zentrale Voraussetzung, nämlich dass Individuen eingipflige Präferenzen haben, erscheint intuitiv als recht verständlich. Ab den späten 1960er-Jahren gab es viele Forschungsarbeiten dazu, ob die Voraussetzungen des Medianwähler-Modells in demokratischen Prozessen erfüllt sind \parencite[S. 21ff]{Tullock1981}. Obwohl die Ergebnisse dazu nicht eindeutig sind, ist das Modell bis heute Standard in vielen Ökonomie-Lehrbüchern. Die Implikation des Medianwähler-Modells ist, dass sich in einem Zwei-Parteien-System beide um den Medianwähler in der Mitte bemühen und ideologische Unterschiede zwischen den beiden Wahl-werbenden Gruppen daher zunehmend verschwimmen. Eine Annahme, die bis heute umstritten ist und die in Unterkapitel \ref{Der Politische Wirtschaftszyklus} zentral für die Gültigkeit eines der dort vorgestellten Modelle ist.

An dieser Stelle ist außerdem noch ein Hinweis zu Zwei-Parteien- und Mehr-Parteien-Systemen angebracht. Heute verbindet man erstere vor allem mit dem Angel-sächsischem Raum, wo es ja, aufgrund des Mehrheitswahlrechts, im wesentlichen tatsächlich nur zwei große Parteien gibt. In Kontinentaleuropa hingegen gibt es seit jeher Verhältniswahlrecht und dementsprechend auch wesentlich mehr Parteien. In den 1950er-Jahren, als die Arbeiten von \textcite{Black1948a, Black1958} zunehmend bekannt wurden, gab es aber auch in Kontinentaleuropa in den meisten Staaten nur zwei bedeutende politische Großparteien. Die häufig als "`das dritte Lager"' bezeichnete Parteien, sowie Öko-Parteien, kamen erst ab den 1980er Jahren zu bedeutenden Stimmenanteilen.


\section{Downs: Wahlergebnisse als Marktergebnisse}

Die Arbeiten von Duncan Black blieben zunächst recht unbekannt. Die ökonomische Schule der "`Neuen Politischen Ökonomie"' bekam Ende der 1950er so richtig Auftrieb. Anthony \textcite{Downs1957b, Downs1957} mit seinen einflussreichen Werken zur ökonomischen Theorie politischer Handlungen in Demokratien, kritisierte, dass Staatseingriffe in der ökonomischen Theorie stets als exogene Variable herangezogen werden, ohne zu Bedenken, dass Staatseingriffe von nutzenmaximierenden Personen vollzogen werden müssen \parencite[S. 135]{Downs1957}. Er lieferte in der Folge ein Modell, dass staatliche Handlungen endogenisierte, indem er individuell-nutzenmaximierende Politiker als Umsetzer der Staatseingriffe berücksichtigte. \textcite[S. 137]{Downs1957} stellt dazu die Hypothese auf, dass Politiker ihre Tätigkeit einzig und alleine darauf ausrichten, maximal viele Stimmen zu erhalten. Politikern geht es weder um Parteiprogramme, noch um Interessenvertretungen, sie bedienen sich derselben nur um ihr einziges Ziel die (Wieder-)Wahl zu erreichen. Die Durchführung politischer Handlungen ist dabei nur ein Nebenprodukt ihrer privaten Nutzenmaximierung: Hohes Einkommen, Prestige und Macht. Das hört sich zunächst recht negativ an. Doch es ist in Wirklichkeit nichts anderes als politisches Verhalten als ökonomisch-marktwirtschaftliches Verhalten zu interpretieren. Ein Politiker handelt eben nicht anders wie alle anderen Menschen auch. So schürft ein Arbeiter in einer Kohle-Mine ja auch nicht deswegen nach Kohle, um die Gesellschaft mit Energie zu versorgen, sondern um damit Geld zu verdienen \parencite[S. 137]{Downs1957}. Das entsprechende Vorgehen von Politiker ist daher \textit{nicht grundsätzlich} verwerflich, ganz im Gegenteil es widerspricht nicht dem gesamtwirtschaftlichen Ziel die "`Soziale Wohlfahrt"' zu maximieren. In einer Welt mit perfekter Information werden die Wähler jene Partei wählen, die ihnen den höchsten persönlichen Nutzen in der zukünftigen Wahlperiode liefert. Dieser erwartete Nutzen wird aus den bisherigen Handlungen der Politiker - sowohl jener, die regieren, als auch jener, die in Opposition sind - abgeleitet. Aufgrund der perfekten Information der Wähler scheint unredliches (verwerfliches) Verhalten der Politiker nicht sinnvoll, weil dadurch Wählerstimmen verloren gehen. Erst durch die realistischere Annahme unvollständiger Information beider Seiten - die Wähler wissen nicht vollständig, welche Handlungen welche politische Partei liefern wird, aber auch die politischen Parteien wissen nicht vollständig, welche Handlungen die Wähler sehen wollen - bringt kostenintensiver Wahlkampf für Politiker zusätzliche Stimmen. Außerdem bringt Lobbyismus bei unvollständiger Information bestimmten Wählergruppen Einfluss auf die Handlungen von Bewerbern um politische Positionen. Damit verbunden ist auch die Möglichkeit, dass Bestechung und anderes unredliches Verhalten zu rationalem Verhalten wird. Unvollständige Information bei politischen Entscheidungen ist also \textit{der} Hauptfaktor im Rahmen von politischen Entscheidungsprozessen. Daraus leitet \textcite[S. 141]{Downs1957} ab, dass politische Parteien bestimmte Ideologien verfolgen. Diese können als eine Art "`Signaling"' (vgl. Kapitel \ref{Info}) verstanden werden: Dem Wähler wird rasch gezeigt, welche Motive die Partei verfolgt, ohne dass sich der Wähler kostenintensiv diese Information besorgen muss.

In weiterer Folge greift \textcite[S. 142]{Downs1957} das Medianwähler-Modell auf, das im vorherigen Kapitel dargestellt wurde. Es ist sogar so, dass dieses Modell erst durch die Arbeiten von \textcite{Downs1957, Downs1957b} den großen Bekanntheitsgrad erfuhr, den es bis heute unter Ökonomen genießt. Interessanterweise wurden später vor allem die Ausführungen von \textcite{Black1948a, Black1948b} bekannt, während sich Downs selbst auf das ältere Werk von \textcite{Hotelling1929} bezog. Allerdings führt \textcite[S. 142]{Downs1957} zusätzliche Annahmen ein, die dazu führen, dass sich in einem Zwei-Parteien-System im Medianwähler-Modell die beiden Parteien nicht notwendigerweise im Zentrum aneinander annähern müssen um eben den Medianwähler und damit die Mehrheit von sich zu überzeugen. Dies ist dann der Fall, wenn die Verteilung der Wähler im Spektrum von "`links-radikal"' - also überzeugte Kommunisten -  bis "`rechts-radikal"' - also Befürworter eines Nachtwächter-Staates - nicht eingipfelig, wie bei etwa bei einer Normalverteilung verläuft, sondern zwei- oder mehrgipfelig. Zum Beispiel könnte es in einer gespaltenen, radikalisierten Gesellschaft die meisten Wähler jeweils an den Rändern geben. In solchen Situationen besinnen sich die Parteien ihrer Ideologie und werden nicht zu "`Parteien der Mitte"'. Dies war ein wichtiger, wenn auch letztlich bis heute umstrittener, Ansatz. Schließlich lässt sich die in der Folge in den 1970er Jahren entstandene Forschung zum Politischen Wirtschaftszyklus einteilen in einen Zweig, der "`Opportunistisches Verhalten"' der Parteien unterstellt und damit eine Annäherung der großen Parteien an die Mitte wie im Medianwähler-Modell, und einem zweiten Zweig, der von "`Ideologischen Parteien"' ausgeht. Diese Modelle werden weiter unten in diesem Kapitel (vgl. Unterkapitel \ref{Der Politische Wirtschaftszyklus}) vorgestellt. Zuvor betrachten wir - der chronologischen Entwicklung folgend - die Arbeiten der "`Public-Choice"'-Vertreter im engeren Sinn. 

\section{Buchanan: Die Public-Choice Theorie}
\label{Pol_Econ}

Eine neue Richtung verliehen der Theorie der Neuen Politischen Ökonomie in den 1960er Jahren James McGill Buchanan und Gordon Tullock. Vor allem dem stark polarisierenden Buchanan wird heute die Rolle zugeschrieben der Begründer Der "`Public Choice Theory"' im engeren Sinn zu sein. Er drückte ihr den Stempel auf, eine extrem wirtschaftsliberale ökonomische Schule zu sein. Und das, obwohl er akzeptierte, dass Märkte in vielen Fällen versagen können. Noch stärker war allerdings seine Überzeugung, dass "`der Staat"' in diesen Fällen keine bessere Lösung anbieten kann als die versagenden Märkte. Er war die längste Zeit seiner akademischen Karriere an Universitäten in Virginia tätig und gründete dort das "`Center for the Study of Public Choice"'. Fast zeitgleich begründete Gordon Tullock das wissenschaftliche Journal "`Papers in Non-Market Decision-Making"', das bald in "`Public Choice"' unbenannt wurde \parencite[S. 101]{Mitchell1988} und unter diesem Namen bis heute veröffentlicht wird. Obwohl Buchanan nie wirklich dem ökonomischen Mainstream zuzurechnen war, was er auch selbst stets betonte \parencite[S. 96]{Warsh}, hatten seine Ideen einen prägenden Einfluss auf die Wirtschaftswissenschaften und die Wirtschaftspolitik. 

Die bisher genannten Arbeiten von \textcite{Black1948a} und \textcite{Downs1957} waren interessante Weiterentwicklungen der Wirtschaftswissenschaften, weil sie Probleme der Politikwissenschaften mit ökonomischen Methoden behandelten und so politische Prozesse in die Ökonomie eingliederten. Allerdings standen ihre Arbeiten weitgehend neben der traditionellen Mikro- und Makroökonomie, ohne viel Überschneidungspunkte aufzuzeigen. Dies änderte sich durch die Arbeit von \textcite{Buchanan1962}. Diese behandelte Abstimmungsprozesse nicht alleinstehend, sondern erkannte, dass erst die rollierende Abfolge von Abstimmungsprozessen zu interessanteren ökonomischen Ergebnissen führt. Dabei spielen die damals jungen Erkenntnisse der Spieltheorie (vgl. Kapitel \ref{Spieltheorie}) eine große Rolle. Vor allem der "`Staatsbegriff"' der damaligen Mainstream-Ökonomie wurden dadurch in Frage gestellt.

Durch die Keynesianische Revolution spielte aktive Wirtschaftspolitik in den 1950er und 1960er-Jahren eine große Bedeutung in der Makroökonomie (vgl. Kapitel \ref{Synthese}). In der Mikroökonomie war dies ähnlich: Die Wohlfahrtsökonomie (vgl. Kapitel \ref{Wohlfahrt}) und die Theorien der Public Economy (vgl. Kapitel \ref{cha: Marktversagen}) waren viel beforschte Themenbereiche. In beiden Fällen übernahm der Staat die Position eines wohlwollenden, gütigen Despoten. Dabei blieb stets die Frage unbehandelt, ob denn der Staat, beziehungsweise dessen Repräsentanten, überhaupt besser als der Markt ungewollten Entwicklungen, erstens, gegensteuern \textit{kann}, und zweitens, \textit{will}. In dieser Zeit, in der wenige Ökonomen daran zweifelten, dass staatlich Eingriffe der wirtschaftlichen Entwicklung schaden könnten, griff \textcite{Buchanan1962} genau dieses Thema auf. Die beiden Autoren erhoben laute und uneingeschränkte Zweifel daran, dass Staatseingriffe die Rettung bei ökonomischen Missständen seien. Dem Begriff des Marktversagen stellten sie den Begriff des Staatsversagens gegenüber. Die zentrale Ausgangsthese lautete dabei, dass sich der Staat ja nichts anderes sei als die Summe seiner Einwohner. Und seine Repräsentanten und Bürokraten streben auch nach nichts anderem als individueller Nutzenmaximierung. Sehr eingängig verdeutlichte dies ein Schüler Buchanan's: "`Angenommen ein Finanzexperte wechselt von der Wallstreet ins Finanzministerium. Die Mainstream-Ökonomie geht davon aus, dass diese Person schlagartig vom Saulus zum heiligen Paulus wird, also seine bisher ausgelebte individuelle Nutzenmaximierung aufgibt und fortan selbstlos als Staatsdiener arbeitet."' \parencite[S. 96]{Warsh}. In den normativen Schulen der Public Economy (vgl. Kapitel \ref{cha: Marktversagen}) und der Wohlfahrtstheorie (vgl. Kapitel \ref{Wohlfahrt}) gingen die Ökonomen davon aus, dass sie wussten was am besten für eine Gesellschaft wäre und dass Entscheidungsträger dieses Wissen nutzen würden um die ökonomischen Gegebenheiten in einem Staat zu verbessern \parencite[S. 167]{Romer1988}. Dem stellte die positive Theorie der Neuen Politischen Ökonomie entgegen, dass es ausschließlich \textit{individuell}-nutzenmaximierende Personen gäbe und sich aus der Summe ihrer Entscheidungen im Rahmen von demokratischen Spielregeln die ökonomischen Gegebenheiten in einem Staat ergeben. Wie bereits erwähnt akzeptieren \textcite{Buchanan1962}, dass manche Produkte und Dienstleistungen auf rein privaten Märkten nicht angeboten werden. Die Entscheidung in welchem Umfang diese öffentlichen Güter und Dienstleistungen jetzt angeboten werden, wird aber nicht dem "`Staat"' als exogenen Entscheidungsträger überlassen, stattdessen gibt es individuell nutzenmaximierende Individuen, die ihre demokratischen Stimmrechte einsetzen um Regeln festzulegen, wie die öffentlichen Güter und Dienstleistungen angeboten werden. Dem exogenen Staat weicht also ein privatwirtschaftlicher Markt für politische Abstimmungen. Die Public Choice Theory folgt also einem radikalen Subjektivismus, der unterstellt, dass nur Individuen selbst wissen können, was am besten für sie ist. Dieses Wissen setzen sie in politischen Abstimmungsprozessen ein. 
\textcite{Buchanan1962} suchen daher nach einem demokratischen Prozess für die optimale Entscheidungsfindung in diesen politischen Abstimmungsprozessen. Sie wägen dabei zwei Kosten ab. Erstens, die Kosten, die Individuen erleiden, weil im politischen Abstimmungsprozess ihre Präferenzen überstimmt werden. Und zweitens, die Kosten der Entscheidungsfindung. Dabei kommt es zu folgendem Trade-Off: Verlangen die politischen Abstimmungsprozesse Einstimmigkeit, so kommt es zwar als Folge der einzelnen Abstimmungen zu keinerlei externen Kosten, weil ja jeder Abstimmungsberechtigte zugestimmt hat, allerdings sind die Kosten der Entscheidungsfindung enorm, weil ja jeder einzelne überzeugt werden muss. Wenn umgekehrt ein Diktator alleinig entscheiden kann, kommt es zu keinerlei Entscheidungskosten, dafür aber zu enormen externen Kosten, weil ja die individuellen Präferenzen der anderen Personen allesamt unbeachtet blieben. \textcite{Buchanan1962} argumentieren, dass selbst ein wohlwollender Diktator - als solchen könnte man den exogenen Staat, der im Sinne der Public Economy School stets das Beste für alle Individuen will, interpretieren - keine optimalen Entscheidungen treffen, weil er schlicht die individuellen Präferenzen nicht kennt. Das heißt, rationale Individuen werden eine optimale Entscheidungsregel wählen, bei der die Summe aus Kosten der Entscheidungsfindung und die externen Kosten, die entstehen weil Abstimmungen nicht wie erwünscht ausgegangen sind, minimiert wird \parencite[S. 71]{Buchanan1962}. \textcite{Buchanan1962} argumentieren damit schon gegen den Ansatz der damaligen Mainstream-Ökonomen öffentlichen Güter vom "`Staat"' zur Verfügung stellen zu lassen, indem sie zeigen, dass der Staat als solcher erst definiert werden muss. Die beiden sind sich aber auch bewusst, dass sie mit ihrer Analyse der optimale Entscheidungsregel das Problem wie öffentliche Güter nun zur Verfügung gestellt werden sollen nur auf eine höhere Ebene geschoben haben. Denn wie soll denn nun eine optimale Entscheidungsregel genau aussehen und vor allem, wie sollen sich individuell-nutzenmaximierende Wähler auf eine solche einigen? Diesbezüglich liefern sie einen interessanten aber umstrittenen Ansatz. Sie argumentieren, dass unterschiedliche individuelle Präferenzen bei \textit{einzelnen} Entscheidungen sehr unterschiedlich ausgeprägt sein können und ein demokratischer Abstimmungsprozess im Einzelfall zu keinen befriedigenden Ergebnissen führt. Viel einfacher ist es hingegen durch demokratische Prozesse, langfristige, allgemeingültige Gesetze zu schaffen, weil bei der Abstimmung darüber die Wähler nicht von kurzfristig nutzenmaximierenden Verhalten geblendet sind \parencite[S. 78]{Buchanan1962}. Die Aufgabe des Staates wäre es dennach vor allem die allgemeinen Entscheidungsregeln möglichst genau zu formulieren. Mit anderen Worten: Durch demokratische Wahlen eine "`Wirtschaftsverfassung"' festzulegen, die Regierungen und Bürokraten in der weiteren Folge bei Einzelentscheidungen nur einen engen Handlungsspielraum lässt. Dieser Ansatz ist eingängig und lässt sich mit einem einfachen Beispiel verdeutlichen: So macht es tatsächlich keinen Sinn alle Individuen eines Staates darüber abstimmen zu lassen, ob in einer Stadt im Osten des Landes ein Kongresszentrum gebaut werden soll, weil die Individuen im Rest des Landes daraus keinerlei Nutzen ziehen. Jede demokratische Abstimmung darüber würde daher zuungunsten des Kongresszentrums ausgehen. Stattdessen sollte in Gesetzen genau festgelegt werden, unter welchen Umständen der Bau von Gebäuden, Straßen, etc. der Bevölkerung des Staates insgesamt mehr Nutzen bringt als Kosten verursacht, und die Entscheidung über deren Bau alleine auf Grundlage dieser Gesetze vorgenommen werden. 

In weiterer Folge legen \textcite[S. 110]{Buchanan1962} ihre Erkenntnisse auf die damals schon etablierte Public Economy (vgl. Kapitel \ref{cha: Marktversagen}) und die Wohlfahrtsökonomie (vgl. Kapitel \ref{Wohlfahrt}) um. Die beiden Autoren kritisieren, dass in diesen beiden Schulen externe Effekte als Marktversagensform eine große Rolle spielen, aber gleichzeitig noch niemand festgestellt hat, dass bei Abstimmungen, bei denen keine Einstimmigkeit gefordert wird, immer ebenso externe Effekte auftreten. Schließlich erleidet jede Person, deren präferierte Option bei Abstimmungen nicht zum Zuge kommt, externe Kosten, in Form der Nutzen-Differenz zwischen der realisierten Option und der präferierten Option. Daraus folgern \parencite[S. 110]{Buchanan1962}, dass die Einstimmigkeitsregel die einzige Entscheidungsregel ist, die das Kriterium des "`Pareto-Optimums"', das ja eine entscheidende Rolle in der Wohlfahrtstheorie spielt, erfüllt. Die Anwendung dieser Regel verursacht aber enorme Entscheidungsfindungskosten und ist bekanntermaßen aus diesem Grund nicht effizient. Dies ist ein erster Angriff auf die Wohlfahrtsökonomie und auf die Public Economy, die vor allem Buchanan in weiterer Folge zeitlebens stark kritisieren wird. Die Idee der externen Kosten bei Abstimmungen für die "`Verlierer"' in Abstimmungsprozessen verfolgen \textcite[S. 115]{Buchanan1962} weiter und schließen daraus, dass politische Einheiten - also etwa Gebietskörperschaften - eher klein gehalten werden und außerdem möglichst homogen sein sollten. In kleineren politischen Einheiten, in welchen außerdem Konsens in vielen Themenbereichen herrscht, sind die externen Kosten bei demokratischen Abstimmungen geringer als in großen und/oder heterogenen Gemeinschaften. Eine Aussage, die allerdings durchaus problematisch ausgelegt werden kann und daher höchst umstritten ist. In weiterer Folge stellen \textcite[S. 117]{Buchanan1962} dar wie demokratische Entscheidungen im Detail gefällt werden. In den Mittelpunkt rückt hierbei das "`Logrolling"', das man ins Deutschen am ehesten mit "`politischen Stimmentausch"' oder "`Gefälligkeitstausch "`übersetzen könnte. \textcite{Tullock1959} hatte diesen Begriff schon wenige Jahre zuvor analysiert: Wenn politische Abstimmungen nicht als einzelne Events gesehen werden, sondern als rollierende Abfolge von Wahlen, wird Logrolling attraktiv. Politische Gruppen, die für ihre Interessen alleine keine Mehrheiten finden, können so Koalitionen mit anderen politischen Gruppen bilden. Im gegenseitigen Austausch der Stimmen, können so durch Mehrheitsabstimmungen Entscheidungen herbeigeführt werden, die eigentlich keine Mehrheiten repräsentieren. Noch komplizierter wird die Analyse unter Anwendung spieltheoretischer Überlegungen \parencite[S. 149]{Buchanan1962}. Insgesamt führen Mehrheitsabstimmungen häufig zu nicht-optimalen Entscheidungen. Es muss daher stets eine Abwägung vorgenommen werden, ob in bestimmten Bereichen der öffentlichen Wirtschaft Mehrheitsentscheidungen durch Einstimmigkeitsentscheidungen oder Privatisierungen - um beide Extreme zu nennen - ersetzt werden soll \parencite[S. 172]{Romer1988}.

Aufbauend auf das Problem des "`Logrollings"', bei dem stimmen zwischen politischen Einheiten gehandelt werden, entwickelte \textcite{Tullock1967} das Konzept des "`Rent-Seekings"', wobei der Begriff selbst erst später von \textcite{Krueger1974} verwendet wurde \parencite[S. 231]{Congleton2004}. Hierbei werden politische Entscheidungen gekauft. Das heißt, Interessensgruppen versuchen Politiker dazu zu bringen, Entscheidungen so zu fällen, dass sie selbst finanziell davon profitieren, ohne aber dafür neuen Wohlstand zu generieren. Dies kann zum Beispiel dadurch erfolgen, dass der Interessensgruppe durch ein Gesetz eine Monopolstellung auf einem bestimmten Markt eingeräumt wird. Dies führt nicht nur zu ungerechtfertigten Gewinnen bei den Vertretern der Interessensgruppe, sondern ist auch ökonomisch ineffizient und führt daher zu einem gesamtwirtschaftlichen Wohlstandsverlust \parencite[S. 228]{Tullock1967}. Im später geprägten Tullock-Paradoxon stellt der Ökonom fest, dass Rent-seeking den begünstigten Interessensgruppen weit weniger Kosten verursacht, als Gewinne einbringt. Was wiederum die Frage aufwirft, warum rationale Politiker für ihr Stimmverhalten nicht mehr von den Gewinnen verlangen \parencite[S. 217]{Congleton2004}. Insgesamt hat \textcite{Tullock1967} damit einen großen Forschungszweig angestoßen. Das daraus entstandene Gebiet des Lobbyismus ist heute aktueller denn je. Auch in der heute wieder aktuellen Ungleichheitsdebatte (vgl. Kapitel \ref{Ungleichheit}) spielt Rent-seeking eine Rolle und zwar in der Form, dass die wohlhabendsten Personen die Gesetzgebung stark zu ihren Gunsten beeinflussen.

Ebenfalls Mitte der 1960er-Jahre entwickelte \textcite{Buchanan1965} die Neue Politische Ökonomie in eine andere Richtung weiter. Mit "`An Economic Theory of Clubs"' baute er seine Alternative zur Wohlfahrtsökonomie und der Public Economy aus. Vor allem \textcite{Samuelson1954, Samuelson1955} etablierte ja schon zehn Jahre davor die Theorie der Öffentlichen Güter (vgl. Kapitel \ref{Offentliche Guter}) mit unzähligen Anwendungsfällen. Dieser Theorie setzte Buchanan den Begriff der "`Klubgüter"' entgegen. Während Öffentliche Güter durch ihre "`Nicht-Rivalität"' und die "`Nicht Ausschließbarkeit"' im Konsum definiert sind, gilt für Klubgüter nur der erstere Begriff. Durch die künstliche Schaffung von Klubs ist es eben doch möglich Personen von der Nutzung dieser Güter auszuschließen. Es ist dann nicht mehr notwendig, dass der Staat das Angebot an öffentlichen Gütern schafft, stattdessen agieren Klubs bei \textcite{Buchanan1965} als Institutionen, die die Zahlungsbereitschaft der potentiellen Kunden ermitteln und über den "`Klubbeitrag"' einen fairen Preis für das ursprünglich öffentlichen Gut einheben \parencite[S. 244]{Marciano2021}. \textcite{Buchanan1959} kritisierte bereits früher das Konzept der Sozialen Wohlfahrtsfunktion von \textcite{Samuelson1954} als problematisch. Zwar sei dieses formal schön dargestellt, allerdings sei er auch ein normativer Ansatz, der Werturteile darüber voraussetzt, was das "`beste für die Gesellschaft"' ist. \textcite{Buchanan1965} forderte stattdessen, dass die Zahlungsbereitschaft jeder Person für ein öffentliches Gut ermittelt werden sollte und gegen diesen Betrag die öffentlichen Güter der Person zur Verfügung gestellt werden. Ein eleganter Ansatz: Wenn jeder seinen individuellen Preis bezahlt, gibt es keine externen Kosten und das von der Wohlfahrtstheorie geforderte Pareto-Optimum ist erreicht. Problematisch ist allerdings, dass das zentrale Problem der Theorie der öffentlichen Güter dabei ungelöst bleibt: Wie bringt man Individuen dazu ihre wahre Zahlungsbereitschaft bekannt zu geben? Aus diesem Problem schlossen \textcite{Musgrave1939} und \textcite{Samuelson1954} ja überhaupt erst auf die Notwendigkeit staatlicher Eingriffe bei öffentlichen Gütern. Die nicht vollkommen befriedigende Antwort von \textcite{Buchanan1965} war eben die Gründung von Klubs. In kleinen Klubs würden Individuen kooperieren, also ihre wahren Präferenzen offenbaren und damit den fairen Preis für die Klubgüter bezahlen. Das Trittbrettfahrer-Problem würde in diesen kleinen Klubs dann nicht auftreten, wenn als Folge davon der Ausschluss aus dem Klub droht \parencite{Buchanan1965}. Als Klubgüter werden heute oft Mautstraßen, oder die Mitgliedschaft bei Fußballvereinen genannt. Beides mäßig geeignete Beispiel, schließlich wollte \textcite{Buchanan1965} zeigen, dass öffentliche Güter nicht unbedingt vom Staat angeboten werden müssen, sondern stattdessen privatwirtschaftlich organisierte Institutionen den Zugang zum grundsätzlich öffentlichen Gut regeln. Noch allgemeiner aber wollte Buchanan eine Alternative zur Wohlfahrtsökonomie und der darin verankerten Sozialen Wohlfahrtsfunktion im Sinne von \textcite{Samuelson1954, Samuelson1955} liefern.

\textcite{Buchanan1962} folgen in ihrem "`Calculus of Consent"' noch recht streng der Prämisse eine positive Theorie zu sein, oder weisen zumindest darauf hin, wenn ausnahmsweise normative Ansätze dargestellt werden. Auch die Errungenschaften der beiden Mitte der 1960er-Jahre - Das Rent-seeking von Tullock, sowie die Entwicklung der Klubgüter durch Buchanan - wurden in der wissenschaftlichen Community aufgenommen und haben sich bis heute dort verankert. In den späteren 1970er-Jahren lieferten die beiden hingegen zunehmend unkonventionelle Beiträge. So publizierte Tullock Arbeiten zur Ökonomie in Diktaturen, ein damals fast verbotenes Thema wie \textcite[S. 215]{Congleton2004} meint. Bekannter aber ebenso unkonventionell wurden die späteren Arbeiten seines Partners, wie zum Beispiel \textcite{Buchanan1977} oder \textcite{Buchanan1978}. In diesen fällt vor allem durch die radikale Ablehnung jeglicher Staatseingriffe auf. Auch können diese Arbeiten eindeutig nicht mehr als rein positivistisch gesehen werden \parencite[S. 105]{Mitchell1988}. Es waren so auch diese späteren Arbeiten, die das Bild von James McGill Buchanan als weitgehend kontroversen und extrem libertären Ökonomen etablierte. Da Politiker und Bürokraten primär ihren eigenen Nutzen maximieren, können von ihnen gesteuerte fiskalpolitische Eingriffe nicht zur gesamtwirtschaftlichen Wohlfahrtsmaximierung beitragen. Die individuelle Nutzenmaximierung von Politikern wird außerdem dazu führen, dass diese immer mehr Macht anstreben und daher danach streben die Staatsquote ständig zu erhöhen. Dies führt auch dazu, dass Unternehmen im Staatsbesitz extrem wichtig sind als Auftraggeber für privatwirtschaftliche Unternehmen, was wiederum zur Folge hat, dass diese zunehmend Einfluss auf politische Entscheidungsprozesse im Sinne des Rent-seekings vornehmen müssen um Aufträge zu erhalten. Buchanan ist also überzeugt davon, dass der Staat möglichst schlank gehalten werden muss. Keynesianischen Eingriffe lehnt er vollends ab, wobei seine Wortwahl nicht zimperlich ist, wenn er in \textcite{Buchanan1978} davon spricht, dass keynesianische Wirtschaftspolitik eine Krankheit ist, die langfristig das Bestehen der Demokratie gefährdet. Einflussreich ist auch seine Einstellung zu Budgetdefiziten, die er in jeglicher Form ablehnt. Laut \textcite{Buchanan1978} führte die Umsetzung der keynesianischen Ideen dazu, dass ständige Budgetdefizite als normal betrachtet werden und Politiker nicht mehr nach ausgeglichenen Budgets streben. Um die negativen Folge von Staatsverschuldung zu vermeiden, sollten Politiker mittels enger verfassungsrechtlicher Vorgaben daran gehindert werden defizitäre Budgets zu verursachen \parencite[S. 172]{Pressman1999}. Genau diese Idee wird heute in vielen westlichen Staaten als "`Schuldenbremse"' oder "`Schuldenobergrenze"' praktiziert. Im Gegensatz zur damals ebenfalls aufkommenden "`Neuen Klassischen Makroökonomie"' (vgl. Kapitel \ref{Neue Makro}), akzeptiert die "`Public Choice"'-Schule das Auftreten von Marktversagen. Die Lösung liegt aber nicht in Staatseingriffen, sondern gesetzliche Rahmenbedingungen, die das Funktionieren von Märkten fördern. Diese Rahmenbedingungen sollten durch enge verfassungsmäßige Regelungen geschaffen werden. Auch dieser Ansatz ist modernen Vertretern der "`Neuen Politischen Ökonomie"' (siehe dieses Kapitel weiter unten) und des "`Neuen Institutionalismus"' (vgl. Kapitel \ref{Neue Institut}) nicht unähnlich. Dieses sehen auch in "`zu wenig Wettbewerb"' ein aktuell zentrales Problem.

Aus wissenschaftlicher Sicht waren diesen späten Arbeiten von Buchanan weniger bedeutend. Allerdings hatte \textcite{Buchanan1978} große politische Wirkung. In den USA der frühen 1980er-Jahre gewannen libertäre Ideen wie der Ruf nach einem schlanken Staat, Steuersenkungen und Nulldefiziten enorm an Zulauf, die in der Präsidentschaft von Ronald Reagan mündeten. Obwohl Buchanan selbst Reagan heftig kritisierte \parencite[S. 177]{Romer1998}, weil dieser das Ziel eines ausgeglichenen Budgets nicht konsequent genug verfolgte, wird der Schule und insbesondere den Schülern Buchanan's großer Einfluss auf die Reagan-Präsidentschaft zugeschrieben. Tatsächlich waren viele Absolventen der "`Virginia School"' in der Reagan-Regierung aktiv \parencite[S. 96]{Warsh}. Die Hauptvertreter der "`Public Choice"'-Schule, James McGill Buchanan und Gordon Tullock, waren aus heutiger Sicht extrem unkonventionelle Ökonomen. Entgegen dem Zeitgeist verzichteten beide fast gänzlich auf hoch-mathematische Modelle, aber auch auf empirische Arbeiten. \textcite[S. 215]{Congleton2004} etwa meinte, dass Gordon Tullock geniale Ideen entwickelte, aber diese bewusst nicht besonders tief analysierte, sondern rein verbal formulierte und anschließend ohne viel Feinschliff rasch publizierte. \textcite[S. 178]{Romer1988} vertritt eine ähnliche Meinung zu Buchanan, wenn er schreibt, dass Buchanan ausschließlich Theorien erstellte und keine einzige empirische Arbeit verfasst.  Überraschend und auch sehr umstritten war die Verleihung des Wirtschafts-Nobelpreises an ihn im Jahr 1986. Der erzkonservative Buchanan war von 1984-1986 Präsident der ebenso erz-liberalen "`Mont Pelerin Gesellschaft"'. Unter anderem die Verleihung des Preises an Buchanan brachte dem Wirtschaftsnobelpreis-Komitee den Vorwurf ein, liberale Ökonomen zu bevorzugen und sogar vorwiegend solchen, die Mitglied der umstrittenen "`Mont Pelerin Gesellschaft"' sind, den Preis besonders häufig zu verleihen. Dazu kommt, dass Buchanan's Arbeiten zwar ganz bestimmt eine Forschungslücke identifizierten und auch gewisse Beachtung fanden, allerdings in der Community der führenden Ökonomen eher ignoriert wurden. Er unterrichtete weder an einer der Top-Wirtschaftsschulen in den USA und verweigerte - wie bereits erwähnt - seine Thesen in hoch-mathematische Theorien zu gießen \parencite[S. 173]{Pressman1999}. Überraschend war auch, dass sein kongenialer Partner Gordon Tullock bei der Nobelpreis-Vergabe unberücksichtigt blieb, was dieser selbst stark beklagte \parencite[S. 98]{Warsh}.

Innerhalb der Neuen Politischen Ökonomie übernahmen bald andere Köpfe die führenden Rollen. Die Forschung zum "`Politische Wirtschaftszyklus"' (vgl. Kapitel \ref{Der Politische Wirtschaftszyklus}) untersucht zwar ebenso individuell-nutzenmaximierende Wähler und Stimmen-maximierende Politiker, hat aber sonst nur mehr sehr wenig gemeinsam mit der hier dargestellten "`Public Choice Theory"' im engeren Sinn. Davor werfen wir aber noch einen Blick auf die "`Rochester-School"' und die Lehren der "`Ostroms"', die zeitlich fast parallel zur "`Public-Choice-Theory"' entwickelt wurden.

\section{Alternative Ansätze der Neuen Politischen Ökonomie: Riker, Olson und die Ostroms }

Ebenfalls im Jahr 1962 publizierte William Riker sein Buch "`The Theory of Political Coalitions"' \parencite{Riker1962}. Riker war bereits in den 1950er-Jahren überzeugt, das Politik und Ökonomie stark miteinander interagieren und gemeinsam als positive Theorie mit quantitativen Methoden analysiert werden sollten \parencite[S. 205]{Maske2003}. Dementsprechend inspirierten ihn die frühen Arbeiten zur Spieltheorie \parencite{Morgenstern1944}, sowie die in diesem Kapitel schon behandelten Arbeiten von \textcite{Downs1957b}, \textcite{Black1948a} und \textcite{Arrow1951} \parencite[S. 205]{Maske2003}. In seinem Hauptwerk \textcite{Riker1962} ist vor allem die Verwendung spieltheoretischer Ansätze und hoch-mathematischer Methoden bahnbrechend. Riker etablierte entsprechende Forschung an der University of Rochester und

Dieser Ansatz entspricht natürlich eher der Entwicklung der Mainstream-Ökonomie, in der sich mathematische Gleichgewichtsmodelle mehr und mehr durchsetzten. Dennoch beh 







HIER WEITER
\textcite[S. 176]{Romer1988}
\textcite[S. 102]{Mitchell1988}
\textcite{Maske2003}


Während Vincent Ostrom eher philosophische Überlegungen einbrachte, machte sich Elinor Ostrom einen Namen mit empirischen Studien \parencite[S. 110]{Mitchell1988}. Das Forscherehepaar Ostrom lebte praktisch gemeinsam für ihre Version der "`Neuen Politischen Ökonomie"', beide verstarben nach fast 50 Jahren Ehe im Jahr 2012 im Abstand von nur wenigen Wochen. 


\textcite[S. 110]{Mitchell1988}



\section{Der Politische Wirtschaftszyklus}
\label{Der Politische Wirtschaftszyklus}

In den 1950er und 1960er-Jahren wa die Neoklassischen Synthese (vgl. Kapitel \ref{Synthese}) die alleinige und unangefochtene Mainstream-Ökonomie. Damit verbunden war ein nicht hinterfragter Glaube daran, dass "`der Staat"' die Konjunktur durch belebende Maßnahmen fördern sollte und auch bei Marktversagen eingreifen sollte \parencite[S. 522]{Snowdon2005}. Ab Ende der 1960er Jahre folgten erste theoretische Zweifel an der Neoklassischen Synthese (vgl. Kapitel \ref{Monetarismus} und \ref{micmac}). Ab Mitte der 1970er Jahre kam es schließlich auch auf dem Gebiet der Politischen Ökonomie zu bahnbrechenden Arbeiten, die untersuchten, wie die Politische Ökonomie mit der Makroökonomie interagiert. Konkret ging es darum, wie die Politik die beiden zentralen makroökonomischen Kennzahlen zu dieser Zeit, Arbeitslosigkeit und Inflation zu beeinflussen versuchte. Mitte der 1970er Jahre war der Erwartungsgestützte Phillipskurven-Zusammenhang nach \textcite{Phelps1968} und \textcite{Friedman1968} noch State of the Art\footnote{Die bereits existierenden Ansätze der Neuen Klassiker (vgl. Kapitel \ref{Neue Makro}), wonach es gar keinen Zusammenhang zwischen Arbeitslosigkeit und Inflation gibt, waren bereits publiziert worden, aber noch nicht weitreichend anerkannt}. William Nordhaus lieferte darauf aufbauend seine Arbeit zum politischen Konjunkturzyklus \parencite{Nordhaus1975}, die eine formal-mathematische Analyse zum Zusammenhang zwischen Politik und Ökonomie vorlegte und damit die Politische Ökonomie auf eine neue Ebene hob. Dazu griff er zunächst die soeben behandelten Arbeiten von \textcite{Downs1957, Downs1957b} auf. Er ging also davon aus, dass es in einem Zwei-Parteien-System beide Kräfte zur Mitte tendieren und Politiker außerdem vorwiegend ihre eigene Wiederwahl anstreben und daher weitgehend ideologiefrei regieren. Wähler wollen sowohl niedrige Arbeitslosigkeit, als auch niedrige Inflationsraten. Sie messen die Leistung der amtsführenden Politiker daran, in welchem Ausmaß diese beiden Ziele erreicht wurden. Dabei sind die Wähler aber recht kurzsichtig, vergessen also schnell was zu Beginn der Legislaturperiode geschehen ist und berücksichtigen dafür bei Wahlen die Kennzahlen der jüngsten Monate sehr stark. Wie bereits erwähnt, war damals die Erwartungsgestützte Phillipskurve State of the Art. Das heißt kurzfristig gibt es einen negativen Zusammenhang zwischen Arbeitslosigkeit und Inflation und die Inflationserwartungen werden aus der vergangenen Inflation abgeleitet. Langfristig gibt es hingegen keinen Zusammenhang. Politiker können nun Geld- und Fiskalpolitik einsetzen, um Inflation und Arbeitslosigkeit zu steuern. Und das machen sie auch: Vor Wahlen verstärken Politiker fiskalpolitische Maßnahmen um das BIP zu steigern und die Arbeitslosigkeit zu senken. Die daraus resultierende, höhere Inflation tritt erst nach den Wahlen auf. Nach erfolgreicher Wiederwahl müssen Inflationserwartungen und die Inflation selbst gesenkt werden, dafür werden Sparmaßnahmen und höhere Arbeitslosenraten in Kauf genommen. So entsteht der von \textcite{Nordhaus1975} postulierte politische Konjunkturzyklus: Durch "`Wahlzuckerl"' vor den Urnengängen gibt es hohes BIP-Wachstum, niedrige Arbeitslosigkeit bei gleichzeitig (noch) niedriger Inflation, nach den Wahlen gibt es Rezessionen bei gleichzeitig hoher Inflation und steigenden Arbeitslosenzahlen.
\textcite{Nordhaus1975} zeigt aber weiters das langfristige Problem mit diesem Ansatz: Bei den Wahlen selbst sind Inflation und Arbeitslosigkeit entscheidend. Nach den Wahlen steigt die Inflation stets an. Langfristig ist die durchschnittliche Inflationsrate damit stets höher als im Optimum bei der Natürlichen Arbeitslosenquote. Dementsprechend ist auch die Inflationserwartung langfristig zu hoch mit dem Ergebnis, dass aus dem kurzfristig Wahl-optimierenden Verhalten von Entscheidungsträgern eine Politik resultiert, die langfristig eine zu hohe Inflation hervorbringt, gleichzeitig liegt die Arbeitslosenraten unter der natürlichen Arbeitslosenrate \parencite{Nordhaus1975}. 
Das Modell wird als auch als "`Opportunistisches Modell"' bezeichnet, weil Politiker darin keine Ideologien verfolgen, sondern opportunistisch handeln um ihren Stimmenanteil zu optimieren. Das Modell überzeugt durch seinen soliden formalen Aufbau. Empirisch ließ es sich nur teilweise erfolgreich anwenden. Als problematisch wurde von manchen allerdings die Annahme angesehen, dass Politiker keine ideologischen Ziele verfolgen. Dies erscheint doch recht unrealistisch, da auch in Zwei-Parteien-Systemen doch recht verfestigte Überzeugungen beobachtet werden können.

Als Gegenmodell entstand daher wenig später das "`Partei-Ideologien Modell"' (engl.: "`Partisan Model"') von \textcite{Hibbs1977}. Er geht stärker auf die politischen Gegebenheiten der Nachkriegszeit bis in die 1970er Jahre ein. Für diese Zeit ist es im wesentlichen unumstritten davon auszugehen, dass es in den westlichen Demokratien jeweils zwei große Parteien gibt. Eine davon ist eher links orientiert, wie die Demokraten in den USA, Labour in Großbritannien und sozialdemokratische\footnote{Diese hießen zu der Zeit in den meisten westeuropäischen Staaten noch "`Sozialistische Parteien"', grenzten sich aber doch recht stark vom Sozialismus im Sinn des real existierenden Sozialismus ab.} Parteien in Westeuropa. Die andere Großpartei war konservativ eingestellt, so wie die Republikaner in den USA und Frankreich, Conservatives in UK und  Christdemokraten oder einfach Volksparteien in den übrigen west-europäischen Staaten. Als wichtigsten wirtschaftspolitischen Trade-off identifiziert auch \textcite{Hibbs1977}, ähnlich wie \textcite{Nordhaus1975}, jenen zwischen Arbeitslosigkeit und Inflation. Tatsächlich dominierten diese beiden Themen die wirtschaftspolitische Diskussion der 1970er Jahre. Die zentrale Annahme bei \textcite[S. 1468]{Hibbs1977} ist nun, dass die linken Parteien als primäres Ziel niedrige Arbeitslosigkeit verfolgen und dafür höhere Inflation akzeptieren, während konservative Parteien primär eine Aversion gegen Inflation haben, die Arbeitslosigkeit hingegen als zweitrangig erachten. Damit unterstellt Hibbs den Parteien einen ideologischen Unterschied im Hinblick auf deren makroökonomischen Ziele. Dies zeigt er auch ausführlich indem er die Entwicklung der beiden Kennzahlen für zwölf verschiedene Länder im Zeitraum zwischen 1945 und 1969 dahingehend vergleicht, ob linke oder konservative Parteien an der Macht waren. Dies ist insgesamt recht eingängig, aber dennoch umstritten. Erstens reduziert Hibbs den Trade-Off auf die zwei Kennzahlen Arbeitslosigkeit und Inflation. Dessen ist er sich durchaus bewusst und er führt auch andere makroökonomischen Zielgrößen der Wirtschaftspolitik, wie Wirtschaftswachstum und Einkommensverteilung an \parencite[S. 1471]{Hibbs1977}. Zweitens geht Hibbs davon aus, dass linke Parteien eher von Personen mit niedrigem bis durchschnittlichem Einkommen gewählt werden, während Wohlhabende eindeutig Konservative Parteien bevorzugen. Dies scheint nachvollziehbar. Es gibt allerdings keine theoretische Begründung dafür, warum arme Haushalte Inflation weniger abneigend gegenüber stehen sollten als reiche Haushalte. Auch dies diskutiert \textcite[S. 1470]{Hibbs1977}. Er argumentiert schließlich empirisch: In Umfragen lehnten Bezieher geringer und mittlerer Einkommen hohe Arbeitslosigkeit tatsächlich stärker ab, als hohe Inflation, während für Bezieher hoher Einkommen das umgekehrte galt \parencite[S. 1470]{Hibbs1977}. Für die USA und Großbritannien erstellt er darauf aufbauend ein ökonometrisches Modell, dass die Arbeitslosigkeit in Abhängigkeit der regierenden Parteien prognostiziert und seine theoretischen Annahmen untermauert.

Sowohl \textcite{Nordhaus1975} als auch \textcite{Hibbs1977} gelten in der Disziplin der Politischen Ökonomie als extrem bedeutend. Auffällig ist aber, dass sich die beiden in einem wichtigen Punkt widersprechen: Im Gegensatz zu \textcite{Nordhaus1975} geht \textcite{Hibbs1977} nicht davon aus, dass sich politische Parteien hinsichtlich ihrer wirtschaftspolitischen Zielen aneinander annähern, sondern ihren ideologischen Prinzipien treu bleiben. Sind Politiker nun Opportunisten oder Ideologen? In dieser Zwickmühle lieferten \textcite{Schneider1978a, Schneider1978b} eine viel beachtete Erweiterung. Diese Arbeiten sind insbesondere auch aus deutschsprachiger Sicht bedeutend. Mit dem Schweizer Bruno Frey und dem Österreicher Friedrich Schneider lieferten schließlich zwei Ökonomen, die beide überwiegend in Zentraleuropa tätig waren und sind, einen bahnbrechenden Beitrag. Die beiden Arbeiten konzentrieren sich vor allem auf eine saubere ökonometrische Analyse der Thematik. In \textcite[S. 175]{Schneider1978a} führen die beiden Autoren eine "`Popularitäts-Funktion ein. Damit messen sie wie die ökonomischen Faktoren Arbeitslosigkeit, Inflation und Konsumwachstum, sowie die persönlichen Faktoren, wie die Beliebtheit, basierend auf Umfragewerten, die Popularität der US-Präsidenten zwischen 1953 und 1975 beeinflussten. Außerdem erstellen sie eine "`Reaktions-Funktion"', die zeigt, wie der jeweilige Präsident auf die ökonomischen Gegebenheiten reagierte um seine Macht zu sichern \parencite[S. 178]{Schneider1978a}. Regierende wollen primär ihren eigenen Nutzen maximieren. Dies bedeutet sie wollen ihre Ideologie umsetzen. Dabei unterliegen sie aber einigen Einschränkungen: Vor allem die Notwendigkeit der Wiederwahl. \textcite[S. 189f]{Schneider1978a} ziehen daraus den Schluss, dass Politiker primär ideologisch motiviert sind, wie in \textcite{Hibbs1977} postuliert. Wenn die eigene Popularität allerdings fällt und zudem Wahlen anstehen, werden Politiker zunehmend populistisch, wie von \textcite{Nordhaus1975} vorhergesagt, und versuchen durch beliebte Maßnahmen ihre Stimmen zu maximieren, ohne auf die eigene Ideologie zu achten. In \textcite{Schneider1978a, Schneider1978b} wird dies mittels ökonometrischem Modell für die USA, bzw. Großbritannien dargelegt.

Alle drei genannten Ansätze - also der Opportunistische, der Ideologische, sowie die Synthese daraus, wurden viel beachtet. Vor allem das hoch-formale Werk von \textcite{Nordhaus1975} war wegweisend in der Neuen Politischen Ökonomie. Allerdings war diesen Modellen nur kurzer Erfolg gegönnt. Denn die "`Lucas-Kritik"' (vgl. Kapitel \ref{Neue Makro}) und der rasche Aufstieg der Theorie der Rationale Erwartungen spülte innerhalb der akademischen Welt nicht nur die Neoklassische Synthese und den Monetarismus innerhalb kurzer Zeit weg, sondern damit auch die Grundlagen der Modelle von \textcite{Nordhaus1975}, \textcite{Hibbs1977} und \textcite{Schneider1978a}: Unter der Annahme rationaler Erwartungen gibt es für Politiker keine Möglichkeit die Wähler kurzfristig zu täuschen und damit Stimmen zu generieren. Außerdem wurde der Phillips-Kurven-Zusammenhang von den jetzt dominierenden Neuen Klassikern komplett abgelehnt. Für eine allgemein-gültige Theorie fehlte außerdem die Empirie für diese frühen Modelle der Politischen Ökonomie. Zwar waren \textcite{Hibbs1977} und \textcite{Schneider1978a} bemüht gerade empirisch und methodisch fortschrittlich zu arbeiten. Allerdings lieferte die Modelle unterschiedlich erfolgreiche Ergebnisse, wenn man sie auf alternative Zeiträume oder Staaten anwendete \parencite[S. 652]{Alesina1987}. Die Forschung zum Zusammenhang zwischen Makroökonomie und demokratischen Prozessen kam rasch zum Erliegen.

Erst Ende der 1980er Jahre schließlich fand die Politische Ökonomie Wege rationale Erwartungen in ihre Modelle aufzunehmen. Untrennbar mit dem Wiederentdecken des Themas verbunden ist der Name Alberto Alesina, der ab Ende der 1980er Jahre bis zu seinem frühen Tod im Jahr 2020 der prägendste Vertreter der Neuen Politischen Ökonomie war. Im wesentlichen baut seine Theorie auf jenem von \textcite{Hibbs1977} auf und wird daher auch als "`Rational Partisan Theory"' (dt.: Rationales Partei-Ideologien-Theorie) bezeichnet. Das Forschungsprogramm von \textcite{Alesina1987, Alesina1988, Alesina1989} ist jedoch umfangreicher und wesentlich moderner - Hibbs war im Jahr 1977 noch vom bereits damals veralteten ursprünglichen Phillips-Kurven-Zusammenhang ausgegangen. Zunächst wurde in der Rational Partisan Theory, wie der Name schon sagt, die Theorie der Rationalen Erwartungen der Neuen Klassiker (vgl. Kapitel \ref{Neue Makro}) aufgenommen. Wichtig ist auch, dass die Spieltheorie (vgl. Kapitel \ref{Spieltheorie}) als Entscheidungstheorie Eingang in der Neue Politische Ökonomie gefunden hat \parencite{Alesina1987} und in weiterer Folge auch dort eine wichtige Rolle spielte. Außerdem wurde zu dieser Theorie eine große Anzahl empirischer Studien durchgeführt (vgl. z.B.: \textcite{Alesina1988b}, \textcite{Alesina1992}).

Das "`Rational Partisan-Model"' wurde in \textcite{Alesina1987} entwickelt. Wie bereits erwähnt knüpft es an \textcite{Hibbs1977} an, und geht davon aus, dass es im Zwei-Parteien-System ideologische Unterschiede zwischen den beiden Parteien gibt. Er implementiert aber auch die Theorie der Rationalen Erwartungen, die in der Form der einflussreichen Arbeit von \textcite{Kydland1977} die Ökonomie revolutioniert hat (vgl. Kapitel \ref{Neue Makro}). Die Wähler wie auch die politischen Parteien sind in diesem Modell folglich zwei Spieler mit unterschiedlichen Zielen. Unter der Annahme Rationaler Erwartungen kann es aber zu keiner systematischen Täuschung der Wähler durch die Politik kommen. Die Erklärung für unterschiedliche Inflations-Arbeitslosigkeits-Gleichgewichte, also politische Konjunkturzyklen, wie von \textcite{Nordhaus1975} vorgeschlagen, muss daher scheitern. Wenn die Wähler, die gleichzeitig ja auch Arbeitnehmer sind, rationale Erwartungen haben, dann können sie von den politischen Parteien nicht systematisch getäuscht werden. Durch politische Entscheidungen ausgelöste Konjunkturzyklen existieren dann nicht, weil die Wähler ihr Verhalten stets an jenes der Politiker sofort anpassen. Hier findet \textcite{Alesina1987} seinen Ansatz für das "`Rational Partisan-Model"'. Wähler können nämlich ihre Präferenzen nur bei Wahlen Ausdruck verleihen, zwischen jeweils zwei Wahlterminen sind die politischen Machtverhältnisse hingegen fixiert. Man kann diesen Effekt mit einer "`nominalen Rigidität, wie in Kapitel \ref{Nominale Rigiditäten} dargestellt, vergleichen. Die Neu-Keynesianer argumentieren dort, dass Geldpolitik in der kurzen Frist eben doch wirksam ist, weil Lohnverhandlungen die Gehälter für die Arbeitnehmer für einen bestimmten Zeitraum fixieren. Analog argumentiert \textcite{Alesina1987}: Die Wähler und Arbeitnehmer verhandeln ihre Löhne mit dem Wissen, dass die beiden politischen Parteien unterschiedliche Präferenzen hinsichtlich Inflation haben. Das heißt: Sind linke Parteien an der Macht, ist die Inflation tendenziell höher, was höhere Lohnabschlüsse rechtfertigt. Umgekehrtes gilt, wenn konservative Parteien an der Macht sind. Rationalen Lohn-Verhandlern ist dies bekannt und wird dementsprechend eingepreist. Finden allerdings nach den Lohnverhandlungen Wahlen statt, so können selbst rationale Verhandler die zukünftigen politischen Maßnahmen nicht abschätzen, weil Unsicherheit darüber besteht, welche Partei überhaupt an der Macht ist \parencite[S. 653]{Alesina1987}. Kommt eine Konservative Partei an die Macht, so wird die Inflation gesenkt. Die zu hohen Inflationserwartungen führen zu einem Anstieg der Arbeitslosigkeit und sinkenden Wachstumsraten. Nach Anpassung der Inflationserwartungen werden sich Arbeitslosigkeit und Wachstum wieder an ihre natürlichen Raten annähern. Umgekehrt wird bei einem Wahlsieg linker Parteien die Inflation höher als erwartet sein. Die Arbeitslosigkeit sinkt und das Wachstum steigt zunächst. Zwischen zwei Wahlen kommt es also zu einem politischen Konjunkturzyklus. Nach den Wahlen weichen die Kennzahlen vom natürlichen Gleichgewicht ab und nähern sich diesem nach einiger Zeit wieder an. Da Abweichungen vom langfristigen Gleichgewicht immer unerwünscht sind, plädiert \textcite[S. 653]{Alesina1987} dafür, den Handlungsspielraum politischer Entscheidungsträger durch klar definierte Regeln einzuschränken.
In ähnlicher Weise - wie \textcite[S. 671]{Alesina1987} selbst anmerkt - hatten bereits ein Jahr früher \textcite{Rogoff1986} das "`Opportunistische Modell"' von \textcite{Nordhaus1975} zu einem "`Rationalen Opportunistischen Modell"' weiterentwickelt. Ihr Ausgangspunkt dabei war, dass die Wähler in ihrem Wahlverhalten zwar rational entscheiden, allerdings unter Informationsasymmetrie leiden. Der Aufwand sich über die Wahlprogramme der Parteien zu informieren, ist höher als der einzelwirtschaftliche Nutzen einer daraus abgeleiteten "`richtigen"' Wahl. Dementsprechend können Politiker durch opportunistisches Verhalten auch Wählern, die unter der Prämisse Rationaler Erwartungen handeln, Stimmen generieren.

HIER WEITER

\parencite[S. 542]{Snowdon2005} Empirische Ergebnisse.











\section{Moderne Politische Ökonomie: Die Unabhängigkeit von Zentralbanken}

Schieben wir an dieser Stelle einen längeren Exkurs über Zentralbanken im Allgemeinen ein: Texte über Funktion, Entstehung und Evolution von Zentralbanken könnten ganze Bibliotheken füllen. Hier soll nur ein ganz kurzer Abriss über Zentralbanken im allgemeinen gemacht werden. Der amerikanische Entertainer Will Rogers soll bereits 1920 gesagt haben: "`There have been three great inventions since the beginning of time: fire, the wheel, and central banking."' Das ist zwar deutlich übertrieben, aber tatsächlich scheint die Arbeit von Zentralbanken\footnote{Gemeint ist hier die Durchführung der Geldpolitik.} für überraschend viele Menschen ein Mysterium. Dass es ganz grundlegende Unterschiede gibt, ob eine Regierung oder aber eine Zentralbank Geld ausgibt, verstehen viele nicht. Umgekehrt glauben viele, dass Geld ausschließlich von der Zentralbank geschaffen wird. Und um ehrlich zu sein, ist das Geldsystem wesentlich komplizierter als es auf den ersten Blick wirkt. Auch dieses Buch muss diesbezüglich an der Oberfläche bleiben\footnote{Möglicherweise bleibt der Beitrag sogar zu stark an der Oberfläche, aber die Alternative wäre, dass der Fokus auf das eigentliche Thema verloren ginge.}. Wir betrachten hier die historische Entwicklung, die Zentralbanken vor allem im 20. Jahrhundert durchliefen. Zentralbanken werden häufig die "`Hüterinnen der Währung"' genannt. Geld ist evolutionär so entstanden, dass sich ein bestimmter "`Kreis an Personen"' auf bestimmte Gegenstände als Tauschmittel geeinigt hat. Das hat den Vorteil, dass zum Beispiel ein Fischer, der zur Abwechslung einmal Kartoffel erwerben wollte, nicht solange suchen musste, bis er einen Ackerbauern gefunden hat, der selbst Fische erwerben wollte. Stattdessen konnte der Fischer seine Ware an jeden Fisch-Liebhaber gegen Geld eintauschen und mit dem Geld Kartoffel erwerben. Der Nachteil des Ganzen: Der "`Kreis der Personen"' muss sich auf ein Gut einigen, das alle als Tauschmittel akzeptieren. Das Gut muss also einen "`allgemeinen Wert"' haben. Niemand kann genau sagen warum, aber bestimmte Edelmetalle, vor allem Gold, hat sich als zentrales Tauschmittel früh etabliert. Zur Einordnung: Wir reden hier von vorchristlichen Zeiten, also lange vor der Entstehung der Ökonomie als Wissenschaft. Die ständige Mitnahme seiner Geldreserven in Form von purem Gold erwies sich aber rasch als unpraktisch. Erstens, Gold ist schwer, zweitens es nutzt sich ab, verliert also an Wert und drittens, in der Praxis ist es recht schwer den \textit{reinen} Goldgehalt, zum Beispiel einer Münze, festzustellen. Die Heureka-Geschichte des Archimedes diesbezüglich ist ja recht gut bekannt. Daher ging man dazu über seine Edelmetalle einer zentralen Institution - genannt Bank - zu übergeben, die dafür wiederum ein Dokument (Wechsel) ausstellte. Die Idee ist, dass dieses - an sich wertlose Dokument - einem potentiellen Käufer signalisieren soll: Ich habe Gold bei der Institution Bank liegen, wenn du mir deine Güter gibst, so gebe ich dir das Dokument und du kannst dir mein Gold von der Bank holen. Im recht kleinen Personenkreis funktioniert das recht gut. Allerdings müssten alle Personen ihre Goldreserven bei der gleichen Bank einlagern, damit das System reibungslos funktioniert. Ist \textit{die eine} Bank räumlich weit weg, ist ein Dokument von dieser Bank umständlich gegen Gold einzutauschen. Es entstanden also lokal verschiedenste Banken, die verschiedenste Dokumente ausstellten. Um dennoch ein einheitliches und damit reibungsloses Geldsystem zur Verfügung zu stellen, müssten diese Banken wiederum eine zentrale Institution gründen, die ein einheitliches Dokument ausstellt. Meist trat spätestens hierbei die Politik in das Spiel ein. Die herrschende Macht - weitgehend egal übrigens ob König, Parlament oder Diktator - gründete diese "`Bank der Banken"' und damit das was wir heute "`Zentralbank"' nennen.

Das eben beschriebene System wäre ein "`reiner Goldstandard"'\footnote{Eigentlich müsste es "`Edelmetallstandard"' heißen, denn als hinterlegtes Gut fungierten zunächst häufig auch andere Edelmetalle, tatsächlich Silber häufiger als Gold. Namensgebend ist aber jenes System, dass sich 1870, ausgehende von Großbritannien, weltweit durchgesetzt hat. Im "`reinen Goldstandard"' im engeren Sinn wird das vorhandene Gold tatsächlich zu Münzen geprägt und als Zahlungsmittel verwendet. Ökonomisch gesehen ist es aber von untergeordneter Bedeutung ob das Gold tatsächlich im Umlauf ist, oder ob Geldscheine stattdessen verwendet werden. Wichtig ist, dass stets die \textit{gesamte} Geldmenge durch Gold repräsentiert ist.}. Die Bezeichnung von Währungen erinnert teilweise noch heute an dieses System: Zum Beispiel "`Pfund Sterling"'. Pfund ist eine Gewichtseinheit (Masseneinheit), Sterling eine Metalllegierung aus Silber und Kupfer. Auf den Geldscheinen steht ein Satz, der uns heute seltsam anmutet und auch nicht mehr wörtlich genommen werden darf: "`I promise to pay the bearer on demand the sum of 10 pounds"'. Also: "`Dem Inhaber der Banknote werden 10 Pfund bezahlt"'!? Der Inhaber der Banknote \textit{hat} ja schon den 10-Pfund-Schein. Gemeint ist aber eben, dass man für diesen Schein 10 Pfund Sterling erhält. Was aber eben auch nicht mehr stimmt. Die Englische Zentralbank "`Bank of England"' hat keine Eintauschverpflichtung gegen Silber. Auf den Pfund-Sterling-Banknoten ist außerdem die Queen abgebildet, was suggeriert, dass das Herrscherhaus das Geldsystem kontrolliert. Auch das ist überholt: Wir werden später sehen, dass die Unabhängigkeit der Zentralbanken bis heute ein zentrales Thema in der Geldpolitik ist. Die einzige Aufgabe einer Zentralbank besteht im "`reinen Goldstandard"' darin ein Edelmetall einzulagern und für eine gewisse Menge dieses Edelmetalls genau einen Geldschein auszugeben. Die Menge an Geldscheinen kann nur dann steigen, wenn auch die Menge an Edelmetall im selben Ausmaß steigt. Aktive Geldpolitik ist in diesem Fall nicht möglich. Diese Form des Geldsystems galt lange Zeit als das einzig stabile und denkbare System. Herrscher wichen meist nur deshalb davon ab, um sich selbst einen Vorteil zu verschaffen, indem sie zum Beispiel zusätzliches - nicht durch Gold gedecktes - Geld druckten um ihre Schulden zu bezahlen. Man nennt das "`Seignorage"' und es führt fast immer zu (Hyper-)Inflation, Vertrauensverlust in die Währung und schließlich eine Wirtschaftskrise. Papiergeld war daher lange Zeit sehr unbeliebt und musste der Bevölkerung aufgezwungen werden. Auch nach dem Zweiten Weltkrieg gab es aus diesem Grund in vielen Währungen noch Münzen mit Edelmetallgehalt - nicht ausschließlich zu Sammelzwecken, sondern es wurde damit tatsächlich bezahlt. Die klassischen Ökonomen hielten den "`reinen Goldstandard"' als einzig denkbares, stabiles Währungssystem und Geld als reines Tauschmittel. Heute gilt der Goldstandard als veraltetes System, wenngleich zum Beispiel in der "`Österreichischen Schule"' (vgl. Kapitel \ref{Austria}) nach wie vor immer wieder die Vorzüge des Goldstandards propagiert werden.  

Mit der ersten Globalisierungswelle, Ende des 19. Jahrhunderts, erhielten die Zentralbanken eine neue Aufgabe, nämlich das Aufrechterhalten stabiler Wechselkurse. Mit dem "`klassischen Goldstandard"' wurde dieses System etabliert. Es folgt dem "`Price-Specie-Flow"'-Mechanismus (vgl. Kapitel \ref{Klassik}): Werden Güter aus Land A exportiert, wird gleichzeitig Kapitel - und damit indirekt Gold - importiert. Die Warenmenge fällt durch den Export, die Geldmenge steigt. Im Importland B geschieht aber genau das Gegenteil hier gibt es nach dem Import mehr Güter aber weniger Gold. In diesem einfachen Modell sorgen die Marktkräfte dafür, dass ein Außenhandelsgleichgewicht entsteht. Durch unterschiedliche Zinssätze in verschiedenen Staaten konnte dieses Gleichgewicht gestört werden. Hier kommen die Zentralbanken ins Spiel: Diese müssen international abgestimmt ihre Zinssätze so anpassen, dass das Gleichgewicht beibehalten wird. Als führende Zentralbank gab hierbei die "`Bank of England"' den Ton an. Die politischen Umwälzungen führten schließlich dazu, dass der Goldstandard mit Beginn des Ersten Weltkriegs aufgegeben wurde. Schon zuvor wurde übrigens aus dem "`reinen Goldstandard"' ein "`Proportionalsystem"'. Hierbei geht man davon aus, dass niemals gleichzeitig das ganze Geld gegen Gold eingetauscht wird und man druckt in weiterer Folge für eine bestimmte Goldmenge eine größere Geldmenge. Ein vorab festgelegtes Verhältnis darf dabei aber niemals überschritten werden. Nach dem Ersten Weltkrieg wurde der Goldstandard wieder eingeführt, allerdings wenig erfolgreich. Deutschland und Österreich litten ab Anfang der 1920er-Jahre an großen wirtschaftlichen Problemen, die in Hyperinflation mündeten. Der britische Pfund war überbewertet und die Bank of England hatte Mühe ihre Verpflichtungen aufrechtzuerhalten. In den USA wiederum war das Wirtschaftswachstum hoch und dauernde Exportüberschüsse wurden verzeichnet. Mit der Weltwirtschaftskrise ab 1929 erfuhr der Goldstandard seinen Tiefpunkt. \textcite{Friedman1963} wurde später dafür berühmt, gezeigt zu haben wie die Federal Reserve während der "`Great Depression"' zu lange auf den Goldstandard gesetzt hatte und damit die Schwere der Krise verstärkt hatte. Noch während des Zweiten Weltkriegs wurde 1944 im gleichnamigen "`Bretton Woods"' die Grundlage für eine neues, einheitliches Währungssystem geschaffen. Diesmal ist der US-Dollar die Leitwährung und praktisch alle Industriestaaten binden ihre Währung an jene der Amerikaner. Diesmal sind es die Inflationstendenzen des US-Dollar bei gleichzeitiger guter wirtschaftlicher Entwicklungen der europäischen Staaten, die dazu führen, dass das System in den 1970er Jahren aufgegeben werden muss.

Damit begann die Zeit der Zentralbanken und der Aufstieg der Bedeutung der Geldpolitik. Hier spielten viele Faktoren zusammen: Bei den Keynesianern steht die Fiskalpolitik im Vordergrund, Geldpolitik wird zwar als wichtig anerkannt, aber eher als Ergänzung im Zusammenspiel mit der Fiskalpolitik. Bereits Mitte der 1960er-Jahre veröffentlichten \textcite{Mundell1963} und \textcite{Fleming1962} ihr "`Impossible Trinity"'-Modell (vgl. Kapitel \ref{Supply-Side-Economics}). Darin beschreiben Sie, dass ein Staat grundsätzlich flexible Wechselkurse, freien Kapitalverkehr und aktive Geldpolitik betreiben möchte. Es sind aber stets nur zwei der drei Ziele miteinander vereinbar. Da der freie Kapitalverkehr in westlichen Demokratien unverhandelbar ist, muss eine Entscheidung zwischen den beiden anderen Zielen getroffen werden. Oder mit anderen Worten: Bis in die 1970er-Jahre waren die Zentralbanken an die Aufgabe gebunden fixe Wechselkurse aufrecht zu erhalten. Erst danach konnten andere wirtschaftspolitische Ziele ins Auge gefasst werden. Die 1970er-Jahre waren zudem die hohe Zeit der Monetaristen. \textcite{Friedman1968, Friedman1976b} wollte die Zentralbanken zwar zugunsten einer fixen Wachstumsrate des Geldes "`abschaffen"', aber er stellte auch die Bedeutung der Geldpolitik eindrucksvoll in den Vordergrund. Ähnliches gilt für die "`Neue Klassische Makroökonomie"', die grundsätzlich jegliche wirtschaftspolitischen Eingriffe als nutzlos erachtete. Dennoch lieferten die Arbeiten von zum Beispiel \textcite{Kydland1977, Barro1976} wichtige Beiträge, vor allem zur Organisation von Zentralbanken als \textit{unabhängige} Institutionen. Die Theorien der modernen Politischen Ökonomie, die ab den späten 1980er-Jahren an Bedeutung erlangten (vgl. Kapitel \ref{Pol_Econ}), untermauerten dies. Die "`Neue Neoklassische Synthese"' schließlich machte die Zentralbanken - wie erwähnt - zum zentralen Player der Wirtschaftspolitik. Zunächst in der Theorie: Wenn es die neu-keynesianischen Elemente "`Nominalen Rigiditäten"' und "`Monopolistische Konkurrenz"' in der Praxis gibt, dann ist Geldpolitik in der kurzen Frist eben doch nicht wirkungslos. Fiskalpolitik hingegen spielt in den DSGE-Modellen der "`Neuen Neoklassische Synthese"' hingegen keine Rolle.

Mit der Erkenntnis, dass Geldpolitik \textit{der} zentrale Hebel einer modernen makroökonomischen Steuerung ist, traten Geldpolitik und Zentralbanken Ende der 1980er-Jahre in das Zentrum der Forschung der "`Neuen Politischen Ökonomie"'. Die berühmten Arbeiten von \textcite{Friedman1968} vorgeschlagen und später \textcite{Kydland1977} schlugen vor, dass die Geldpolitik einer fixen Regel folgen sollte und gänzlich unabhängig von diskretionären Entscheidungen sein sollte. Mit dem allmählichen Niedergang der "`Neuen Klassik"' und dem Aufstieg des "`Neukeynesianismus"' wurde klar, dass Geldpolitik als wirtschaftspolitische Maßnahme in der kurzen Frist doch wirksam wäre und dementsprechend nicht vollständig einer geldpolitischen Regel überlassen werden konnte. Natürlich waren sich die Ökonomen aber auch bewusst, dass Geldpolitik in den Händen von Politikern auch zu Seigniorage führen konnte. Seigniorage, also die Verlockung durch das bloße Drucken von Geld den Staatshaushalt aufzubessern, führt regelmäßig und unweigerlich zu Hyperinflation. Ausgehend von \textcite{Alesina1988c} wurde das Thema der "`Unabhängigkeit von Zentralbanken"' der wohl bedeutendste Forschungsbereich innerhalb der modernen "`Neuen Politischen Ökonomie"'. Alberto Alesina prägte diese Forschung wie kein zweiter.

HIER WEITER \textcite[S. 549]{Snowdon2005}













In der Praxis war die Entwicklung etwas zeitverzögert, aber heute gibt es auch hier soetwas wie einen globalen Konsens der Geldpolitik. In den USA begann der Umbruch in der Geldpolitik 1979 mit der Bestellung von Paul Volcker zum Leiter der Fed. Er führte einen schmerzhaften aber erfolgreichen Disinflations-Kurs und schaffte es, durch harte restriktive Geldpolitik, die hohe US-Inflation in den Griff zu bekommen. In der Greenspan-Ära von 1987-2006 wurde die enorme Macht eines Notenbankchefs erstmals einer breiten Bevölkerung bewusst. Seine Reden und Aussagen wurden vor allem an den Finanzmärkten peinlichst genau analysiert. In der Ära Bernanke 2006-2014 und auch Yellen (2014-2018) trat eine deutliche Verwissenschaftlichung der Zentralbank hervor. In Kontinentaleuropa prägte stets die äußerst auf Stabilität pochende Deutsche Bundesbank die Geldpolitik. Vor allem im Europäischem Währungssystem (EWS) und später in der Phase vor der Euro-Einführung 1999, in der die Teilnahme-Länder die Stabilitätskriterien nach Maastricht einhalten mussten. Die europäischen Zentralbanken hatten vor allem in den frühen 1990er Jahren damit zu kämpfen, die festgelegten Wechselkurse aufrechtzuerhalten. Spekulanten identifizierten immer wieder Überbewertungen verschiedener Währungen gegenüber der harten Deutschen Mark. Berühmt wurde der Investor George Soros, der 1992 auf die Überbewertung des Britischen Pfunds setzte und bei dessen Abwertung schließlich eine hohe Summe gewann. In dieser Zeit waren die europäischen Zentralbanken also so etwas wie "`Spieler"' auf den internationalen Devisenmärkten. Mit der Einführung des Euros und der damit verbundenen Schaffung der Europäischen Zentralbank (EZB), entstand der heute zweitwichtigste geldpolitische Akteur nach der US-Notenbank Fed. Die EZB ist dahingehend interessant, weil sie als unabhängiges Institut gegründet wurde und zudem als Primärziel einzig die Geldwertstabilität - also explizit festgelegtes Inflation-Targeting - festgeschrieben hat (siehe weiter unten in diesem Kapitel \ref{Inflation}). Die Zentralbanken haben sich also auch in der zweiten Hälfte des 20. Jahrhunderts kräftig gewandelt: Bis in die 1970er-Jahre mussten sie im Rahmen des "`Bretton-Woods-Systems"' die Währungskurse stabil halten. Eine Aufgabe, die im wesentlichen von der Politik vorgegeben wurde. Bald danach begann der Versuch der Geldmengensteuerung im Sinne von Friedman. Bis schließlich das Anstreben einer Zielinflation in den Vordergrund rückte.







Ideologie, oder Opportunismus? Folgen: Rules rather than discretion? Unabhängige Zentralbanken und Schuldenbremse.

George Stigler: Regulierung.


Gesamtübersicht Finanzwissenschaft - Public Economy und Neue Politische Ökonomie (insbesondere Buchanan)
Einbauen den Kameralismus \parencite{Backhaus2005}

Moderne Themen, die aus diesem Bereich kommen: Ungleichheit, institutionelles Wachstum, Innovation, Fiskalpolitik und Austerität, Dani Rodrik, Aghion in einem anderen Kapitel (aktuelle Themen)









