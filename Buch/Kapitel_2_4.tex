%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Die Neoklassik neben Keynes}
\label{Neoklassik_nach1945}

Teil des Kapitels könnte auch Finanzierungstheorie, Spieltheorie sein (sind aber eigene Kapitel), aber auch die ganze Input-Output-Analyse.


\section{Pigou: Die Neoklassik erfindet sich neu}
\label{sec: Pigou}

Beginnend mit Arthur Cecil Pigou entwickelte sich die Neoklassik in eine neue Richtung. Wie in Kapitel \ref{Neoklassik} dargestellt, kann die Neoklassische Theorie mit Marshall in gewisser Hinsicht als abgeschlossen gelten. Dies vor allem in dem Hinblick, dass sich die mikroökonomischen Ausgangstheorien seit damals tatsächlich kaum noch geändert haben. Selbst in modernen Mikroökonomie-Büchern sind die ersten Kapitel im wesentlich identisch in den Arbeiten Marshall's zu finden. Die Mikroökonomie wurde seither nicht mehr grundlegend verändert, in dem Sinne, dass zuvor geltende Konzepte über den Haufen geworfen wurden, sondern sie wurde seither immer wieder erweitert. Marshall's Principles sind nach wie vor richtig. Aber man kann sie eben nicht mehr als Erklärung aller wirtschaftlichen Tätigkeiten heranziehen, sondern gelten mittlerweile nur mehr für einen sehr speziellen Fall. Heute wissen wir, dass die damals angenommenen Voraussetzungen, wie vollkommene Märkte und perfekte Konkurrenz nicht die Regel, sondern die Ausnahme sind.

Arthur Cecil Pigou ist der letzte große Ökonom in der Reihe der englischen Vertreter der Klassik und Neoklassik in Cambridge. Nach Pigou entwickelte sich die Ökonomie dort in Richtung Keynesianismus weiter, wie wir im letzten Kapitel (vgl. Kapitel \ref{Keynes}) bereits gelesen haben. Pigou ist wohl einer der meist unterschätzten Ökonomen des 20. Jahrhunderts. Schließlich war er der erste Mainstream-Ökonom, der postulierte und auch anerkannte, dass rein marktwirtschaftliche Ergebnisse nicht immer effizient sein müssen. Er erkannte also bereits vor Keynes die Sinnhaftigkeit von Staatseingriffe in bestimmten Situationen, wenn auch deren Wirkung und Berechtigung von ganz anderer Art und Weise sind. Während Keynes die makroökonomische Wirtschaftspolitik begründete, tat Pigou dies für die mikroökonomische Wirtschaftspolitik. Seine daraus unter anderem resultierenden Thesen zu den verschiedenen Formen des Marktversagen sind heute - Stichwort Klimawandel - aktueller denn je, wie gleich konkretisiert werden wird. Pigou's Karriere begann dann auch wie die eines ganz großen: Er war der Lieblingsschüler Marshall's der damals unangefochtenen Lichtgestalt der englischen Ökonomie. Mit erst 30 Jahre wurde Pigou schließlich dessen Nachfolger an der Universität in Cambridge. Und bereits 1912 legte er das bedeutende Werk "Wealth and Welfare" (\parencite{Pigou1912}) auf, das in der Neuauflage von 1920 als "The Economics of Welfare" (\parencite{Pigou1920}) ein bis heute bedeutendes Werk darstellt. Diese Jahreszahlen legen nahe, dass Pigou eigentlich auch in Kapitel \ref{Neoklassik} gut aufgehoben wäre. Inhaltlich von Bedeutung wurde der Forschungsbereich, den Pigou damit eröffnete, aber erst nach 1945. 

Mit zwei wesentlichen Punkten hat Pigou in seinem Hauptwerk die Neoklassik revolutioniert. Erstens, hat er mit dem Credo aufgeräumt, das seit Adam Smith die Neoklassik prägte, nämlich, dass individuell-nutzenmaximierendes Verhalten auch für die gesamte Gesellschaft erstrebenswert sei und das optimale gesamtwirtschaftliche Ergebnis hervorbringt \parencite[S. 111]{Pigou1920}. Das hat enorme Auswirkungen. Damit verbunden ist nämlich die Notwendigkeit staatlicher Eingriffe, immer dann, wenn der Markt darin versagt eine optimale Allokation hervorzubringen. Das riesige Gebiet der mikroökonomischen Wirtschaftspolitik war damit geboren. Zweitens, wollte er einen formalen Ansatz zur Analyse des \textit{gesamt}wirtschaftlichen Nutzens etablieren - was die Begründung der Wohlfahrtsökonomie bedeutete. Diese wurde aber recht rasch als gescheitert betrachtet. Dazu aber später mehr, werfen wir zunächst einen Blick auf seine Ansätze zum ersten Punkt. Ausgangspunkt sind die Gleichgewichtstheorien in der Tradition von Walras (vgl. Kapitel \ref{Walras}). Darin wird davon ausgegangen, dass alle Märkte im Gleichgewicht sind. Damit wurde stets auch impliziert, dass die Märkte jeweils das \textit{optimale} Ergebnis liefern. \textcite{Pigou1920} zeigte nun systematisch Beispiele, in denen das nicht der Fall ist. Der Ausgangspunkt sind hier stets Externalitäten \parencite[S. 115]. Um diese systematisch zu analysieren führt er den Vergleich zwischen privaten und sozialen Grenzprodukten ein \parencite[S. 114]{Pigou1920}. Nur wenn die sozialen und privaten Grenzerträge übereinstimmen, ist die Marktlösung auch eine gesamtwirtschaftlich optimale Lösung. Weichen die sozialen Grenzerträge von den privaten ab, liegt ein externer Effekt vor. Der könnte zum Beispiel darin bestehen, dass der Produzent A bei der Herstellung seiner Güter Kosten auf die Allgemeinheit überträgt, für die er nicht aufkommen muss. Zum Beispiel könnte seine Fabrik das Umland verschmutzen ohne, dass er eine entsprechende Reinigungsgebühr entrichten muss. Diese sozialen Kosten trägt stattdessen die Bevölkerung. Als Resultat sind die privaten Kosten des Fabrikanten zu niedrig, was wiederum in einer zu hohen Produktion und zu niedrigen Preisen führt. Nur wenn der Staat eingreift und durch Steuern die sozialen Kosten wieder auf den Produzenten überträgt, ist das gesamtwirtschaftliche Ergebnis tatsächlich optimal. Damit begründete er die heute wieder so oft zitierte Pigou-Steuer. Überhaupt erlangte Pigou mit dem Aufkommen der Umweltproblematik eine enorme Bekanntheit in den letzten Jahren. Seine Arbeiten zu Marktversagen begründeten die mikroökonomische Wirtschaftspolitik. Allerdings muss man einschränkend sagen, dass in \textcite{Pigou1920} zwar bereits verschiedene Marktversagensformen wie natürliche Monopole \parencite[S. 240]{Pigou1920}, Informationsmängel \parencite[S. 131]{Pigou1920} und eben externe Effekte, allerdings werden die Probleme eher anhand von Beispielen und nicht systematisch-analytisch behandelt. Auch finden sich noch theoretische Fehler in seinen Abhandlungen, wie zum Beispiel der fehlende Unterschied zwischen technologischen und pekuniären negativen Effekten \parencite[S. 242]{Cansier1989}. Letztgenannte sind definiert als Kosten, die einem Unternehmen erwachsen, wenn ein Konkurrent ein identisches Gut zu besseren Preisen anbieten kann. In diesem Fall ist keine Korrektur durch staatliche Einriffe sinnvoll, weil die "Kosten" darin bestehen, dass die Gewinne eines Unternehmens reduziert werden, und eben keine gesamtwirtschaftlichen Kosten entstehen. Pigou war relativ stur diesen Fehler einzugestehen \parencite[S. 153]{Johnson1960}. Er betrachtete externe Effekte außerdem stets eindimensional. Schließlich gibt es grundsätzlich zwei verschiedene Möglichkeiten, wie externe Effekte internalisiert werden können. Entweder zahlt der Verursacher der Gesellschaft einen Ausgleich für den Schaden, oder aber die Gesellschaft zahlt umgekehrt dem Verursacher die Kosten zur Vermeidung des Schadens. Ronald Coase (vgl. Kapitel \ref{Neue Institut}) kritisierte Pigou später vehement für diese einseitige Darstellung \parencite[S. 243]{Cansier1989}.

Der zweite neuartige Punkt in \textcite{Pigou1920} erscheint zwar reizvoll, wurde aber fast umgehend formal widerlegt: Der Versuch Pigou's eine gesamtwirtschaftliche Nutzenbetrachtung durchzuführen. Pigou beschäftigte sich dabei zunächst ausführlich damit den Begriff des Volkseinkommens, bzw. des Sozialprodukts zu definieren. In weiterer Folge wollte eine Funktion für die gesamtwirtschaftliche Wohlfahrt ableiten. Diese sei abhängig von der Höhe, der Verteilung und der Stabilität des Sozialprodukts \parencite[S. 42]{Pigou1920}. Der Ansatz klingt natürlich zunächst vielversprechend: Wir wissen ja, dass das Vermögen alleine nur eingeschränkte Aussagen über die tatsächliche Wohlfahrt, also den erlebten Nutzen, zulässt. Es war \textit{die} zentrale Errungenschaft der Neoklassik das Wertparadoxon der Klassiker zu überwinden und den Nutzen in den Vordergrund von Maximierungsentscheidungen zu stellen. Verlockend ist es daher eine "gesamtwirtschaftliche" Wohlfahrtsfunktion anzustreben. Das Bruttoinlandsprodukt (Volkseinkommen) als aggregierte Wertschöpfung der Bevölkerung in einem Staat, sagt wenig über die Wohlfahrt aus. Man könnte stattdessen die einzelnen Vermögen der Individuen als Nutzenwerte ausdrücken und das Aggregat dieser Werte als "nationalen Gesamtnutzen" - oder eben Wohlfahrt - interpretieren. \textcite[S. 48]{Pigou1920} legte also die individuelle Grenznutzen-Theorie auf die Gesamtwirtschaft um: "Das Gesetz des abnehmenden Grenznutzens lehrt uns, dass ein steigendes Sozialprodukt nur zu einem unterproportionalen Wohlfahrtsgewinn führt." Aus der Annahme des abnehmenden Grenznutzens lässt sich laut \textcite[S. 53]{Pigou1920} außerdem ableiten, dass eine zusätzliche Geldeinheit einer armen Person mehr Nutzen stiftet, als einer reichen Person. Oder mit anderen Worten: Neben einem möglichst hohem Gesamt-Volkseinkommen erhöht auch eine möglichst gleiche Verteilung der Einkommen zu einer höheren gesamtwirtschaftlichen Wohlfahrt. Daher sollte der Staat auch dahingehend eingreifen und zum Beispiel durch progressive Besteuerung die Einkommenshöhe angleichen. Pigou missachtete dabei allerdings die wesentlichen Erkenntnisse seiner Vorgänger: Nutzen ist nicht kardinal, also in Geldeinheiten ausgedrückt, messbar. Stattdessen behilft man sich mit ordinalen Nutzenkonzepten wie in Kapitel \ref{Pareto} dargestellt. Es ist ein Irrtum zu glauben, Pigou wäre sich dessen nicht bewusst gewesen. Er wusste, dass interpersonelle Nutzenvergleiche formal-mathematisch nicht möglich sind. Aber er war auch pragmatisch genug um anzuerkennen, dass zum Beispiel bei unverändertem Sozialprodukt eine gleichmäßigere Einkommensverteilung gesamtwirtschaftlich einen positiven Wohlfahrtseffekt hat. Auch eine bewusst vereinfachend einheitliche Einkommens-Nutzenfunktion dachte Pigou zumindest an \parencite[S. 237]{Pigou1920}. Das Konzept von \textcite{Pareto1906} plädiert hingegen für eine die Unzulässigkeit von interpersonellen Nutzenvergleichen. Man kann eben gerade \textit{nicht} behaupten, dass eine arme Person durch eine zusätzliche Geldeinheit mehr Nutzen generiert als ein Millionär. Der Effekt von Umverteilungsmaßnahmen auf die Gesamtwohlfahrt ist damit in der Neoklassik in keinster Weise abbildbar. Stark kritisiert \parencite[S. 123]{Robbins1932} wurde Pigou für seine Idee der gesamtwirtschaftlichen Wohlfahrtsfunktion eben, weil die formale Unzulänglichkeit seines Konzepts schon seit dem Werk von \textcite{Pareto1906} bekannt war. Interessant ist der Ansatz von Pigou aus heutiger Sicht aber möglicherweise dennoch. Natürlich, formal-mathematisch ist es anerkannt, dass Nutzen nicht kardinal gemessen werden kann. Das stattdessen angewendete  Konzept von \textcite{Pareto1906}, bzw. der modernere Ansatz mittels Grenzrate der Substitution nach \textcite{Hicks1934b} ist eine elegante und in formaler Hinsicht höchst erfolgreiche Lösung. Diese führt aber eben auch dazu, dass Fragen der Einkommensverteilung in der Neoklassik einfach keinen Platz haben. Gerade solche Fragen sind in den letzten Jahren aber wieder vermehrt in den Vordergrund getreten.

Mit der Veröffentlichung von "Wealth and Welfare" und gerade einmal 43 Jahren war Pigou allerdings bereits auf den Zenit seiner Karriere angekommen. Denn sein eigener Assistent, ein uns bereits aus dem letzten Kapitel bekannter, gewisser John Maynard Keynes, revolutionierte kurze Zeit später die Ökonomie. Pigou nahm während dieser Revolution eine eher unglückliche Position ein. Er war einer jener Ökonomen, der an der fast magischen Strahlkraft von Keynes und dessen Werk fast zerbrach. Ähnlich ging es übrigens Joseph Schumpeter, Michal Kalecki und in gewissen Maße auch Friedrich Hayek. Ab den 1930er Jahren wendete sich Pigou nämlich von der Weiterentwicklung der "Wohlfahrtsökonomie" ab und stattdessen anderen Inhalten zu. Getrieben wurde er dazu natürlich von der "Great Depression", später aber auch vom Aufstieg Keynes'.  
Pigou könnte als das genau Gegenteil von Keynes beschrieben werden. Nach erschütternden Ereignissen als Sanitäter im Ersten Weltkrieg, wurde er zum exzentrischen Einzelgänger \parencite[S. 153]{Johnson1960}. Der lockere Bloomsbury-Group-Lebemann Keynes trat schon diesbezüglich ganz anders auf. Auch wird Pigou in seiner Position als Berater als Vertreter veralteter Ideen beschrieben, der unter anderem die Wiedereinführung des Goldstandards empfahl \parencite[S. 232]{Cansier1989}. Eine Idee, die Keynes als "barbarisches Relikt" ansah und nach 1918 auch nicht mehr wirklich erfolgreich implementiert werden konnte \parencite[S. 232]{Cansier1989}. Zwar haben wir soeben gelesen, dass Pigou staatliche Eingriffe als erster moderner Ökonom in vielen Situationen befürwortete, in Bezug auf die "Great Depression" schlug er aber keine konjunkturfördernden Maßnahmen vor. Im Gegenteil, die hohe Arbeitslosigkeit erklärte er typisch neoklassisch als Missmatch zwischen Angebot und Nachfrage auf dem Arbeitsmarkt \parencite[S. 232]{Cansier1989}. Seine neoklassische Analyse der Arbeitslosigkeit (\textcite{Pigou1933}: The Theory of Unemployment) kam zur Unzeit, am Höhepunkt der "Great Depression". Es war die erste umfassende neoklassische Beschäftigungstheorie, aber gerade während der Weltwirtschaftskrise waren diese Erklärungsmuster unpassend. So wurde das Werk schließlich der Angriffspunkt schlechthin für Keynes. Überhaupt war Pigou, als führender Vertreter der neoklassischen Schule in den 1930er Jahren, \textit{die} Zielscheibe von Keynes' Kritik in der "General Theory" \parencite[S. 154]{Johnson1960}. Sehr häufig liest man darin über die "falschen Schlussfolgerungen von Prof. Pigou". Dieser reagiert trotzig und damit genau falsch. Anstatt sich auf Keynes' Theorien genauer einzulassen und diese dann eingehend zu analysieren, verfasste \textcite{Pigou1936} eine giftige Kritik über die Art und Weise wie Keynes seine Ideen darstellte, ohne dabei wirklich auf inhaltliche Unklarheiten tiefer einzugehen. Erst später änderte Pigou seine Meinung und akzeptierte die bahnbrechenden Erkenntnisse von \textcite{Keynes1936} \parencite[S. 154]{Johnson1960}. Sein späteres Werk \textcite{Pigou1941}: "Employment and Equilibrium", zum Beispiel, beinhaltet schon die Anerkennung keynesianischer Ideen, aber auch abweichende Meinungen, wie zum Beispiel die später als "Pigou-Effekt" beschriebene positive Wirkung sinkender Preise. Im Widerspruch zu Keynes führen sinkende Preise demnach zu einer höheren Nachfrage, weil die Kaufkraft des Geldes durch Deflation steigt. Der Pigou-Effekt ist nach wie vor in vielen Lehrbüchern zu finden, seine positive Wirkung blieb aber eher Minderheitenmeinung.

Angriffe auf das zweite Standbein von \textcite{Pigou1920}, die Notwendigkeit von Staatseingriffen bei Marktversagen, kamen nach dem Zweiten Weltkrieg von Seiten der neu aufkommenden Politischen Ökonomie (vgl. Kapitel \ref{Pol_Econ}). Zuerst kritisierte Coase die einseitige Betrachtung Marktversagen können nur durch Staatseingriffe beseitigt werden. Seiner Meinung nach wären marktwirtschaftlichen Lösungen ebenso möglich. Weiters wurde erstmals das Problem des möglichen Staatsversagens aufgegriffen. Zwar wurde anerkannt, dass es Situationen gibt, in denen der Markt zu nicht-effizienter Allokation führen würde, allerdings wurde zunehmend angezweifelt, dass Staatsvertreter für eine bessere Allokation sorgen würden. Für das Problem der natürlichen Monopole wurde von \textcite{Baumol1982} das alternative Konzept der angreifbaren Märkte entwickelt.

Pigou ging dennoch als revolutionärer Ökonom in die Geschichte ein. Er erweiterte die rein marktwirtschaftliche Analyse der neoklassischen Theorie um Aspekte des Marktversagens und der gesamtwirtschaftlichen Wohlfahrt. Er brachte damit den Staat als wichtigen Player ins Spiel, ohne aber von den grundsätzlichen Ideen der Mikroökonomie abzugehen. \textcite{Pigou1920} stellt damit den Beginn der mikroökonomischen Wirtschaftspolitik dar.


\section{Die moderne Wohlfahrtsökonomie}
\label{Wohlfahrt}

Mit dem Kapitel der Wohlfahrtsökonomie betritt die Volkswirtschaftslehre ganz neuen Boden. Schon rein methodisch unterscheidet sich die Wohlfahrtsökonomie von der klassischen und neoklassischen Ökonomie: Sie ist eine normative Theorie \parencite[S. 77]{Scitovsky1941}. Während positivistische Theorien die ökonomischen Vorgänge beobachten und daraus Gesetzmäßigkeiten ableiten, sind sich normative Theorien ihres Einflusses auf die ökonomischen Vorgänge bewusst. Positivistische Theorien sind nicht wertend und können dafür stets objektiv validiert werden. Die Wohlfahrtstheorie hingegen akzeptiert, dass Ökonomen wirtschaftspolitische Empfehlungen abgeben um "die Welt zu verbessern", sie enthalten stets auch "Werturteile". Ihre Fragestellungen können streng genommen nur subjektiv bewertet werden. Zum Beispiel: Ist eine gleichmäßigere Einkommensverteilung gerechter und besser für eine Gesellschaft?  Schon alleine diese Subjektivität machte die Wohlfahrtsökonomie von Anfang an umstritten und zwar auf zwei Ebenen. Erstens, die inhaltliche Ebene. Auf die Fragen der Wohlfahrtsökonomie gibt es oftmals plausible gegenteilige Antworten. Diese können zudem nicht abschließend, zum Beispiel mit empirisch-statistischen Untersuchungen, geklärt werden. Zweitens, gibt es eine übergeordnete Ebene, die in den Bereich der Philosophie vordringt. Macht es überhaupt Sinn, Fragen der Wohlfahrt, die man eben nie abschließend objektiv klären kann, in der Ökonomie zu behandeln? Bis heute ist die Wohlfahrtsökonomie ein stark beforschter Zweig der Wirtschaftswissenschaften. Wegen der fehlenden Möglichkeit einer Validierung allerdings wird bis heute heftig diskutiert, ob ihre Ergebnisse rein wissenschaftliche betrachtet einen wertvollen Beitrag liefern. 

Auch die Platzierung der Wohlfahrtsökonomie ist weder einfach noch klar. Die Einordnung in dieses Überkapitel macht vor allem wegen ihrer Ursprünge Sinn, alternativ könnte man sie auch als "Social Choice Theory" (Sozialwahl-Theorie)\footnote{Die "`Social Choice Theory"' ist eine Teildisziplin der Wohlfahrtsökonomie.} gemeinsam mit der "Public Choice Theory" im Kapitel \ref{Pol_Econ} darstellen. Wohlfahrtsökonomie und Public Choice Theorie beziehen sich auf ähnliche Grundkonzepte. Die Wohlfahrtstheorie ist allerdings Teil der Mikroökonomie, während die Public Choice Theorie der Neuen Politischen Ökonomie zugeordnet wird und damit auch in Teil \ref{Teil: NPO und Inst} behandelt wird. 

Die Arbeiten von \textcite{Pareto1906} und vor allem \textcite{Pigou1920} gelten bis heute als die Ursprünge der Wohlfahrtstheorie. In Hinblick auf Pigou's "`The Economics of Welfare"' wurde dies bereits im letzten Kapitel \ref{sec: Pigou} dargelegt. Kommen wir noch einmal kurz darauf zurück: Durch die Kritik von \textcite{Robbins1932} an den notwendigen interpersonellen Nutzenvergleichen galt dessen Ansatz rasch als widerlegt. Das Nutzenkonzept von \textcite{Pareto1906} und \textcite{Hicks1934a} galt als formal überlegen. Dieses etablierte sich als Teil der neoklassischen Mainstream-Theorie: Das Pareto-Prinzip und die ordinale Nutzenmessung waren der Kern dieser "`Neuen Wohlfahrtsökonomie"'. Anerkannt war, erstens, dass Wohlfahrtsökonomie die Gesamtwohlfahrt einer Gesellschaft zu bewerten als Ziel hat. Es war aber eben, nach der einflussreichen, kritischen Arbeit von \textcite{Robbins1932}, zweitens, auch bereits klar, dass die \textit{Summe} der empfundenen Nutzen (Wohlfahrt) nicht geeignet sei die Gesamtwohlfahrt zu messen (vgl. zum Beispiel \textcite{Lange1942}) Die Wohlfahrtsökonomie wurde daher ab Ende der 1930er Jahre auf neue Beine gestellt. Damals wurden die heute noch angeführten zwei Hauptsätze der Wohlfahrtstheorie als solche ausformuliert:
\begin{itemize}
	\item Erstes Wohlfahrtstheorem: Auf einem vollkommenen Markt - also mit vollkommener Information, bei vollkommener Konkurrenz und ohne externe Effekte - sind Gleichgewichtslösungen Pareto-optimal. Pareto-optimal (bzw. Pareto-effizient) sind Marktlösungen dann, wenn keine Person besser gestellt werden kann, ohne dass eine einzige Person schlechter gestellt wird.
	\item Zweites Wohlfahrtstheorem: Jedes Pareto-Optimum kann durch Marktgleichgewicht realisiert werden. Das heißt für jedes Pareto-Optimum existiert eine Einkommensverteilung, bei der alle Haushalte und Unternehmen ihre Nutzen bzw. Gewinne maximieren.
\end{itemize}
Die erstmalige Formulierung der Wohlfahrtstheoreme in ihrer modernen Form kann heute nicht mehr eindeutig zugeordnet werden. Das erste Theorem folgt im Prinzip schon direkt aus \textcite{Pareto1906}. Die erste mathematische Beweisführung wird häufig \textcite{Lange1942} zugeschrieben. 

Zwei verschiedene Ansätze prägten die frühe Zeit der "`Neuen Wohlfahrtsökonomie"'.  Der erste wurde von \textcite{Bergson1938} formuliert, aber erst durch \textcite{Samuelson1947} bekannt gemacht. Ähnlich wie bei Pigou gibt es hier eine "Soziale Wohlfahrtsfunktion", die den gesamtgesellschaftlichen Nutzen abbildet. Allerdings besteht dies nicht aus der \textit{Summe} der individuellen Nutzenwerte, sondern aus einem Vektor, der alle individuellen Nutzenwerte \textit{enthält}. Die Optimierungsaufgabe besteht nun nicht darin die Summe der Nutzen zu maximieren - was ja an den nicht-vergleichbaren und nicht-kardinalen individuellen Nutzenwerten scheitert - sondern darin, den optimalen Vektor zu bestimmen. Ein Vektor mit Nutzenwerten dominiert einen anderen Vektor immer dann, wenn er das Pareto-Kriterium erfüllt. Also kein Nutzen-Wert darf schlechter sein als im Vergleichsvektor \parencite[S. 9]{Suzumura2016}. Damit lässt sich eine "`Soziale Wohlfahrtsfunktion"' finden, die keine interpersonellen Nutzenvergleiche notwendig macht. Diese Bergson-Samuelson Sozial-Wohlfahrtsfunktion wurde von der ökonomischen Forschung bald wieder weitgehend verworfen. Anwendungsprobleme und Widersprüche zum Unmöglichkeitstheorem, auf das wir in Kürze eingehen werden, waren dafür verantwortlich. Weitgehend durchgesetzt hat sich hingegen der Ansatz, der auf \textcite{Kaldor1939} und \textcite{Hicks1940} zurückgeht. Noch heute wird oftmals auf das "`Kaldor-Hicks-Kriterium"', oder sogenannte "`Kompensation-Tests"' verwiesen, wenn es darum geht eine Kosten-Nutzen-Analyse vor Realisation eines Projektes durchzuführen. Worum geht es darin? Nun, das Pareto-Kriterium ist sehr streng wenn es darum geht Wohlfahrtsveränderungen herbeizuführen, da ja \textit{keine einzige} Person auch nur eine kleine Verschlechterung erfahren darf. \textcite{Hicks1940} und \textcite{Kaldor1939} argumentieren nun, dass eine Pareto-Verbesserung auch dann eintritt, wenn zwar der Wohlfahrtsverbesserung von Person A eine Wohlfahrtsverringerung bei Person B entgegensteht, die Wohlfahrtsverbesserung bei A aber zu einem Teil abgeschöpft wird um damit die Wohlfahrtsverringerung bei B zu kompensieren. Auch an diesem Konzept gibt es Kritikpunkte \parencite{Baumol1946}. Der erste ist inhaltlicher Natur. Während \textcite{Pigou1920} noch explizit darauf achtete bei seiner Form der Wohlfahrtsökonomie auch eine ethische Komponente zu umfassen, fehlt dies in der "Neuen Wohlfahrtsökonomie" gänzlich. Für Pigou war es klar, dass bei sonst konstanter Wohlfahrt eine Änderung der Einkommensverteilung zugunsten armer Haushalte eine höhere Gesamtwohlfahrt impliziert. Das darf man beim Kaldor-Hicks-Kriterium nicht annehmen. Wessen Wohlfahrt verringert wird um Kompensation bei einem Geschädigten zu erreichen und ob diese Kompensation auch tatsächlich realisiert wird, ist nicht Teil der Überlegungen bei Kaldor und Hicks \parencite[S. 11]{Suzumura2016}. Der zweite Kritikpunkt war ein rein formal-logischer. \textcite{Scitovsky1941} zeigte anhand eines einfachen Beispiels, dass es Fälle gibt, bei denen die Rückabwicklung einer ursprünglich Wohlfahrts-steigernden Maßnahme ebenfalls zu einer Wohlfahrtssteigerung führt. Das Kaldor-Hicks-Kriterium ist dann inkonsistent bei der Bestimmung der Wohlfahrtseffekte ökonomischer Maßnahmen. Dieses Phänomen wurde als Scitovsky-Paradoxon bekannt \parencite[S. 12]{Suzumura2016}.

Anfang der 1950er Jahre wurde die Wohlfahrtstheorie von Kenneth Arrow mit dessen Unmöglichkeitstheorem um eine vollkommen neue Problematik erweitert. Seine Arbeit war übrigens auch ein Anstoß für die neue Forschungsrichtung der "`Neuen Politischen Ökonomie"' ("`Public Choice Theory"'), die in Kapitel \ref{Neue_Politik} behandelt wird. Konkret auf die Wohlfahrtsökonomie angewendet in \textcite[S. 329]{Arrow1950} und wenig später in seinem bahnbrechendem Werk \parencite{Arrow1951} dargestellt, zeigt Arrow auf, dass rationales Wahlverhalten zur Unmöglichkeit konsistenter demokratischer Entscheidungen führt. Dieses Problem wurde schon von \textcite{Condorcet1785} erkannt: Wenn drei Personen bei drei alternativen Abstimmungsmöglichkeiten A, B und C jeweils eine andere Reihenfolge wählen, so bevorzugt eine Mehrheit von zwei Personen A gegenüber B und B gegenüber C. Aber es findet sich auch eine Mehrheit, die C gegenüber A bevorzugt. \textcite{Arrow1950} beschreibt, dass nicht nur spezielle Probleme, wie das Scitovsky-Paradoxon beim Kaldor-Hicks-Kriterium, oder das Condorcet-Paradoxon bei der Bergson-Samuelson Sozial-Wohlfahrtsfunktion, Probleme bereiten. Stattdessen gibt es für jedes Entscheidungskriterium, das darauf basiert, die individuellen Präferenzen von Individuen aggregiert heranzuziehen um eine demokratische Lösung zu finden, Beispiele, die Inkonsistenzen aufweisen \parencite[S. 330]{Arrow1950}. Das sogenannten "`Arrow'sche Unmöglichkeitstheorem"' - und damit auch die "`Social Choice Theory"' im engeren Sinn\footnote{\textcite{Fleurbaey2021} schreiben richtigerweise, dass die Social Choice Theory bereits durch zwei Journalbeiträge von Duncan Black im Jahr 1948 (\textcite{Black1948a} und \textcite{Black1948b}) begründet wurden. Darin werden Mehrheitsregeln und spezielle Mehrheitsregeln formal-logisch untersucht \parencite{Fleurbaey2021}.} - waren geboren. \textcite{Arrow1950} argumentiert damit, das nicht nur kardinale Nutzenmessung unmöglich ist, sondern auch ordinale Nutzenmessung - wie in der "Neuen Wohlfahrtsökonomie" angewendet - zumindest problematisch ist. Was hat es mit dem Unmöglichkeitstheorem auf sich? \textcite{Arrow1950} erstellt darin ein logisches System mit fünf Bedingungen. Diese beinhalten rein logische Statements, aber auch die Bedingung, dass die Individuen in einer Gesellschaft rational handeln, sowie frei über ihre Präferenzen entscheiden dürfen. Weiterhin gelten die Wohlfahrtstheoreme, also das Pareto-Prinzip, sowie, dass  interpersonelle Nutzenvergleiche nicht sinnvoll möglich sind. Die Aufgabe besteht nun darin eine Soziale Wohlfahrtsfunktion aus den Präferenzen der Individuen abzuleiten, die zudem die fünf genannten Bedingungen erfüllt \parencite[S. 339]{Arrow1950}. Mit einer konsequenten Beweisführung zeigt \textcite[S. 339ff]{Arrow1950}, dass demokratisches Abstimmungsverhalten zu keiner konsistenten "Sozialen Wohlfahrtsfunktion" führen wird. So eine Funktion muss entweder als gegeben angenommen werden, oder aber eine Autorität, also ein Diktator, übernimmt die Präferenzordnung für alle Individuen einer Gesellschaft. Zusammengefasst: Man kann aus individuellen Präferenzen keine Soziale Wohlfahrtsfunktion ableiten. Man kann damit in einer Demokratie keine gesamt-gesellschaftliche Nutzenmaximierung durchführen. Oder mit anderen Worten: Innerhalb des Konzepts der neoklassischen Mikroökonomie lässt sich keine befriedigende Wohlfahrtsökonomie etablieren. Tatsächlich schien die Wohlfahrtsökonomie in der Folge in einer Sackgasse. Und was deren weitere Entwicklung innerhalb der Mainstream-Ökonomie angeht, muss man das wohl auch bestätigten. 

Zwar gab es weiterhin verschiedenste Ansätze zur Wohlfahrtsökonomie, diese im Detail zu analysieren wäre hier jedoch nicht zielführend. \textcite{Fleurbaey2021} folgend sei aber erwähnt, dass es einen starken Zweig in Richtung Spieltheorie gibt. Wie schon erwähnt, sind wohlfahrtstheoretische Überlegungen mit Ansätzen der Neuen Politischen Ökonomie verwandt. Aber auch in den Gebieten Logik und "`Computergestützte Sozialwahl"' gibt es abgeleitete Forschungszweige. Alternativ dazu gibt es auch Ansätze, die vom Inhalt her mit der Wohlfahrtstheorie in Verbindung gebracht werden, allerdings klar im Bereich der Heterodoxen Ökonomie anzusiedeln sind. Erwähnenswert ist hier die Glücksforschung, die seit den 1950er Jahren vor allem von \textcite{Easterlin1974} durchgeführt wurde. Auf Basis von Umfragen wird versucht zu erheben, was in Menschen tatsächlich Glücksgefühle auslöst. Wohlfahrt wird nicht mehr ausschließlich anhand des Sozialprodukts gemessen. Diese Ansätze unterscheiden sich fundamental von den davor dargestellten. Zum einen sind diese interdisziplinär, eine Mischung aus Ökonomie, Psychologie und Verhaltenswissenschaften. Zum anderen sind die Ansätze empirisch getrieben und verzichten auf die neoklassischen Modellannahmen, wie zum Beispiel die Annahme von Rationalität. Als modernen Ansatz zur Wohlfahrtsökonomie könnte man auch die Neuroökonomie ansehen. Mit bildgebenden Verfahren werden hier Vorgänge im Gehirn hinsichtlich sozialer Präferenzen und bei ökonomischen Entscheidungen gemessen. Dieser Forschungsbereich wird der Verhaltensökonomie zugezählt. Möglicherweise bietet der Ansatz in Zukunft aber die Unmöglichkeit das Problem der interpersonellen Nutzenvergleiche zu überwinden. Dieser Zweig der Wissenschaft publizierte zuletzt sehr erfolgreich in hoch angesehenen Journalen \parencite{Fehr2000, Fehr2003}.

Als historisch bedeutendste Weiterentwicklung, aber auch klare Neuorientierung der Wohlfahrtsökonomie, müssen die Arbeiten von Amartya Sen genannt werden. Neben dem extrem einflussreichen Werk des Polit-Philosophen \textcite{Rawls1971}: "`A Theory of Justice"',  führte vor allem Sen die Wohlfahrtsökonomie in den 1970er Jahren auf neue Wege. Zunächst - Anfang der 1970er Jahre - in Richtung Erweiterung der "`Social Choice Theory"'. In einem kurzen Beitrag führt \textcite{Sen1970} das Pareto-Prinzip in gewissen Situationen ad absurdum. Er führt dazu das Entscheidungskriterium des "`Liberalismus"' ein. Er selbst gibt zu, dass der Name etwas unglücklich gewählt ist. Es geht hierbei einfach darum, dass es Entscheidungen gibt, die nur auf eine Person, nämlich den Entscheider selbst, Auswirkungen hat. Am Beispiel des Buches "`Lady Chatterley's Lover"' - einer der ersten Erotik-Romane, der 1928 erschien und in vielen Ländern zensiert wurde - zeigt \textcite{Sen1970}, dass eine individuelle Präferenzordnung im Sinne des ordinalen Nutzenprinzips, das Pareto-Prinzip und das von Sen eingeführte liberale Prinzip nicht miteinander vereinbar sind. \textcite{Sen1970} wollte damit vor allem die Unzulänglichkeiten des Pareto-Prinzips als ökonomisches Entscheidungsprinzip aufzeigen. 
\textcite{Sen1970b} weichte in weiterer Folge die seit \textcite{Robbins1932} uneingeschränkt geltende Unzulässigkeit von interpersonellen Nutzenvergleichen auf. Dabei ging er streng formal-mathematisch vor. Insgesamt vertrat er den Standpunkt, dass interpersonelle Nutzenvergleiche in gewissem Ausmaß durchaus realistisch sind. "`Wir sollten keine großen Zweifel daran haben, dass Kaiser Nero's Nutzen von der Feuerbrunst in Rom kleiner war, als die Summe der Nutzenverluste aller anderen Römer"', meinte in seiner Rede anlässlich der Verleihung des Nobelpreises 1998 \parencite[S. 356]{Sen1999}. Sen hatte wenig Berührungsängste mit philosophischen Ansätzen. Er vertritt den Standpunkt, dass Wohlfahrtsökonomie auch ganz bewusst ethische Fragen behandeln darf. Dementsprechend entdeckte er Verteilungsfragen und Fragen der Armut für die Wohlfahrtsökonomie wieder. Durch viele Publikationen in hochwertigen Journalen und natürlich nicht zuletzt durch die Vergabe des Nobelpreises an Sen im Jahr 1998 erlangte die Wohlfahrtsökonomie in der öffentlichen Wahrnehmung wieder an Bedeutung. Allerdings entfernte sich die Wohlfahrtsökonomie damit immer stärker von der Mainstream-Ökonomie. Derzeit spielt die Wohlfahrtsökonomie innerhalb der Mainstream-Forschung maximal eine Nebenrolle, wie \textcite{Atkinson2011, Atkinson2001} kritisierte. Sen schuf aber vor allem auch Verbindungen zu den Arbeiten zur Einkommensverteilung von Anthony Atkinson (vgl. Kapitel \ref{Ungleichheit}) und zu den Arbeiten zur Armut von Angus Deaton (vgl. Kapitel \ref{Armut}). Man kann diese Bereiche als Weiterentwicklung der Wohlfahrtstheorie sehen, so gesehen gewinnt diese Disziplin in letzter Zeit wieder an Bedeutung.


\section{Bäume, die in den Himmel wachsen: Die Neoklassische Wachstumstheorie}

Die Wachstumstheorie ist eine \textit{der} zentralen Disziplinen innerhalb der Ökonomie. Der Kern dieses Kapitels beschäftigt sich großteils mit dem historisch gesehen bedeutendsten Modell-theoretischem Erklärungsansatz: Der Exogenen Wachstumstheorie, häufig auch schlicht neoklassische Wachstumstheorie genannt. Diese entstand in den 1950er Jahren und wird bis heute in den meisten Lehrbüchern als Mainstream-Modell dargestellt. Auch wenn ihr die Endogenen Wachstumsmodelle diesen Rang in den letzten Jahrzehnten zunehmend ablaufen. 

Bevor wir uns den theoretischen Modellen zuwenden, gehen wir aber kurz fundamentaler auf das Phänomen Wirtschaftswachstum ein. Mehr als andere ökonomische Disziplinen beschäftigt es Ökonomen aus verschiedensten Richtungen. Tatsächlich ist die Geschichte der modernen Ökonomie - wenn man diese mit Adam Smith beginnen lässt - eine Geschichte des Wirtschaftswachstums. Seit der industriellen Revolution, die eben auch grob zusammenfällt mit der Publikation der "`Wealth of Nations"' in der zweite Hälfte des 18. Jahrhunderts, erlebt die wirtschaftliche Entwicklung auf einen beispiellosen Aufwärtstrend. Natürlich unterbrochen durch Wirtschaftskrisen, Kriege, Revolutionen und auch Seuchen. In keiner geschichtlichen Epoche davor konnte eine vergleichbare Entwicklung beobachtet werden. Ebenso interessant ist die Tatsache, dass der wirtschaftliche Aufstieg nicht gleichmäßig über den gesamten Globus erfolgte, sondern stattdessen einzelne Staaten und Wirtschaftsblöcke einen enormen Aufschwung erlebten, während dieser in anderen Teile der Erde bis heute ausblieb. Diese Thematik ist durchaus viel beforscht. Hier können die verschiedenen Erklärungsansätze dazu nur kurz angestreift werden: Bekannt sind die "`Fünf Stadien der Entwicklung"' - von der Tauschgesellschaft zum Massenkonsum - des insgesamt recht umstrittenen Politikers und Ökonomen \textcite{Rostow1960}. Der Wirtschaftshistoriker \textcite{Gerschenkron1962} nennt ebenso einen "`Modernisierungsanstoß"' als notwendigen Auslöser für einen dann folgenden großen Entwicklungssprung. Zwar wahrten die beiden Autoren eine kritische Distanz zueinander, ihre Arbeiten werden dennoch unter dem Begriff "`Modernisierungstheorie"` zusammengefasst. Im Gegensatz dazu entwickelte ab 1949 vor allem der Argentinier Raul Prebisch die "`Dependenztheorie"', die davon ausgeht, dass die Rückständigkeit der "`Peripherie-Länder"' durch deren Abhängigkeit von den Industriestaaten ("`Zentrum"') zustande kommt. Einflussreich schlug in dieselbe Kerbe die "`Welt-System-Theorie"' von \textcite{Wallerstein1974}. 

Die sogenannte "`Great Divergence"', also das Auseinanderdriften der Entwicklungsstadien in verschiedenen Staaten oder Wirtschaftsblöcken, spielte schließlich auch eine Rolle in der Evolution der Modell-theoretischem Erklärungsansätze, die wir in weiterer Folge im Detail betrachten. Das Solow-Modell postuliert eigentlich, dass es zu einer Angleichung des wirtschaftlichen Entwicklungsstandes verschiedener Länder kommen sollte. Allerdings ist dies eher nicht zu beobachten, was im "`Lucas Paradoxon"' formuliert wurde. Die Endogenen Wachstumstheorien (vgl. Kapite \ref{sec: endogene}) erklären die anhaltende Divergenz mittels unterschiedlichen Bildungsmöglichkeiten in unterschiedlichen Ländern. Einen anderen Ansatz verfolgt der "`Neue Institutionalismus"' von Daren Acemoglu (\ref{sec: Neue Inst}), der die Bedeutung von funktionierenden Institutionen als Voraussetzung für Wirtschaftswachstum hervorhebt. 

Die Erklärung langfristigen Wachstums, ist mehr als die meisten anderen ökonomischen Teilbereiche, eine Disziplin der Wirtschaft\textit{geschichte}, wie \textcite{Baumol1986} beschreibt. Zur Analyse der langfristigen, wirtschaftlichen Entwicklung sind aber auch entsprechende Datensätze notwendig. Bekannt geworden sind in diesem Zusammenhang die Arbeiten von Angus Maddison \parencite{Maddison2010}, der bis an sein Lebensende der Aufgabe nachging historische BIP-Daten zu sammeln oder zu rekonstruieren. Das Projekt wird seit seinem Tod im Jahr 2010 von ehemaligen Kollegen weitergeführt \parencite{Maddison2023}.

Nach diesem kurzen Exkurs zum eigentlichen Inhalt des Kapitels: Wirtschaftswachstum aus Modell-theoretischer Sicht. Die Vorgeschichte der Wachstumstheorien ist lang und vielfältig. Die bedeutendsten Ökonomen verschiedenster Richtungen hatten sich allesamt auch mit Wachstumstheorien beschäftigt. So etwa Adam Smith, der optimistisch im Hinblick auf langfristiges Wachstum war. Was die Klassiker angeht, wird auch die pessimistische Prognose Malthus' bis heute häufig zitiert, obwohl sich diese bislang nicht bewahrheitet hat. Nicht zuletzt widmete sich auch Karl Marx Wachstumstheorien. Mit der marginalistischen Revolution verlagerte sich die ökonomische Forschung auf die mikroökonomische Ebene. Allgemeines Wirtschaftswachstum wurde damit nicht mehr explizit im Rahmen einer eigenen Theorie thematisiert, aber natürlich implizit zum Beispiel im Rahmen der Produktivitätstheorien. Insbesondere die Arbeiten von \textcite{Wicksteed1894} und \textcite{Wicksell1922} waren in dieser Ära wichtige Wegbereiter der modernen Wachstumstheorie, wie wir gleich sehen werden. Während der "`Great Depression"' und der hohen Zeit des frühen Keynesianismus dominierten Theorien zur Krisenerklärung. Zwar entstanden in dieser Zeit die wichtigen (Vorläufer-) Arbeiten zur Wachstumstheorie - insbesondere die Cobb-Douglas-Produktionsfunktion, sowie das Ramsey-Modell - die hohe Bedeutung, die diese bis heute genießen, wurde ihnen allerdings erst nach dem Zweiten Weltkrieg zuteil. Betrachten wir zunächst die Entwicklung der Produktionsfunktion.

\subsection{Die Cobb-Douglas-Produktionsfunktion} \label{sec: Cobb-Douglas-Produktionsfunktion}
Cobb-Douglas-Produktionsfunktionen sind noch heute in jeden Ökonomie-Studium omnipräsent. Sie scheinen eines jener Konzepte, die die Evolution der Ökonomie unbeschadet überstehen. Interessant ist hierbei, dass der Name \textit{Cobb-Douglas}-Produktionsfunktion dabei nicht auf die eigentlichen Entwickler des \textit{theoretischen} Konzepts zurückgeht. Paul H. Douglas war ein Ökonomie-Lehrender an verschiedenen US-amerikanischen Universitäten, der, abgesehen von den Arbeiten zur Produktionsfunktion, keine bedeutenden wirtschaftswissenschaftlichen Forschungsarbeiten hervorbrachte. Douglas war allerdings als Politiker erfolgreich und lange Zeit für die Demokratische Partei im US-Senat. In \textcite{Douglas1976} beschreibt er, wie er im Jahr 1927, eher zufällig, die so langlebige Produktionsfunktion entwickelte. Er erstellte und verglich Indexzahlen für die Anzahl der Arbeitnehmer, sowie Höhe des eingesetzten Kapitals für amerikanische Produktionsunternehmen über die Jahre 1899 bis 1922. Als er die Werte in logarithmischer Form ins Verhältnis zu einem Produktionsindex setzte, bemerkte er, dass der Abstand der drei Funktionen über die Zeit annähernd konstant blieb \parencite[S. 904]{Douglas1976}. Er zog den befreundeten Mathematiker Charles Cobb zurate, wie denn dieses Ergebnis zu interpretieren sei. Dieser schlug vor den empirischen Zusammenhang in eine Formel zu gießen:

$$P = b*L^k*^{1-k}$$

Die Produktion$P$ ergibt sich also aus den Faktoren Arbeit$L$ und Kapital$K$, die jeweils mit $k$ gewichtet wurden. Diese Formel ist eben bis heute als Cobb-Douglas-Produktionsfunktion weltweit bekannt. Die Gewichtung der Faktoren mit $k$ und $(1-k)$ bildet hierbei konstante Skalenerträge ab. Das heißt, wenn beide Produktionsfaktoren verdoppelt werden, verdoppelt sich auch der Output der Produktion$P$. Die Annahme konstanter Skalenerträge ist bis heute umstritten. Später gingen Cobb und Douglas dazu über die Exponenten der Faktoren unabhängig voneinander zu bestimmen, stellten aber empirisch fest, dass die Summe dieser Exponenten ohnehin jeweils ungefähr eins beträgt \parencite[S. 904]{Douglas1976}.

Ihre Erkenntnisse veröffentlichten die beiden 1928 im Journal of Political Economy als "`A Theory of Production"' \parencite{Cobb1928}. Das der darin empirisch gezeigte Zusammenhang bereits zuvor von \textcite{Wicksteed1894} und \textcite{Clark1899} in ähnlicher Form postuliert wurde, war den beiden bekannt und sie zitierten entsprechend auch deren Arbeiten \parencite[S. 151]{Cobb1928}. Die Beiträge von \textcite{Wicksell1922}, der die Theorie bereits um 1890 darstellte und heute als der \textit{eigentliche} Urheber der Produktionsfunktion gilt, waren den beiden hingegen nicht bekannt. Zu Beginn wurde die Arbeit wenig akzeptiert, auch weil empirische Daten weitgehend fehlten um deren Aussagekraft überhaupt zu verifizieren. Vor allem der erste Ökonomie-Nobelpreisträger und damals führende quantitative Ökonom Ragnar Frisch kritisierte die Theorie als weitgehend nutzlos und die Aussagen, aufgrund der dünnen Datenlage als nicht haltbar \parencite[S. 905]{Douglas1976}. Cobb und Douglas konnten mit weiteren empirischen Untersuchungen die Gültigkeit ihrer Produktionsfunktion unterlegen. Ihre bahnbrechende Bedeutung erlangte sie aber erst später - dann bereits unter dem Namen "`Cobb-Douglas-Produktionsfunktion"' - vor allem als Ausgangspunkt der neoklassischen Wachstumstheorie. Interessantere Nebenaspekt: Die Cobb-Doulgas-Produktionsfunktion wird seit ihrer Entwicklung sowohl in der Mikro- als auch in der Makroökonomie herangezogen. Deren Anwendung kann also praktisch als Vorläufer der später - in den 1970er Jahren - etablierten Mikrofundierung der Makroökonomie gesehen werden.

\subsection{Solow: Technischer Fortschritt als Wachstumsquelle} \label{sec: Solow-Modell}

HIER WEITER


Solow-Swan-Modell

Ausgangspunkt ist eine Produktionsfunktion, wie jene, die wir gerade in Kapitel \ref{sec: Cobb-Douglas-Produktionsfunktion} kennen gelernt haben.  Der Output – gesamtwirtschaftlich das BIP – wird durch verschiedene Inputs – standardmäßig in der Neoklassik Arbeit und Kapital – hervorgebracht. Der Output ergibt sich also aus eine Kombination der beiden Inputfaktoren, Ökonomen würden sagen: "`Der Output ist eine Funktion der Inputfaktoren"'. 
Folgende Überlegung macht recht schnell klar, warum man mit diesem einfachen Modell stetige Wachstumsraten nicht erklären kann: Angenommen der Output ist einfach eine Addition der beiden Inputfaktoren Arbeit und Kapital. Möchte ich den Output verdoppeln, so müsste ich \textit{beide} Inputfaktoren Arbeit und Kapital jeweils verdoppeln. Ökonomen sprechen hier von konstanten Skalenerträgen. 
Was passiert aber wenn nur einer der beiden Input-Faktoren steigen kann? Gesamtwirtschaftlich könnte man argumentieren, dass der Produktionsfaktor Arbeit durch die Bevölkerungszahl begrenzt ist. Wenn man dies in unserer Überlegung berücksichtigt, würden wir folglich nicht beide Inputfaktoren gleichzeitig erhöhen, sondern nur einen, nämlich Kapital. Erhöhen wir diesen Inputfaktor nun um eine Einheit und der andere Inputfaktor bleibt gleich, so steigt der Gesamtoutput zwar selbstverständlich an, allerdings pro zusätzlicher Einheit um einen immer geringeren Prozentsatz. Intuitiv ist das leicht verständlich: Erhöhe ich bei gleichbleibender Mitarbeiterzahl ständig das Kapital – zum Beispiel die Anzahl der Computer – dann wird der erste eingesetzte Computer einen hohen Zuwachs an Produktivität bringen. Mit jedem weiteren Computer wird die Produktivität zwar weiter steigen, allerdings mit immer geringerer Zuwachsrate. Wenn jeder Mitarbeiter mehr als einen Computer besitzt, wird der Produktivitätszuwachs verschwindend gering werden. Diesen Zusammenhang bezeichnen Ökonomen als „Abnehmenden Grenzertrag“.
Das würde aber bedeuten, dass bei ungefähr gleich bleibender Arbeitsbevölkerung – eine Annahme, die man zumindest für die mittlere Frist in Industriestaaten, bedenkenlos machen kann – die Wirtschaftsleistung stagnieren sollte. Geht man davon aus, dass der Kapitaleinsatz ständig steigt, wäre zwar stetiges Wachstum möglich, aber nur mit immer geringer werdenden Wachstumsraten \footnote{Ständig steigender Kapitaleinsatz wäre nur mit steigenden Sparquoten erklärbar. In einer Ökonomie ohne Außenhandel gilt ja, dass das Sparen der Haushalten den Investitionen der Firmen entspricht. Investitionen wiederum bedeuten einen Aufbau von Kapital. Spezielle Beobachtungen von Fällen von Wirtschaftswachstum werden tatsächlich darauf zurückgeführt, dass die Sparquoten gestiegen sind. So ist zum Beispiel die Ökonomie in der stalinistischen Sowjetunion tatsächlich beträchtlich gewachsen. Da man aber keine wesentlichen technologischen Vorsprünge des Landes in dieser Zeit ausmachen kann, vermutet man, dieses Wachstum sei eben alleine auf den Anstieg der Sparquote zurückzuführen.}. Langfristig würden die Zuwachsraten aber gegen Null tendieren, womit auch in diesem Fall die Wirtschaftsleistung stagniert.

Bisher haben wir aber eine Möglichkeit außer Acht gelassen: Nämlich, dass die eingesetzten Maschinen (hier als Synonym für Kapital verwendet) immer besser werden. Tatsächlich wird eine Arbeitskraft mit zwei Computern nicht wesentlich produktiver sein, als mit einem Computer. Sie könnte aber mit einem \textit{besseren} Computer wesentlich produktiver sein. Es könnte sich also nicht nur die \textit{Menge} des Kapitals verändern, sondern auch dessen \textit{Qualität}. Dies nennen wir „technischen Fortschritt“ \footnote{Technischer Fortschritt umfasst nicht nur die Weiterentwicklung bestehender Produkte zu „besseren“ Produkten, sondern auch die Einführung neuer Produkte}.
Berücksichtigt man diesen Umstand, kommt man zu dem Ergebnis, dass stetiges Wirtschaftswachstum nur dann möglich ist, wenn sich die eingesetzten Kapitalgüter – also zum Beispiel Maschinen, Computer, Transportmittel, Kommunikationsmittel – immer weiter verbessern.
Der Inhalt des „technischen Fortschritts“, also was sich wie verbessert – ist allerdings ist nicht Teil der Ökonomie. Die ersten Wachstumstheorien haben sich also damit abgefunden festzustellen, dass technischer Fortschritt für Wachstum notwendig ist, dieser selbst allerdings nicht durch ökonomisches Handeln beeinflusst werden kann. Der technische Fortschritt wurde also als „exogen“ betrachtet. Daher der Name „exogene Wachstumstheorie“.


Nachteil: Konnte Divergenz zwischen armen und reichen Ländern nicht erklären (Kontra-Argument: Mankiw, der das exogene Wachstumsmodell noch befürwortet.)


Leontieff: Input-Output-Analyse.



Vorläufer: Von-Neumann Growth-Theory: 
"`Über ein ökonomisches Gleichungssystem und eine Verallgemeinerung des Brouwerschen Fixpunktsatzes"',  1937, in K. Menger, editor, Ergebnisse eines mathematischen Kolloquiums, 1935-36. [English 1945 trans. as "A Model of General Economic Equilibrium", RES].






Ramsey–Cass–Koopmans Modell:
Das Ramsey–Cass–Koopmans Modell (RCK) ähnelt dem Solow-Modell stark, jedoch wird die Dynamik der Wirtschaftsaggregate durch Entscheidungen auf mikroökonomischer Ebene bestimmt. Das RCK-Modell unterscheidet sich vom Solow-Modell in einem entscheidenden Punkt, es ist mikrofundiert.



Zusammengefasst: Zuerst keynesianisches HArrod-Domar. Dann Solow-Swan. Dann lange nichts. Dann endogene Wachstumstheorie, aber mit Verteidiung der Solow-Modelle vor allem durch Mankiw. Außerdem neu: Acemoglu-Ansätze. 
In den 1970er Jahren schließlich Endogene Wachstumstheorien (vgl Kapitel). Paul Romer. Zuletzt Ansätze aus dem Neuen Institutionalsimus vor alle Acemoglu



\section{Die Welt im Arrow-Debreu-Gleichgewicht}
\label{Arrow-Debreu}
Ursprünglichste Form: Walras.
Vorarbeiten von Neumann (1937, siehe oben) und Leontieff. Danach: \textit{Ramsey-Cass-Koopmans!}

Arrow-Debreu:
Das Arrow-Debreu Gleichgewichtsmodell (auch: Arrow-Debreu-McKenzie-Modell) ist ein mikroökonomisches Modell der gesamten Volkswirtschaft. Es ist nach Gérard Debreu und Kenneth Arrow sowie Lionel W. McKenzie benannt, stellt eine Weiterentwicklung des von Léon Walras entwickelten walrasianischen Gleichgewichtsmodells dar und untersucht einen gesamtwirtschaftlichen Gleichgewichtszustand. 
Das Modell erweitert das allgemeine Gleichgewichtsmodell um unsichere Erwartungen und zustandsabhängige Größen und ist damit für die Finanzierungstheorie von großer Bedeutung. Es zeigt, dass es in einer Marktwirtschaft unter idealisierenden Bedingungen nicht möglich ist, jemanden besserzustellen, ohne jemand anderen schlechterzustellen. Kurz gesagt ist ein Marktgleichgewicht ein Pareto-Optimum. 















