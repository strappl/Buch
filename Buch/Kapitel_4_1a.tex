%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Public Economy: Der Staat als wirtschaftlicher Player} \label{cha: Marktversagen}

Die Mikroökonomie gilt seit Marshall (vgl. Kapitel \ref{Neoklassik}) als praktisch abgeschlossen. Dies gilt aber nur für die formale Betrachtung \textit{funktionierender} Märkte. Wie wir in Kapitel \ref{Neoklassik_nach1945} sahen, war es vor allem \textcite{Pigou1920} der zumindest die Tatsache aufwarf, dass viele Marktergebnisse gesamtwirtschaftlich nicht erwünscht sind. Mit dem Aufstieg des Keynesianismus in Form der Neoklassischen Synthese, bekam der Staat als Teilnehmer am wirtschaftlichen Leben eine allgemein enorm höhere Bedeutung. Inhaltlich hängen die Überlegungen von \textcite{Pigou1920} und den Vertretern der Neoklassischen Synthese gar nicht sehr eng miteinander zusammen: Schließlich betrachtet die makroökonomische, neoklassische Synthese ausschließlich wirtschaftliche Gesamtzusammenhänge und nicht Unzulänglichkeiten auf einzelnen Märkten. Es war eher die allgemeine Überzeugung nach 1945, dass der Staat auch eine wichtige Funktion im allgemeinen Wirtschaftsleben einnehmen sollte. Woher diese Überzeugung kam, ist umstritten. Möglicherweise spielte Roosevelt's New Deal eine entscheidende Rolle am wachsenden theoretischen Interesse an staatlichen Ausgaben. Vielleicht auch der Zweite Weltkrieg. Kriege kosten Geld und verschlingen hohe Kapazitäten der Produktion. Die wirtschaftliche Bedeutung der öffentlichen Hand steigt so gezwungenermaßen. Wahrscheinlicher ist aber, dass sich die Verbindung eher auf ideologischer Ebene findet: Die Vertreter der makroökonomischen, neoklassischen Synthese befürworteten einen wirtschaftspolitisch aktiven Staat. Diese ökonomische Schule war in den 1950er Jahren in der Volkswirtschaftslehre allgemein tonangebend. Dies sieht man auch daran, dass deren Vertreter eben nicht nur makroökonomische Werke verfassten, sondern auch in der Mikroökonomie bahnbrechende Arbeiten lieferten. Franco Modigliani, James Tobin und vor allem Paul Samuelson sind dafür die besten Beispiele. Gerade letztgenannter war es, der in den 1950er Jahren die Public Economy prägte. Später, in den 1970er-Jahren, war es die neue Generation der keynesianisch geprägten Ökonomen, welche die ersten bahnbrechenden Arbeiten in der mikroökonomischen Theorie des Marktversagens lieferten: Joseph Stiglitz und George Akerlof. Die beiden überzeugten Neu-Keynesianer werden auch im nächsten Kapitel (Kapitel \ref{cha: Neu Keynes}) eine bedeutende Rolle spielen.

Die hier behandelte Theorie der öffentlichen Wirtschaft ("`Public Economy"')\footnote{Vor allem im deutschen etablierten sich verschiedene Namen für diese Theorie. Häufig wird sie auch als "`Public Finance"' bzw. im Deutschen unscharf als "`Theorie der öffentlichen Güter"', "`Theorie der öffentlichen Finanzwirtschaft"' oder schlicht Finanzwissenschaft bezeichnet.} steht in enger Verbindung mit der Wohlfahrtstheorie (vgl. Kapitel \ref{Wohlfahrt}) und der Allgemeinen Gleichgewichtstheorie (vgl. Kapitel \ref{Arrow-Debreu}), indem sie dort beginnt, wo Wohlfahrtstheorie oder allgemeine Gleichgewichtstheorie aufhören zu funktionieren. Es ist weitgehend unstrittig, dass es Märkte gibt, auf denen der erste Hauptsatz der Wohlfahrtstheorie - Individuell-nutzenmaximierendes Tauschverhalten führt zu einer effizienten Güterverteilung - und/oder der zweite Hauptsatz der Wohlfahrtstheorie - für jedes Pareto-Optimum existiert eine Einkommensverteilung, bei der alle Haushalte und Unternehmen ihre Nutzen bzw. Gewinne maximieren - nicht gelten. Wenn es solche Märkte gibt, scheitert auch die Allgemeine Gleichgewichtstheorie als alleiniges Instrument zur effizienten Güterverteilung.
Als Begründer der Theorie der öffentlichen Wirtschaft kann man Richard Musgrave und Paul Samuelson nennen. Bereits im Jahr 1939 hat Musgrave einen bahnbrechenden Artikel zur Theorie der öffentlichen Wirtschaft verfasst \parencite{Musgrave1939}. Er war es, der die oben angedeutete Verbindung zwischen makroökonomischen Fragestellungen und mikroökonomischen Ansätzen zur Analyse der öffentlichen Wirtschaft etablierte. Tatsächlich gab es nämlich in Kontinentaleuropa und hier insbesondere in deutscher Sprache eine recht umfangreiche Literatur zu "`öffentlichen Gütern"'. Diese nehmen eine entscheidende Bedeutung im Rahmen der Theorie der öffentlichen Wirtschaft ein. Tatsächlich hatte bereits der Vertreter der deutschen Historischen Schule (vgl. Kapitel \ref{Hist_Schulen}) \textcite{Wagner1892} öffentliche Güter definiert, als Güter bei denen keine Ausschließbarkeit, aber auch keine Rivalität beim Konsum vorliegen. So kann man zum Beispiel niemanden davon ausschließen die Sonne als Lichtquelle zu nutzen (Nicht-Ausschließbarkeit). Es schränkt aber auch niemanden in seiner eigenen Nutzung der Sonne ein, wenn jemand anderer die Sonne als Lichtquelle nutzt (Nicht-Rivalität). Vor allem aber der in Wien habiliterte Emil \textcite{Sax1887}, sowie die Schweden Erik \textcite{Lindhal1928} und - einmal mehr - Knut \textcite{Wicksell1896} lieferten bereits formal-quantitative Ansätze zur Analyse öffentlicher Güter im Sinne der neoklassischen Grenznutzenschule\footnote{Emil Sax, Erik Lindhal und Knut Wicksell wurden, neben William Bowen, übrigens auch von \textcite{Samuelson1954} als Vorläufer der Theory of Public Economy genannt. Deren Arbeiten waren Samuelson also durchaus bekannt.}. Vereinzelt werden die Arbeiten von Richard Musgrave daher auch als Verbindung aus der deutschen öffentlichen Finanzwissenschaft und der angel-sächsischen neoklassischen Theorie, sowie dem Keynesianismus interpretiert (\textcite[S. 13]{Sinn2007} und \textcite[S. 589]{Sturn2007}). Für diese Aufgabe war der Richard Abel Musgrave wie geboren. Schließlich wurde er in Deutschland geboren, studierte dort Volkswirtschaft, wanderte 1933 in die USA aus, wo er in Harvard sein Studium abschloss. Er hatte also sowohl den deutschen, als auch die amerikanischen Zugang zur Volkswirtschaftslehre aus erster Hand kennen gelernt.

Bekannt wurde der Musgrave's Ansatz die Aufgabe des Staates in drei Funktionen einzuteilen \parencite{Musgrave1956, Musgrave1959}: Allokation, Distribution und Stabilisierung. In Bezug auf die Allokation entwickelte \textcite{Musgrave1956} den Begriff der "`Meritorischen Güter"'. Das sind Güter, die rein privatwirtschaftlich organisiert nicht in dem Ausmaß produziert werden würden, wie gesamtwirtschaftlich erwünscht. Der Staat muss also die Produktion solcher Güter und Dienstleistungen selbst vornehmen oder vorschreiben, da es ansonsten zu Unterproduktion derselben käme. Ein Beispiel hierfür ist die Schulpflicht. Bildung ist seit jeher eine zentrale Quelle wirtschaftlichen Wachstums und daher für eine Gesamtwirtschaft von hoher Bedeutung. Gerade beim Fehlen sozialer Absicherung war es Eltern aber oft wichtiger, dass die Kinder statt in die Schule zu gehen, Geld verdienen. Die Aufgabe des Staates im Hinblick auf Distribution, also die Verteilung der Einkommen, ist heute aktueller und umstrittener denn je, geriet doch die Frage der personellen Einkommensverteilung in den letzten Jahren wieder zunehmend in den Fokus der Wirtschaftswissenschaften. Die Aufgabe der makroökonomischen Stabilisierung war zunächst recht unumstritten, mit dem Aufstieg der Neuen Klassik (vgl. Kapitel \ref{Neue Makro}) geriet auch diese Funktion des Staates in die Kritik. Wie später noch dargestellt wird, trat die "`Neue Politische Ökonomie"' ab den 1960er Jahren in direkte Konkurrenz zur hier dargestellten "`Public Economy"'. Obwohl beide Schulen die Bedeutung des Staates analysierten, kamen ihrer Vertreter regelmäßig zu geradezu konträren Forschungsergebnissen. Die lebhafte Diskussion zweier Hauptvertreter der beiden Schulen, nämlich eben Richard Musgrave auf der einen Seite und James Buchanan auf der anderen Seite im Rahmen der - über den in Kapitel \ref{Pol_Econ} noch ausführlich geschrieben werden wird - mündete schließlich im Werk \textcite{Musgrave1999}: "`Public Finance and Public Choice: Two Contrasting Visions of the State"'.

Breit gefasst behandelt die "`Public Economy"' enorm viele Themen, wie Besteuerung, Fiskalpolitik, öffentliche Verschuldung, Regulierung und Einkommensverteilung. Grundsätzlich könnte man darunter alle volkswirtschaftlichen Themen behandeln, in denen der Staat eine Rolle spielt. Hier beschränken wir uns auf einen Kernbereich der "`Public Economy"': Die Theorie des Marktversagens. Zunächst betrachten wir die Besonderheiten der "`Öffentlichen Güter"' (vgl. Kapitel \ref{Offentliche Guter}), die weiter oben schon kurz definiert wurden. Danach wird die Marktversagensform der Informationsasymmetrien behandelt. Also die Tatsache, dass Angebots- oder Nachfrageseite auf bestimmten Märkten in der Regel keine vollkommene Information über die Produkteigenschaften haben. Im darauf folgenden Unterkapitel (vgl. Kapitel \ref{Disease}) wird (auch) auf das Problem der Natürlichen Monopole eingegangen. Solche gibt es auf Märkten, auf denen es keinen Sinn macht, dass mehrere Anbieter auftreten. Die vierte typische Marktversagensforme "`Externe Effekte"' wurde in den Kapiteln \ref{sec: Pigou} und \ref{Pol_Econ} angeschnitten. Insgesamt spielt die Frage, ob das nicht perfekte Funktionieren von Märkten relevant für die Volkswirtschaftstheorie sein soll in der Ökonomie bis heute eine entscheidende Rolle und zwar interessanterweise sowohl in der Mikro- als auch in der Makroökonomie, wie in Kapitel \ref{micmac} dargestellt.


\section{Öffentliche Güter}
\label{Offentliche Guter}

Trotz seiner revolutionären Arbeiten ist der Name Richard Musgrave heute nur Ökonomie-Insidern ein Begriff. Mehr Resonanz erhielt Paul Samuelson, der mit der Veröffentlichung eines Artikel-Triple \parencite{Samuelson1954, Samuelson1955, Samuelson1958} Mitte der 1950er Jahre das Interesse auf dieses Thema lenkte. Er gilt damit als Mitbegründer der "`Theorie der öffentlichen Wirtschaft"' und etablierte sie als weitgehend normativen Theorie. Mit seinem nur dreiseitigen Journal-Artikel, entdeckte \textcite{Samuelson1954} die Theorie der "`öffentlichen Güter"' für die angelsächsische Mainstream-Ökonomie der 1950er-Jahre wieder.  \textcite[S. 387]{Samuelson1954} verweist durchaus gleich zu Beginn auf die deutschen Arbeiten von \textcite{Sax1887}, \textcite{Lindhal1928} und \textcite{Wicksell1896}. Auch die Definition von öffentlichen Gütern übernahm ist identisch mit jener, die schon die deutsche "`Finanzwissenschaft"' zur Jahrhundertwende hervorgebracht hatte: Nicht-Rivalität im Konsum  und Nicht-Ausschließbarkeit vom Konsum. Samuelson kannte also die Literatur und war sich bewusst, dass "`öffentliche Güter"' in Kontinentaleuropa schon zur Jahrhundertwende diskutiert wurden. Sein zentraler Verdienst bestand darin, dass er die Thematik vollends mit mikroökonomischen, neoklassischen und auch wohlfahrtstheoretischen Elementen analysierte und somit in der Mainstream-Ökonomie etablierten konnte. Im Bezug auf die wohlfahrtstheoretischen Elemente baute er direkt auf sein eigenes Konzept der "`Neuen Wohlfahrtstheorie"' und die darin entwickelte "`Bergson-Samuelson Sozial-Wohlfahrtsfunktion"' auf (vgl. Kapitel \ref{Wohlfahrt}). Entscheidend ist das formal-analytische Ergebnis, dass \textcite{Samuelson1954} hervorbringt: Es gibt bei öffentlichen Gütern keinen funktionierenden Preismechanismus, mit dem sich das Optimum bestimmen ließe, weil Individuen kein Interesse daran haben ihre wahren Präferenzen hinsichtlich der öffentlichen Güter mitzuteilen. Würden Entscheidungsträger die Präferenzen der Individuen abfragen und diese Individuen ihre Nachfrage wahrheitsgetreu kundtun, so könnten die Entscheidungsträger darauf aufbauend die Steuern so festsetzen, dass die Produktionskosten vollends gedeckt sind und die Nachfrage im Optimum befriedigt wird \parencite[S. 389]{Samuelson1954}. Allerdings werden die Individuen jeweils immer geringeres als tatsächlich vorhandenes Interesse an die Entscheidungsträger signalisieren. Durch die Nicht-Ausschließbarkeit vom Konsum, erhoffen sich die Individuen dadurch niedrige Steuern bei gleichzeitig voller Verfügbarkeit der öffentlichen Güter.


HIER WEITER


\section{Informationsasymmetrie}
\label{Info}

HIER WEITER:
\parencite{Sandmo1999}


Mit dem Aufstieg konservativer ökonomischer Theorien in den 1960er und 1970er Jahren war auch ein Ruf nach wachsender Deregulierung verbunden. Hayek und Friedman, die Ikonen des Liberalismus, plädierten für einen in allen Belangen freien Markt. Ihre Aussagen dazu waren nur zum Teil wissenschaftlich fundiert, zum anderen Teil sicherlich auch ideologisch motiviert. Genau in dieser Zeit publizierte George Akerlof sein berühmtes Paper, das meist abgekürzt "`Market for Lemons"' genannt wird \parencite{Akerlof1970}. Er begründete damit eine Reihe von Arbeiten in denen gezeigt wurde, dass unter bestimmten Umständen - auf scheinbar ganz normalen, also kompetitiven Märkten - kein befriedigendes Marktgleichgewicht zustande kommt. Dieses Marktversagen kann dann auftreten, wenn zwischen Angebots- und Nachfrageseite asymmetrische Information herrscht. Eine Marktseite ist also über die Marktbedingungen besser informiert, als die andere. Selbst wenn, abgesehen von Informationsasymmetrien, ein vollkommener Markt vorliegt, tritt dieses Problem in einer freien Marktwirtschaft auf. \textcite{Akerlof1970} beschrieb das Problem anhand des Gebrauchtautomarktes. Die Verkäufer gebrauchter Autos kennen den Zustand ihres Wagens in der Regel recht gut. Verkäufer von "`Montagsautos"'  also Autos, die regelmäßig technische Probleme aufweisen, werden die Schwachstellen ihrer mangelhaften Fahrzeuge - die im amerikanischen Englisch häufig "`Lemons"' genannt werden - gerne unerwähnt lassen. Käufer haben nur wenig Möglichkeiten die Qualität eines Gebrauchtwagens zu bewerten. Dies führt zum Problem der Adversen Selektion (negative Risikoauslese). Wenn Käufer nicht zwischen guten und schlechten Gebrauchtwagen unterscheiden können, werden diese zum gleichen Preis gehandelt. Es ist aber jeden klar, dass ein Gebrauchtwagen guter Qualität mehr Wert ist als einer schlechter Qualität. Die Anbieter guter Gebrauchtwagen werden keinen fairen Preis angeboten bekommen, weil sie die hohe Qualität ihres Autos nicht beweisen können. Käufer wiederum werden nur den fairen Preis eines schlechten Autos bereit sein zu bezahlen, da sie nur in diesem Fall sicher sein können, nicht über den Tisch gezogen zu werden. Gute Autos werden von schlechten verdrängt. Als Resultat werden am Gebrauchtwagenmarkt ausschließlich Autos schlechter Qualität gehandelt. Der Markt für gute Gebrauchtwagen bricht zusammen \parencite[S. 490]{Akerlof1970}. Unterteilt man den Markt nicht in gute und schlechte Autos, sondern in ein kontinuierlich verlaufendes Qualitätsspektrum, so werden  ausgezeichnete Autos von guten verdrängt, gute von mittleren und schließlich Autos mittlerer Qualität von schlechten Autos - bis der Gebrauchtwagenmarkt komplett zusammenbricht. Trotz eines grundsätzlich perfekten Wettbewerbsmarktes mit rationalen Teilnehmern, kommt kein Gleichgewicht zustande.

Das Standardbeispiel von Akerlof wurde weltberühmt, wenn es auch nicht das beste Beispiel ist für einen Markt mit asymmetrischer Information. Bei den meisten materiellen Gütern ist eine Qualitätsprüfung in einem gewissen Ausmaß durchaus möglich, so auch bei Gebrauchtwagen. Schon \textcite[S. 492]{Akerlof1970} selbst nannte als weitere Beispiele für adverse Selektion vor allem immaterielle Güter. Insbesondere auf Versicherungsmärkten ist das Problem einer negativen Risikoauslese immanent. Welchem Unfall- oder Gesundheitsrisiko eine Person ausgesetzt ist, ist eine höchstpersönliche Angelegenheit und von Versicherungen nicht so einfach festzustellen. In einem weiteren bahnbrechenden Paper zeigen \textcite{Stiglitz1976a}, dass es auf Versicherungsmärkten tatsächlich zu adversen Selektionsprozessen und in weiterer Folge zu Marktversagen kommen wird, wenn Versicherungen versuchen allen Versicherungsnehmern den gleichen Vertrag, mit der gleichen Risikoprämie, anzubieten. Personen mit hoher Schadeneintrittswahrscheinlichkeit (hohe Risiken) werden so einen Vertrag gerne unterzeichnen. Personen mit geringer Schadeneintrittswahrscheinlichkeit (niedrige Risiken) werden hingegen die Prämie als zu hoch einstufen und den Vertragsabschluss ablehnen. Die notwendige Subventionierung der hohen Risiken durch die niedrigen Risiken bleibt damit aus. Der adverse Selektionsprozess kommt in Gang und der Markt versagt auf gleiche Weise wie im oben genannten Gebrauchtwagen-Beispiel. Ein Markt-Gleichgewicht mit einem Vertrag für alle unterschiedlichen Risikogruppen - genannt Pooling-Gleichgewicht - wird also nicht zustande kommen. Versicherungen könnten aber versuchen unterschiedliche Verträge für unterschiedliche Risikogruppen anzubieten. Sportliche Autofahrer wählen einen Vollversicherungsschutz selbst dann noch, wenn die Prämie höher, also risikoadäquat, ist. Vorsichtige Wenigfahrer verzichten auf einen vollumfänglichen Risikoschutz und genießen dafür die niedrigere, aber ebenfalls risikoadäquate, Prämie. \textcite[S. 634ff]{Stiglitz1976a} zeigen, dass solche "`Separating-Gleichgewichte"' durchaus möglich sind. Die Versicherungsnehmer handeln hierbei nutzenmaximierend, filtern sich jedoch selbst in die für sie passenden Tarifklassen, was auch "`Screening"' genannt wird.

In der Realität gibt es auch auf Versicherungsmärkten viele Möglichkeiten, wie man die Qualität seiner Kunden feststellen kann. Traditionell in der Kraftfahrzeug-versicherung mit Bonus-Malus-Stufen. Verursachte Schäden führen zu höheren Prämien. In der privaten Krankenversicherung mit verpflichtenden ärztlichen Untersuchungen vor Vertragsabschluss. Modernere Ansätze ermöglichen es KfZ-Versicherungsnehmern ihren sicheren Fahrstil in Form von GPS-Daten zu beweisen und der Versicherung damit ein geringes Schadeneintrittsrisiko zu signalisieren. Im Gesundheitsbereich kann man einen gesunden Lebensstil mit Smartphone-Apps, die den Aktivitätsgrad messen, signalisieren und damit die Prämie senken. Allesamt Maßnahmen, die Informationsasymmetrien abbauen, allerdings vielleicht zum Preis der totalen Überwachung?!  
Im Bereich der allgemeinen Gesundheits- und Unfallversicherung ist das Thema der adversen Selektion nach wie vor brandaktuell. In Kontinentaleuropa ging man den Weg der staatlichen Pflichtversicherung aller Erwerbstätigen, die einen bestimmten Teil ihres Einkommens, als Sozialversicherung abgeben müssen und im Sinne eines Solidarbeitrags somit die medizinische Versorgung aller Bürger finanzieren. Im angelsächsischen Raum ist dies noch immer als "`sozialistisches Gedankengut"' verpönt, hier setzt man auf privatwirtschaftliche Lösungen. Im Fall der medizinischen Versorgung sieht es aber so aus als wäre der staatliche Eingriff von Vorteil. So haben die USA das teuerste Gesundheitssystem der Welt und dennoch ist ein beträchtlicher Teil der Bevölkerung unversichert nach wie vor unversichert.

Bereits \textcite{Spence1973} zeigte ein effizientes Mittel, um die Probleme der adversen Selektion zu lösen: Das Signaling. Als Anwendungsbeispiel wählte \textcite{Spence1973} den Arbeitsmarkt. Die Suche nach guten Arbeitnehmern ist schwierig. Nicht zuletzt deswegen weil ein Arbeitgeber weniger Information zur Produktivität hat als die potenziellen Arbeitnehmer selbst. Letztgenannte stehen als Bewerber in Konkurrenz zur Stelle, die der Arbeitgeber anbietet. Diese können versuchen dem Arbeitgeber zu signalisieren, dass sie die beste Wahl für die ausgeschriebene Stelle sind. Das benötigen sie entsprechende Mittel, genannt Signale. Je schwieriger (ökonomisch: je kostenintensiver) ein Signal zu erwerben ist, desto besser ist das Signal. Ein schwaches Signal wäre es zum Beispiel adäquat gekleidet und freundlich beim Vorstellungsgespräch aufzutreten. Allerdings sollten das zumindest einige Bewerber schaffen. Somit kann sich ein einzelner dadurch nicht von den anderen abheben, es liegt ein schwaches Signal vor. Wesentlich schwieriger - weil zeit- und damit kostenintensiv - ist es eine fundierte Ausbildung zu absolvieren. Eine vollwertige Ausbildung dauert mehrere Jahre in denen man schlecht bezahlt an einem starken Signal arbeitet. Dieses Signal, zum Beispiel in Form eines Abschlusszeugnisses, kann man dann verwenden um beim Bewerbungsgespräch die asymmetrische Information des potenziellen Arbeitgebers zu verringern \parencite{Spence1973}
Es bleibt allerdings auch hier die Frage nach der Regulierung. Denn der Arbeitgeber muss ein schwaches Signal von einem starken Signal unterscheiden können. Kann er das nicht wird das Problem nur um eine Stufe verlagert: Die adverse Selektion findet dann auf Ebene der Signale statt. In Kontinentaleuropa waren Ausbildungen unter anderem deshalb lange Zeit staatlichen Institutionen vorbehalten. Mit der Privatisierung von Bildungsinstitutionen treten diese in Konkurrenz zueinander. Es ist also kurzfristig individuell rational, zum Beispiel als Privatuniversität, ein eigentlich starkes Signal, zum Beispiel einen Master-Abschluss, für einen verhältnismäßig geringen Aufwand zu verleihen. Die Nachfrage nach diesem Bildungsprodukt - und damit der Gewinn der Hochschule - werden hoch sein. Erst langfristig werden die Arbeitgeber die mangelnde Qualität der Ausbildung, durch die geringere Produktivität der Arbeitnehmer, feststellen. Das Signal "`Master-Abschluss"' reicht dann nicht mehr aus, das Problem der asymmetrischen Information kann durch dieses Signal nicht mehr behoben werden.

Ein weiteres Anwendungsbeispiel der Probleme asymmetrischer Information, das ebenfalls den Arbeitsmarkt betrifft, wird in der Effizienzlohnhypothese (Adverse Selektion) und im "`Shirking"'-Modell (Moral Hazard) behandelt. Die Folgen sind makroökonomisch bedeutsam und werden daher in Unterkapitel \ref{RR_AM} behandelt.

Adverse Selektion beschreibt das Problem Asymmetrischer Information \textit{vor} Vertragsabschluss. Beim nun behandelten Problem des "`Moral Hazard"' (moralisches Risiko) tritt das Problem asymmetrischer Information erst \textit{nach} Vertragsabschluss auf. Das Problem, dass eine Person nach dem Abschluss einer Vereinbarung sein Verhalten ändert um sich besser zu stellen, ist jedem von uns seit Kindertagen bekannt. In den 1960er Jahren wurde dieses Verhalten allerdings erstmals ökonomisch analysiert \parencite{Arrow1963, Dickerson1963} und zwar am Beispiel medizinischer Versorgung: Je besser der Versicherungsschutz, desto umfangreicher waren die in Anspruch genommenen Leistungen. \textcite{Pauly1968} zeigte, dass nicht unmoralisches Verhalten der Auslöser für die Verhaltensänderung sein muss, sondern dass die Verhaltensänderung wirtschaftlich rationales Verhalten darstellen kann. Das ist nicht unwesentlich, da unmoralisches Verhalten - in Regeln formalisiert und in Gesetze gegossen - sanktioniert werden kann. Ökonomisch rationales Verhalten, das zu keinem stabilen Marktergebnis führt, ist hingegen Marktversagen. Vor allem im Versicherungsbereich ist dieses Problem wohlbekannt. Das Versicherungsunternehmen hat keine Möglichkeit sicher festzustellen, welches Ausmaß an Leistungen vom Versicherungsnehmer gerechtfertigt in Anspruch genommen werden darf und durch welche Verhaltensweisen der Versicherungsnehmer zusätzliche Versicherungsleistungen "`provoziert"'. Im Bereich der Versicherungen gibt es allerdings ein einfache Maßnahme, die Moral Hazard weitgehend einschränkt: Die Selbstbehalte. Wie Sie wahrscheinlich schon bei eigenen Versicherungsverträgen bemerkt haben, gibt es Selbstbehalte praktisch in jedem Versicherungsvertrag verankert, der hohen Versicherungsschutz umfasst.

Eine Ableitung aus dem Moral Hazard-Problem hat ist im Rahmen der "`Great Recession"', also der globalen Wirtschaftskrise nach 2008 in den Mittelpunkt öffentlicher Diskussion getreten: Das \textit{Principal Agent}-Problem. Dieses Problem zielt darauf ab, dass Eigentümer eines Unternehmens und dessen Manager unterschiedliche Ziele verfolgen. Die Aktionäre (="'Principals"'), also die Eigentümer, einer großen Bank haben das Ziel, dass das Unternehmen \textit{langfristig} seinen Wert maximiert. Die Manager (="'Agents"') haben hingegen befristete Verträge und damit Anreize \textit{kurzfristige} Gewinne zu erzielen, da diese die Höhe ihrer Prämie bestimmen. Die Aktionäre, als Arbeitgeber der Manager, sehen sich also dem Risiko ausgesetzt, dass die Manager nach Vertragsabschluss andere Ziele verfolgen, als ursprünglich vereinbart. Eine noch extremere Ausprägung resultiert im "`Too big to fail"'-Problem. Hier wird Managern vorgeworfen, bewusst sehr riskante Geschäfte einzugehen, weil sie im Wissen handeln, im Falle eines Defaults vom Staat finanziell unterstützt werden zu müssen, da andererseits systemweite Verwerfungen drohen. Dieses Problem ist eher dem "`Neuen Institutionalismus"' (Kapitel \ref{Neue Institut}) zuzuordnen und wurde erstmals von \textcite{Jensen1976} beschrieben. Ihre wissenschaftliche Abhandlung dazu erfuhr große Resonanz und gilt als einer der meist-zitierten Journalartikel in den Wirtschaftswissenschaften.


\section{Die Kostenkrankheit und angreifbare Märkte}
\label{Disease}
Ein extrem unkonventioneller Ökonom war William Baumol. Er lieferte bedeutende Beiträge in verschiedenen Disziplinen der Volkswirtschaft, sowohl in der Mikroökonomie als auch in der Makroökonomie. Es ist sympathisch, dass er ideologisch kaum einzuordnen ist, da er in so vielen grundverschiedenen Bereichen forschte. Er scheint sich nur der Wissenschaft verpflichtet gefühlt zu haben. Zwei wichtige Beiträge werden hier - in historisch umgekehrter Reihenfolge - dargestellt.

Eine in der praktischen Umsetzung unheimlich mächtige Idee ist Baumol's \textit{Theorie der angreifbaren Märkte}. Eine der vier zentralen Marktversagensformen ist jene der \textit{Natürlichen Monopole}. Ökonomen sprechen von einem natürlichen Monopol, wenn die Durchschnittskosten über den gesamten Mengenbereich über den Grenzkosten liegen. Anders ausgedrückt heißt das nichts anderes als, dass ein natürliches Monopol dann vorliegt, wenn die Fixkosten einen hohen Anteil der Gesamtkosten ausmachen. Dies ist überall dort der Fall wo eine große Infrastruktur geschaffen werden muss um das Produkt oder die Dienstleistung überhaupt anbieten zu können. Wenn die Infrastruktur aber einmal existiert, fallen nur mehr verhältnismäßig geringe Kosten für den laufenden Betrieb an. Beispielen dafür begegnen wir täglich. Das gesamte Verkehrsnetz, vor allem im Bereich der Eisenbahnen, ist ein Beispiel für ein natürliches Monopol. Aber auch das Strom- und Gasnetz, die Wasserversorgung oder das Kanalnetz, sowie das Telefonnetz und Postdienstleistungen sind Beispiele dafür. Stellen sie sich vor sie möchten als Privatunternehmen in den Eisenbahnverkehr einsteigen. Bevor sie auch nur eine Fahrt starten könnten, müssten sie Eisenbahnschienen verlegen. Ein eventuell bereits vorhandenes Schienennetz gehört schließlich nicht ihnen und sie können damit vom Gebrauch leicht ausgeschlossen werden. Jetzt ist es jedoch aus ökonomischen, aber auch aus raumplanerischen und nicht zuletzt ökologischen Gründen, völlig undenkbar, dass jeder potenzielle Anbieter sein eigenen Schienennetz erstellt. Ein einziges Schienennetz pro Strecke ist die einzig sinnvolle Lösung. Der Eigentümer dieses Schienennetzes ist per Definition ein Monopolist. Da er weder aus rechtlichen Gründen, noch aufgrund ökonomischer Überlegenheit zum Monopolisten wurde, sondern aufgrund der Eigenschaft Eigentümer der notwendigen Infrastruktur zu sein, nennt man so eine Situation ein \textit{Natürliches Monopol}. Aufmerksamen Lesern mag vielleicht aufgefallen sein, dass alle gerade oben genannten Dienstleistungen früher auch in den westlichen Marktwirtschaften fast ausschließlich von staatlichen Unternehmen angeboten wurden. Dass dies heute nur mehr zum Teil der Fall ist, ist nicht zuletzt auf die bahnbrechende Arbeit von \textcite{Baumol1982, Baumol1982b} zurückzuführen. Darin zeigen die Autoren die wesentliche Bedeutung von Markteintritts- und Marktaustrittsbeschränkungen.  Wenn man nun - eine zugegebenermaßen zunächst recht theoretisch wirkende Überlegung - diese Beschränkungen abschafft, so führt schon allein dies, laut \textcite{Baumol1982}, dazu, dass sich der bisherige Monopolist potenzieller Konkurrenz ausgesetzt sieht und in weiterer Folge seine Preissetzung nicht mehr wie ein Monopolist vornimmt, sondern wie ein Anbieter auf einem perfekten Konkurrenzmarkt. Alleine das Abschaffen von Markteintritts- und Marktaustrittsbeschränkungen führt also dazu, dass aus einem Monopolmarkt praktisch ein perfekter Konkurrenzmarkt wird \parencite[S. 2]{Baumol1982b}. Damit verbunden sind all die positiven Effekte: Niedrigerer Preis und höhere ausgebrachte Menge. Der Grund liegt einfach darin, dass die erhöhten Gewinnmöglichkeiten auf Monopolmärkten leicht erkannt und von Konkurrenten ausgenutzt werden können, wenn es keine Zugangsbeschränkungen gibt. Als Resultat verschwindet der Monopolvorteil aufgrund von Marktkräften und der Markt wird zum perfekten Konkurrenzmarkt. Der zweite Wohlfahrtseffekt ist ebenso bedeutend. Monopolmärkte tendieren dazu nicht ökonomisch effizient zu arbeiten. Wer der Chance hat eine Monopolrente abzuschöpfen und sich keinem Konkurrenzdruck ausgesetzt sieht, wird mit der Zeit immer weniger effizient arbeiten. Nach \textcite{Leibenstein1966} nennt man dieses Problem das Auftreten von \textit{X-Efficiency}. Wer früher einen Telefonanschluss haben wollte, musste diesen bei der staatlichen Behörde beantragen und war nicht selten deren Willkür und damit langen Wartezeiten ausgesetzt. Heute, am offen zugänglichen Telekommunikationsmarkt, wird man als potenzieller Kunde geradezu umgarnt von Anbietern\footnote{Das Beispiel hinkt zugegebenermaßen, weil im angesprochenen Bereich der technische Fortschritt wohl einen größeren Beitrag zur besseren Marktentwicklung beigetragen hat.}. 
Kommen wir zurück zum entscheidenden Punkt: Was sind Markteintritts- und Marktaustrittsbeschränkungen überhaupt? Gemeint sind damit Kosten, die ein Unternehmen leisten muss, bevor es überhaupt auf einem Markt als Anbieter auftreten kann. In einem natürlichen Monopol stellen diese Kosten also zum Beispiel die Herstellungskosten für das Schienennetz dar. Das Abschaffen dieser Markteintritts- und Marktaustrittsbeschränkungen bedeutet aber nicht, dass die Kosten auf Null reduziert werden, sondern, dass ein am Markteintritt interessiertes Unternehmen keinerlei Benachteiligungen haben darf gegenüber dem Monopolinhaber \parencite[S. 3f.]{Baumol1982b}. Ökonomisch ist das Thema mit dem Satz "`Abschaffen von Markteintritts- und Marktaustrittsbeschränkungen"' abgedeckt. Auf anderer - nämlich rechtlicher - Ebene wurde damit ein riesiges Feld geöffnet: Das Wettbewerbs- und Regulierungsrecht wurde damit wesentlich erweitert. Es muss nämlich ein Rahmen geschaffen werden, der den bisherigen Monopolisten und damit Inhaber der Infrastruktur dazu bringt, allen interessierten Mitbewerbern zu fairen Preisen Zutritt zum Markt zu gewähren. Dies funktioniert meist so, dass die Infrastruktur in ein eigenes staatliches Unternehmen ausgegliedert wird und eine neu geschaffenen Kontrollbehörde den Marktzutritt zu fairen Preisen zusichert. Auf sehr umkämpften Märkten, vor allem auf den mobilen Telekommunikationsmärkten, wurden in der Folge Lizenzen an die Höchstbieter vergeben, wobei die Vergabeverfahren ein eigenes Forschungsfeld aufmachten: Die sogenannten \textit{Auktionstheorie}, die vor allem durch spieltheoretische Überlegungen geprägt ist. In diesem Bereich wurde 2020 der Nobelpreis für Wirtschaftswissenschaften an \textit{Paul Milgrom} und \textit{Robert Wilson} vergeben. Ein anderes Forschungsfeld, das auch auf spieltheoretischen Überlegung basiert, ist jenes des sogenannten \textit{Marktdesigns}. Dabei geht es um die Gestaltung der Märkte, die ursprünglich natürliche Monopolmärkte waren. In diesem Bereich wurde bereits 2012 der Nobelpreis für Wirtschaftswissenschaften an \textit{Alvin Roth} und \textit{Lloyd Shapley} vergeben\footnote{Beide Themen werden im Kapitel \ref{cha: Spieltheorie} näher behandelt.}. Wie man sieht stieß das Konzept insgesamt einen riesigen Forschungsbereich an. Dahingehend ist es überraschend, dass William Baumol selbst niemals Nobelpreisträger wurde, obwohl er das hohe Alter von 95 Jahren erreichte. 

Insgesamt war das Modell theoretisch extrem einflussreich. Interessanterweise spielt es eher den polit-ökonomisch liberalen Tendenzen der 1980er Jahre in die Hände. Schließlich wird einer Form des Marktversagens nicht mehr durch staatliche Eingriffe entgegengetreten, sondern durch eine reine Marktlösung, gepaart mit gesetzlichen Vorgaben. Die Theorie passt damit eher zur \textit{Neuen Institutionsökonomik} (Kapitel \ref{Neue Institut}) oder sogar zur \textit{Neuen Klassischen Makroökonomie} (Kapitel \ref{Neue Makro}). Dabei ist Baumol zumindest letztgenannter Schule keineswegs zuzurechnen. Auch praktisch war die Umsetzung sofort ein Erfolgsmodell. Die Umsetzung erfolgte praktisch nahtlos an das Erscheinen des Buches \textcite{Baumol1982}. Vorreiter war Großbritannien, wo Margaret Thatcher noch in den 1980er Jahren Transportunternehmen privatisieren ließ. Anfang der 1990er Jahre erfolgte die große Privatisierungswelle in den westlichen Industriestaaten vor allem auf den Telekommunikationsmärkten, dem Eisenbahnwesen und der Versorgungsindustrie (vor allem Elektrizität). Aus heutiger Sich ist diese Umsetzung insgesamt wohl eine Erfolgsgeschichte. Vor allem wenn man auf sicherlich vorhandene X-Effizienzen in verkrusteten, staatlichen Unternehmen denkt. Mittlerweile kann man aber auch wesentliche Kritikpunkte nicht von der Hand weisen. So unterblieben in vielen Ländern, als Antwort auf die Liberalisierung, wichtige Investitionen in die Infrastruktur. Das traurigste Negativbeispiel ist wohl die Privatisierung der Eisenbahn in Großbritannien. Ende der 1990er-Jahre kam es dort zu zwei schweren Zugunglücken, die auf den schlechten Zustand der Infrastruktur und damit letztendlich auf die Liberalisierung des Eisenbahnverkehrs, zurückgeführt werden. Auch abgesehen davon funktionierte der private Eisenbahnmarkt in Großbritannien schlecht und so gibt es seit 2020 Tendenzen den Betrieb wieder gänzlich zu verstaatlichen. Es gibt aber auch den USA und in Kontinentaleuropa zahlreiche Negativbeispiel. Das Problem liegt hierbei häufig darin, dass die Umsetzung ganz wesentlich von der Schaffung eines rechtlichen Rahmenwerkes abhängt. Diese Regulierung zu schaffen ist schwierig und in der Praxis häufig gescheitert.

Einen weiteren, gänzlich anderen aber ebenso unkonventionellen, Beitrag zur Ökonomie lieferte \textit{William Baumol} bereits Mitte der 1960er Jahre \parencite{Baumol1965, Baumol1967}. Das exogene Wachstumsmodell von Robert Solow war schon als Standardmodell etabliert, als William Baumol einen interessanten Problempunkt darin aufzeigte. Er unterscheidet zwei Arten von Unternehmungen. Eine, die stark Technologie-getrieben ist und eine zweite, bei der Technologie nur eine untergeordnete Rolle spielt. Baumol selbst nannte diese "`stagnierenden Sektor"' und "`progressiven Sektor"' \parencite[S. XX]{Baumol2012}. Man könnte sie aber auch grob als Produktionsunternehmen und Dienstleistungsunternehmen bezeichnen. Entscheidend ist, dass erstgenannte vom technologischen Fortschritt profitieren. Mit besserer Technologie steigt die Produktivität in diesem Sektor an. Im zweitgenannten Sektor gibt es hingegen keine Produktivitätszugewinne durch verbesserte Technologie. Baumol's klassisches Beispiel dafür - er war ein bekennender Kunst- und Musikliebhaber \parencite[S. 228]{Krueger2001Interview} - war jenes vom Streichquartett, das für ein Musikstück heute noch immer so lange braucht wie vor 200 Jahren. Für die Herstellung eines Stahlträgers werden hingegen heute wesentlich weniger Arbeitsstunden benötigt, als im frühen 19. Jahrhundert. Daraus kann man ableiten, dass der Aufwand (und damit die Kosten) für ein Streichquartett gleich geblieben sind, während die Kosten für einen Stahlträger relativ dazu gesunken sind. Bei einer angenommenen Inflation von zum Beispiel 4\% würden Dienstleistungen dementsprechend eine höhere Inflation erfahren, als Produktionsgüter. Oder mit anderen Worten: Dienstleistungen wie medizinische Leistungen, Pflege und Ausbildung werden im Verhältnis zu Produktionsgütern wie Kleidung, Fernseher und Autos immer teurer. In der Ökonomie ist dieses Phänomen als die \textit{Kostenkrankheit}\footnote{Auch als \textit{Baumol's Disease} oder \textit{Bowen's curse} bezeichnet\parencite[S. 3]{Baumol2012}.} bekannt.
Die Folge der Kostenkrankheit ist, dass sich die Anteile an den Gesamtausgaben immer stärker von den Industriegütern zu den Dienstleistungen verschieben. Laut \textcite[S. 43]{Baumol2012} ist dies aber kein Problem. Wenn die Produktivität für einen Teil der geleisteten Arbeitsstunden steigt, für einen Teil konstant bleibt, aber für keinen Teil sinkt, dann steigt die Produktivität auch im Durchschnitt. Damit steigt insgesamt die Produktion und damit das GDP. Dass sich das Verhältnis zwischen Gütern und Dienstleistungen dadurch verschiebt und damit zum Beispiel der Anteil der Kosten für Gesundheitsdienstleistungen immer weiter steigt, ist zwar ein Faktum, aber im Endeffekt von sekundärer Bedeutung. Die Kostenkrankheit wäre demnach eher ein Verteilungsproblem als ein Problem stagnierender Produktivität. 

\textcite{Nordhaus2008} hat die möglichen Auswirkungen der Kostenkrankheit analysiert, zusammengefasst und empirisch untersucht. Er kam zu dem Schluss, dass sich die Baumolsche Kostenkrankheit in sechs Symptomen zeigt. Die Kosten und Preise müssten auf stagnierenden Märkten überdurchschnittlich stark steigen (1), der reale Output in diesen Sektoren sollte aber nur unterdurchschnittlich steigen (2). Wenn stagnierende Märkte Preis-unelastisch sind, dann müsste der Anteil dieser Märkte am Gesamt-BIP steigen (3), dies würde das Gesamtwachstum der Produktivität reduzieren (4). Unternehmen auf stagnierenden Märkten werden zunehmend Kosten- und Preisdruck ausgesetzt und schließlich vermehrt finanzielle Probleme haben (5). Zuletzt stellt sich die Frage, wie sich die Kostenkrankheit auf die Gesamtbeschäftigung auswirkt (6). \textcite{Nordhaus2008} kommt zu dem Ergebnis, dass für die USA seit 1948 die ersten drei Symptome eindeutig zu erkennen sind. Auch das Wachstum in der Produktivität hat sich seit 1948 verlangsamt. Interessanterweise könnte Nordhaus nicht bestätigen, dass vor allem Unternehmen in progressiven Sektoren vom technologischen Fortschritt profitieren und im Umkehrschluss Unternehmen im stagnierenden Sektor in Probleme geraten. Stattdessen werden die Vorteile, die in progressiven Sektoren beobachtet werden, tendenziell an den Endkunden weitergegeben. Das heißt Produkte im aus dem progressiven Sektor werden relativ gesehen immer günstiger. Der letzte Punkt ist nicht eindeutig zu beantworten. Es gibt Industrien, in denen technologischer Fortschritt zu einem Ersatz der Arbeitskräfte durch Maschinen führt. Eine relativ dazu steigende Anzahl an Personen ist dann in stagnierenden Sektoren tätig. Es gibt aber auch Industrien, wo der technologische Fortschritt zu einer steigenden Nachfrage nach Arbeitskräften führt \parencite{Nordhaus2008}.

Das Konzept hat damit übrigens auch spannende wirtschaftspolitische Auswirkungen. Da der Staat fast ausschließlich für die zur Verfügung-Stellung von Dienstleistungen zuständig ist, der private Sektor hingegen nach wie vor einen gehörigen Anteil an Produktionsunternehmen hat, müsste es dazu kommen, dass die staatlichen Leistungen im Verhältnis zu privatwirtschaftlichen Leistungen im Durchschnitt immer teurer werden. Das heißt, die Staatsquote müsste mit steigender Produktivität ebenfalls steigen, wenn die staatlichen Dienstleistungen in gleicher Qualität und Quantität aufrechterhalten werden sollen. Dies wäre auch eine Erklärung für das Wagner'sche Gesetz \parencite{Wagner1892}, das postuliert, dass mit steigendem Wohlstand auch die Staatsquote zunimmt. Es steht aber auch im Spannungsverhältnis mit wachsendem Budgetdruck und dem Trend zu sinkenden Staatsquoten.





Später: Abgrenzung zur "`Public Choice"' Theorie: Ganz andere, libertäre Betrachtungsweise




