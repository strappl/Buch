%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Public Economy: Der Staat als wirtschaftlicher Player}
\label{cha: Marktversagen}

Die Mikroökonomie gilt seit Marshall (vgl. Kapitel \ref{Neoklassik}) als praktisch abgeschlossen. Dies gilt aber nur für die formale Betrachtung \textit{funktionierender} Märkte. Wie wir in Kapitel \ref{Neoklassik_nach1945} sahen, war es vor allem \textcite{Pigou1920} der zumindest die Tatsache aufwarf, dass viele Marktergebnisse gesamtwirtschaftlich nicht erwünscht sind. Mit dem Aufstieg des Keynesianismus in Form der Neoklassischen Synthese, bekam der Staat als Teilnehmer am wirtschaftlichen Leben eine allgemein enorm höhere Bedeutung. Inhaltlich hängen die Überlegungen von \textcite{Pigou1920} und den Vertretern der Neoklassischen Synthese gar nicht sehr eng miteinander zusammen: Schließlich betrachtet die makroökonomische, neoklassische Synthese ausschließlich wirtschaftliche Gesamtzusammenhänge und nicht Unzulänglichkeiten auf einzelnen Märkten. Es war eher die allgemeine Überzeugung nach 1945, dass der Staat auch eine wichtige Funktion im allgemeinen Wirtschaftsleben einnehmen sollte. Woher diese Überzeugung kam, ist umstritten. Möglicherweise spielte Roosevelt's New Deal eine entscheidende Rolle am wachsenden theoretischen Interesse an staatlichen Ausgaben. Vielleicht auch der Zweite Weltkrieg. Kriege kosten Geld und verschlingen hohe Kapazitäten der Produktion. Die wirtschaftliche Bedeutung der öffentlichen Hand steigt so gezwungenermaßen. Wahrscheinlicher ist aber, dass sich die Verbindung eher auf ideologischer Ebene findet: Die Vertreter der makroökonomischen, neoklassischen Synthese befürworteten einen wirtschaftspolitisch aktiven Staat. Diese ökonomische Schule war in den 1950er Jahren in der Volkswirtschaftslehre allgemein tonangebend. Dies sieht man auch daran, dass deren Vertreter eben nicht nur makroökonomische Werke verfassten, sondern auch in der Mikroökonomie bahnbrechende Arbeiten lieferten. Franco Modigliani, James Tobin und vor allem Paul Samuelson sind dafür die besten Beispiele. Gerade letztgenannter war es, der in den 1950er Jahren die Public Economy prägte. Später, in den 1970er-Jahren, war es die neue Generation der keynesianisch geprägten Ökonomen, welche die ersten bahnbrechenden Arbeiten in der mikroökonomischen Theorie des Marktversagens lieferten: Joseph Stiglitz und George Akerlof. Die beiden überzeugten Neu-Keynesianer werden auch im nächsten Kapitel (Kapitel \ref{cha: Neu Keynes}) eine bedeutende Rolle spielen.

Die hier behandelte Theorie der öffentlichen Wirtschaft ("`Public Economy"')\footnote{Vor allem im deutschen etablierten sich verschiedene Namen für diese Theorie. Häufig wird sie auch als "`Public Finance"' bzw. im Deutschen unscharf als "`Theorie der öffentlichen Güter"' bezeichnet. Im deutschsprachigen Raum behandelten Ökonomen bereits im 19. Jahrhundert ähnliche Fragestellungen, diese Schule wird als "`Theorie der öffentlichen Finanzwirtschaft"' oder schlicht als Finanzwissenschaft bezeichnet.} steht in enger Verbindung mit der Wohlfahrtstheorie (vgl. Kapitel \ref{Wohlfahrt}) und der Allgemeinen Gleichgewichtstheorie (vgl. Kapitel \ref{Arrow-Debreu}), indem sie dort beginnt, wo Wohlfahrtstheorie oder allgemeine Gleichgewichtstheorie aufhören zu funktionieren. Es ist weitgehend unstrittig, dass es Märkte gibt, auf denen der erste Hauptsatz der Wohlfahrtstheorie - individuell-nutzenmaximierendes Tauschverhalten führt zu einer effizienten Güterverteilung - und/oder der zweite Hauptsatz der Wohlfahrtstheorie - für jedes Pareto-Optimum existiert eine Einkommensverteilung, bei der alle Haushalte und Unternehmen ihre Nutzen bzw. Gewinne maximieren - nicht gelten. Wenn es solche Märkte gibt, scheitert auch die Allgemeine Gleichgewichtstheorie als alleiniges Instrument zur effizienten Güterverteilung.

Die Theorie der öffentlichen Wirtschaft behandelt alle Märkte auf denen der Staat als wirtschaftlicher Player auftritt, wobei sowohl die Einnahmeseite als auch die Ausgabenseite des Staates behandelt werden. Um wirtschaftliche Tätigkeiten vornehmen zu können, benötigt der Staat Einnahmen. Dieses beschafft er sich in der Regel über Steuern. Die Theorie der optimalen Besteuerung wurde schon von Ökonomen in der Klassik, insbesondere von David Ricardo, John Stuart Mill und in der Neoklassik von \textcite[Kapitel 38]{Walras1874} recht ausführlich behandelt. Die Einnahmeseite spielt in der modernen Theorie der öffentlichen Wirtschaft daher eine eher untergeordnete Rolle. Interessanter ist die Ausgabenseite, weil schon die Frage auf welchen Märkten, bzw. unter welchen Bedingungen der Staat überhaupt aktiv werden soll, eine bis heute hoch umstrittene ist. Eine zentrale Bedingung der "`Public Economy"'-Ökonomen war die Festlegung, dass der Staat immer dann tätig werden soll, wenn der Markt scheitert eine effiziente oder erwünschte Lösung zu kreieren. Die "`Public Economy"' beschäftigt sich daher mit dem Begriff des "`Marktversagens"'.

Wie später noch dargestellt wird, trat die "`Neue Politische Ökonomie"' ab den 1960er Jahren in direkte Konkurrenz zur hier dargestellten "`Public Economy"'. Obwohl beide Schulen die Bedeutung des Staates analysierten, kamen ihrer Vertreter, gerade im Bezug auf Marktversagen und die Rolle des Staates, regelmäßig zu geradezu konträren Forschungsergebnissen. Die lebhafte Diskussion zweier Hauptvertreter der beiden Schulen, nämlich eben Richard Musgrave auf der einen Seite und James Buchanan auf der anderen Seite im Rahmen der - über den in Kapitel \ref{Pol_Econ} noch ausführlich geschrieben werden wird - mündete schließlich im Werk \textcite{Musgrave1999}: "`Public Finance and Public Choice: Two Contrasting Visions of the State"'.

Als Begründer der modernen Form der Theorie der öffentlichen Wirtschaft werden häufig Richard Abel Musgrave und Paul Samuelson angesehen. Bereits im Jahr 1939 hat Musgrave einen bedeutenden Artikel zur Theorie der öffentlichen Wirtschaft verfasst \parencite{Musgrave1939}. Er war es auch, der die oben angedeutete Verbindung zwischen makroökonomischen Fragestellungen und mikroökonomischen Ansätzen zur Analyse der öffentlichen Wirtschaft etablierte. Tatsächlich gab es nämlich in Kontinentaleuropa und hier insbesondere in deutscher Sprache bereits deutlich zuvor eine recht umfangreiche Literatur zu "`öffentlichen Gütern"'. Diese nehmen eine entscheidende Bedeutung im Rahmen der Theorie der öffentlichen Wirtschaft ein. Der Vertreter der deutschen Historischen Schule (vgl. Kapitel \ref{Hist_Schulen}) \textcite{Wagner1892} definierte öffentliche Güter in ihrer modernen Form, nämlich als Güter bei denen keine Ausschließbarkeit, aber auch keine Rivalität beim Konsum vorliegen. So kann man zum Beispiel niemanden davon ausschließen die Sonne als Lichtquelle zu nutzen (Nicht-Ausschließbarkeit). Es schränkt aber auch niemanden in seiner eigenen Nutzung der Sonne ein, wenn jemand anderer die Sonne als Lichtquelle nutzt (Nicht-Rivalität). Vor allem aber der in Wien habiliterte Emil \textcite{Sax1887}, sowie die Schweden Erik \textcite{Lindhal1928} und - einmal mehr - Knut \textcite{Wicksell1896} lieferten bereits Ansätze zur Analyse öffentlicher Güter. Vereinzelt werden die Arbeiten von Richard Musgrave daher auch als Verbindung aus der deutschen öffentlichen Finanzwissenschaft und der angel-sächsischen neoklassischen Theorie, sowie dem Keynesianismus interpretiert (\textcite[S. 13]{Sinn2007} und \textcite[S. 589]{Sturn2007}). Für diese Aufgabe war der Richard Musgrave wie geboren. Schließlich wurde er in Deutschland geboren, studierte dort Volkswirtschaft, wanderte 1933 in die USA aus, wo er in Harvard seine Ausbildung abschloss. Er hatte also sowohl den deutschen, als auch die amerikanischen Zugang zur Volkswirtschaftslehre aus erster Hand kennen gelernt.

\section{Die moderne Theorie der öffentlichen Wirtschaft}
\label{Beginn_Public_Economy}

Bekannt wurde das Werk von Musgrave durch zwei wesentliche Punkte. Erstens, auf der Einnahmenseite die Theorie der Steuern weiterzuentwickeln \parencite{Musgrave1959} und zweitens, auf der Ausgabenseite die Aufgabe des Staates in drei Funktionen einzuteilen \parencite{Musgrave1956, Musgrave1959}, nämlich: Allokation, Distribution und Stabilisierung. Diese Aufgaben des Staates werden weiter unten behandelt (vgl. Kapitel \ref{Offentliche Guter}). Zunächst betrachten wir die Einnahmeseite der öffentlichen Hand: die "`Theorie der optimalen Besteuerung"'. Wie bereits erwähnt, beschäftigten sich damit viele Ökonomen seit Beginn der klassischen Ökonomie. \textcite{Musgrave1959} fasste diese zu einem modernen Ansatz zusammen. Zunächst definierte er die zwei möglichen Steuerrechtfertigungsgründe, indem er unterschied zwischen dem "`Benefit Approach"' und dem "`Ability to Pay Principle"'. Der erstere war ursprünglich dominierend und sieht vor, dass jene Individuen einer Gesellschaft zu besteuern sind, welche die staatlichen Leistungen am stärksten in Anspruch nehmen. Dies klingt zunächst vor allem gerecht. Güter, die der Staat zur Verfügung stellt werden quasi wie Marktgüter behandelt. Zwar liefert der Staat die Leistungen, aber es bezahlen über Steuern jene dafür, die sie in Anspruch nehmen. In der kontinentaleuropäischen Literatur galt dieses Steuerprinzip als "`Normalfall"'. Allerdings scheitert der "`Benefit Approach"' meist daran, dass es nicht möglich ist herauszufinden wer die angebotenen Leistungen am stärksten in Anspruch nehmen will, wie \textcite{Musgrave1959} schreibt und \textcite{Samuelson1954} auch analytisch zeigen konnte. Das "`Ability to Pay Principle"' zielt hingegen darauf ab, die Steuern jenen aufzubürden, die sie sich am einfachsten leisten können. \textcite{Musgrave1959} zielt dabei interessanterweise eindeutig auf das Einkommen - und nicht etwa auf das Vermögen oder den Konsum - als Indiz dafür ab. Wer aber kann sich Steuern "`am einfachsten leisten"'? Hier zielt Musgrave darauf ab, dass jedes Individuum durch Steuerzahlungen das gleiche Opfer (engl.: "`equal sacrifice"') bringen soll. Das ist natürlich wieder schwer zu quantifizieren. Hier findet man die Verbindung zur Wohlfahrtstheorie: Kennt man die Nutzenfunktionen der Individuen, so kann man messen bei welcher Steuerhöhe, welcher Wohlfahrtsverlust eintritt und so ein Steuersystem erschaffen, das jedem das gleiche Opfer abverlangt. Das ist ein sehr theoretischer Ansatz und auch im Hinblick auf die Unmöglichkeit interpersonellen Nutzenvergleich umstritten (vgl. Kapitel \ref{Wohlfahrt}). Zumindest lässt sich daraus aber eine theoretische Ableitung progressiver Einkommenssteuern rechtfertigen, die es in vielen Staaten heute gibt. Unter der weitgehende akzeptierten Annahme eines abnehmende Grenznutzens von Einkommen, ist eine progressive Einkommenssteuer im Hinblick auf das "`equal sacrifice"' Prinzip zielführend.  

Zur Theorie der optimalen Besteuerung trugen viele Ökonomen der verschiedensten Richtungen Arbeiten bei. Bekannt wurden die Ansätze der beiden Neoklassiker \textcite{Edgeworth1897} und \textcite{Pigou1920}, aber auch das Mathe-Genie Frank Ramsey (vgl. Kapitel \ref{sec: Solow-Modell}) lieferte einen bedeutenden Beitrag. Das Problem zum Beispiel von \textcite{Pigou1920} war, dass seine theoretische Überlegungen dazu führten, dass vollkommene Einkommensgleichheit zu maximalem gesamtwirtschaftlichen Gesamtnutzen führt\footnote{Bekanntermaßen wurde die Unzulässigkeit der interpersonellen Nutzenvergleiche, die die Voraussetzung dieser Annahme ist, erst später von \textcite{Robbins1932} einflussreich thematisiert}. Demnach sollten Steuern die Einkommensungleichheit vollkommen ausgleichen. Natürlich waren sich die Ökonomen damals aber bewusst, dass dies zu Anreizproblemen und damit zu Effizienzeinbußen führen würde. Analytische Lösungen zu diesem Trade-Off zwischen "`Gerechtigkeit"' und "`Effizienz"' lieferten sie allerdings nicht \parencite[S. 168]{Sandmo1999}. Dies gelang erst \textcite{Mirrlees1971}, der auf frühe Arbeiten von \textcite{Vickrey1945, Vickrey1947} aufbaute. Beide suchten nach "`optimalen Steuersystemen"', die den Trade-Off zwischen "`Gerechtigkeit"' und "`Effizienz"' berücksichtigten. Tatsächlich wirkt die Arbeit von \textcite{Mirrlees1971} mit ihrer sehr quantitativen Ausrichtung noch heute modern. Vor allem aber trat der "`Gerechtigkeitsgedanke"' zu Gunsten des "`Effizienzgedanken"' in den Hintergrund. Wie \textcite[S. 35]{Musgrave1981} selbst schreibt, zählt er sich selbst zur älteren Generation, die Steuern als Mittel zur Schaffung von mehr Gerechtigkeit sahen, was zu Lasten von Effizienzüberlegungen ging. Entscheidend bei den Ansätzen zur optimalen Besteuerung von \textcite{Vickrey1947} und \textcite{Mirrlees1971} war das auch von \textcite{Samuelson1954} hervorgehobene Problem, dass staatliche Entscheidungsträger gerne wüssten, wie stark das Interesse von Individuen an bestimmten Öffentlichen Gütern ist um abschätzen zu können, welche Beiträge Individuen dafür bereit wären zu zahlen. Analog dazu wüsste der Steuergesetzgeber welchen Individuen er welche Steuerhöhe zumuten kann um auf der einen Seite eine möglichst gerechte Verteilung erhält, aber auf der anderen Seite keine Effizienzverluste riskiert, indem zu hohe Steuern die Anreize zur Leistungserbringung untergraben. Dies sind typische Probleme der asymmetrischen Information, die später in diesem Kapitel noch ausführlich im Hinblick auf daraus resultierende Probleme auf privatwirtschaftlichen Märkten betrachtet werden. \textcite{Mirrlees1971} nahm in seiner Arbeite einen Kunstgriff vor: Individuen wissen sowohl über ihren Stundenlohn als auch über die gearbeiteten Stunden Bescheid, der Staat weiß hingegen nur über das Einkommen (was dem Produkt der beiden Werte entspricht) Bescheid. Damit nimmt \textcite{Mirrlees1971} eine Formalisierung des später so präsenten Themas der asymmetrischen Information vor, ohne sich dessen bewusst zu sein. Tatsächlich kommt der Begriff asymmetrische Information in seiner Arbeit selbst gar nicht vor \parencite[S. 170]{Sandmo1999}. Was aber soll diese eingeführte Informationsasymmetrie bringen? Nun, Individuen haben unterschiedliche Fähigkeiten, die zu unterschiedlich hohen Stundensätzen führen. Der Staat weiß nun zwar die Einkommen der Individuen, nicht aber deren Fähigkeiten. Würde er nun alle Vor-Steuer-Einkommen so besteuern, dass alle Nach-Steuer-Einkommen identisch wären, würde dies dazu führen, dass jene Individuen, die wertvollere Fähigkeiten haben und daher höhere Stundensätze erhalten, weniger Arbeitsstunden leisten um so das gesamtwirtschaftliche Durchschnittseinkommen zu erhalten. Mehr zu arbeiten würde keinen Sinn machen, da der Mehrverdienst durch Steuern abgeschöpft werden würde. Das heißt, es würde zu Effizienzverlusten kommen. Das Ergebnis eines solchen Modells ist also, dass - anders als etwa bei \Textcite{Pigou1920} - eine Besteuerung, die zu vollkommener Einkommensgleichheit führt, nicht mehr zu maximalem gesamtwirtschaftlichen Nutzen führt. Stattdessen muss der Steuersatz so gewählt werden, dass der Trade-Off zwischen "`Gerechtigkeit"' und "`Effizienz"' minimiert wird. Was dadurch gelingt, dass der Steuersatz gering genug ist um Anreize für Individuen mit besser bezahlten Fähigkeiten zu liefern. \textcite{Mirrlees1971} findet dazu ein Konzept, das als "`Single Crossing"' bekannt wurde. Das ist der Steuersatz ab dem sich die Individuen mit besser bezahlten Fähigkeiten nicht mehr dazu entscheiden durch weniger Arbeit Steuern zu sparen. Das ist insofern interessant als die Arbeit von \textcite{Mirrlees1971} zunächst für die Theorie der öffentlichen Wirtschaft und im speziellen für die Theorie der optimalen Besteuerung entwickelt wurden, später aber auch für ganz andere Gebiete entdeckt wurden, nämlich überall dort wo es asymmetrische Information und Anreizprobleme gibt, wie zum Beispiel bei Auktionen oder auch auf privaten Versicherungsmärkten. Wir werden im Kapitel \ref{Info} sehen, dass \textcite{Akerlof1970} ein ganz ähnliches Problem für private Märkte fast gleichzeitig analysierte und \textcite{Stiglitz1976a} ein im Ergebnis ähnliches Modell für den Versicherungsmarkt entwickelten wie \textcite{Mirrlees1971} für die Besteuerung. Bei \textcite{Stiglitz1976a} wählen die Versicherungsnehmer trotz unterschiedlich hohem Schadensrisiko aufgrund von Anreizen den für sie geschaffenen Vertrag selbst aus, obwohl die Versicherung keine Information über das tatsächliche Schadensrisiko der einzelnen Kunden hat. \textcite{Stiglitz1982} gelang es später sein Modell auf die Steuerproblematik anzuwenden und damit das Thema der asymmetrischen Information auch formal in die Theorie der optimalen Besteuerung zu integrieren. James Mirrlees und William Vickrey erhielten übrigens im Jahr 1996 gemeinsam den Nobelpreis für Wirtschaftswissenschaften. Die Verleihung an William Vickrey ist hierbei in zweifacher Hinsicht bemerkenswert. Seine wissenschaftlichen Leistungen zur Auktionstheorie und zur Theorie der optimalen Besteuerung sind unumstritten. Daneben war er aber noch in den 1990er Jahren ein klarer Verfechter keynesianischer Wirtschaftspolitik und lehnte damals moderne Konzepte wie jenes der "`natürlichen Arbeitslosigkeit"' oder "`Austerität"' entschieden ab. Interessant wäre in diesem Zusammenhang seine Nobelpreisrede gewesen. Warum "`wäre gewesen"'? - der tragische Aspekt seiner Biografie ist, dass Vickrey nur drei Tage nach der Bekanntgabe der Nobelpreisverleihung überraschend verstarb.

Breit gefasst behandelt die "`Public Economy"' enorm viele Themen, wie Fiskalpolitik, öffentliche Verschuldung, Regulierung und Einkommensverteilung. Grundsätzlich könnte man darunter alle volkswirtschaftlichen Themen behandeln, in denen der Staat eine Rolle spielt. An dieser Stelle beschränken wir uns in weitere Folge auf die Betrachtung eines Kernbereichs der "`Public Economy"': Die Theorie des Marktversagens. Zunächst betrachten wir die Besonderheiten der "`Öffentlichen Güter"' (vgl. Kapitel \ref{Offentliche Guter}), die weiter oben schon kurz definiert wurden. Danach wird die Marktversagensform der Informationsasymmetrien behandelt. Also die soeben schon kurz thematisierte Tatsache, dass Angebots- oder Nachfrageseite auf bestimmten Märkten in der Regel keine vollkommene Information über die Produkteigenschaften haben. Im darauf folgenden Unterkapitel (vgl. Kapitel \ref{Disease}) wird (auch) auf das Problem der Natürlichen Monopole eingegangen. Solche gibt es auf Märkten, auf denen es keinen Sinn macht, dass mehrere Anbieter auftreten. Die vierte typische Marktversagensforme "`Externe Effekte"' wurde in den Kapiteln \ref{sec: Pigou} und \ref{Pol_Econ} angeschnitten. Insgesamt spielt die Frage, ob das nicht perfekte Funktionieren von Märkten relevant für die Volkswirtschaftstheorie sein soll in der Ökonomie bis heute eine entscheidende Rolle und zwar interessanterweise sowohl in der Mikro- als auch in der Makroökonomie, wie in Kapitel \ref{micmac} dargestellt.


\section{Öffentliche Güter}
\label{Offentliche Guter}

Trotz seiner revolutionären frühen Arbeiten auch im Bereich der öffentlichen Güter ist der Name Richard Musgrave heute nur Ökonomie-Insidern ein Begriff. Mehr Resonanz erhielt Paul Samuelson, der mit der Veröffentlichung eines Artikel-Triple \parencite{Samuelson1954, Samuelson1955, Samuelson1958} Mitte der 1950er Jahre das Interesse auf dieses Thema lenkte. Er gilt damit als Mitbegründer der "`Theorie der öffentlichen Wirtschaft"' und etablierte sie als weitgehend normative Theorie. Mit seinem nur dreiseitigen Journal-Artikel, entdeckte \textcite{Samuelson1954} die Theorie der "`öffentlichen Güter"' für die angelsächsische Mainstream-Ökonomie der 1950er-Jahre wieder.  \textcite[S. 387]{Samuelson1954} verweist durchaus gleich zu Beginn auf die deutschen Arbeiten von \textcite{Sax1887}, \textcite{Lindhal1928} und \textcite{Wicksell1896}. Auch die Definition von öffentlichen Gütern ist identisch mit jener, die schon die deutsche "`Finanzwissenschaft"' zur Jahrhundertwende hervorgebracht hatte: Nicht-Rivalität im Konsum und Nicht-Ausschließbarkeit vom Konsum. Samuelson kannte also die Literatur und war sich bewusst, dass "`öffentliche Güter"' in Kontinentaleuropa schon zur Jahrhundertwende diskutiert wurden. Sein zentraler Verdienst bestand darin, dass er die Thematik vollends mit mikroökonomischen, neoklassischen und auch wohlfahrtstheoretischen Elementen analysierte und somit in der Mainstream-Ökonomie etablierte. Im Bezug auf die wohlfahrtstheoretischen Elemente baute er direkt auf sein eigenes Konzept der "`Neuen Wohlfahrtstheorie"' und die darin entwickelte "`Bergson-Samuelson Sozial-Wohlfahrtsfunktion"' auf (vgl. Kapitel \ref{Wohlfahrt}). Entscheidend ist das formal-analytische Ergebnis, dass \textcite{Samuelson1954} hervorbringt: Es gibt bei öffentlichen Gütern keinen funktionierenden Preismechanismus, mit dem sich das Optimum bestimmen ließe, weil Individuen kein Interesse daran haben ihre wahren Präferenzen hinsichtlich der öffentlichen Güter mitzuteilen. Würden Entscheidungsträger die Präferenzen der Individuen abfragen und diese Individuen ihre Nachfrage wahrheitsgetreu kundtun, so könnten die Entscheidungsträger darauf aufbauend die Preise so festsetzen, dass die Produktionskosten vollends gedeckt sind und die Nachfrage im Optimum befriedigt wird \parencite[S. 389]{Samuelson1954}. Allerdings werden die Individuen jeweils immer geringeres als tatsächlich vorhandenes Interesse an die Entscheidungsträger signalisieren. Durch die Nicht-Ausschließbarkeit vom Konsum, erhoffen sich die Individuen dadurch niedrige Preise bei gleichzeitig voller Verfügbarkeit der öffentlichen Güter. Da es allerdings für alle Individuen nutzenmaximierend ist ihre wahre Nachfrage nach öffentlichen Gütern zu verschleiern, wird es unter marktwirtschaftlichen Bedingungen dazu kommen, dass das Angebot zu gering ist, oder es gar kein Angebot gibt. Es liegt also auch hier asymmetrische Information und zwar in Form des Trittbrettfahrerproblems, einer Ausgestaltung des Moral Hazard Problems. Die einzelnen Individuen auf der Nachfrageseite geben ihre wahren Präferenzen nicht bekannt, in der Hoffnung so einen "`Free Lunch"' zu erhalten. Es kommt zu keinem privatwirtschaftlichen Angebot. In diesem Fall muss eine öffentliche Stelle einspringen um das Angebot zu übernehmen. 

\textcite{Musgrave1956} entwickelte schließlich den zusätzlichen Begriff der "`Meritorischen Güter"'. Das sind ebenso öffentliche Güter, die rein privatwirtschaftlich organisiert nicht in dem Ausmaß produziert werden würden, wie gesamtwirtschaftlich erwünscht. Bei \textcite{Musgrave1956} können meritorische Güter grundsätzlich individuell konsumiert werden, öffentlichen Güter hingegen nicht. Ein öffentliches Gut in diesem Sinne wäre die innere oder äußere Sicherheit eines Staates. Polizei oder Militär sichert dann die Unversehrtheit des Staates. Ein Beispiel für ein meritorisches Gut wäre hingegen Bildung. Diese ist seit jeher eine zentrale Quelle wirtschaftlichen Wachstums und daher für eine Gesamtwirtschaft von hoher Bedeutung. Gerade beim Fehlen sozialer Absicherung war es Eltern aber oft wichtiger, dass die Kinder statt in die Schule zu gehen, Geld verdienen um zum Lebensunterhalt beizutragen. 

Während der hohen Zeit der neoklassischen Synthese wurden sehr viele Güter als öffentliche Güter identifiziert, die der Staat anbieten sollte. Mit dem Aufstieg konservativer ökonomischer Theorien in den 1960er und 1970er Jahren verloren öffentliche Güter an Bedeutung. Das Konzept der Nicht-Rivalität und der Nicht-Ausschließlichkeit wurde näher betrachtet. Als reine öffentliche Güter gelten heute nur mehr wenige Bereich. Bei den meisten Gütern gibt es nämlich doch zumindest einen gewissen Grad an Rivalität im Konsum. So galten viele Rohstoffe, die Natur, natürliche Wasserquellen, oder die Fischbestände in den Meeren lange Zeit als öffentliche Güter. Durch die weltweite Industrialisierung und den Klimawandel entstand aber in den letzten Jahrzehnten auch Rivalität in diesen Bereichen. Besteht Rivalität im Konsum und Nicht-Ausschließbarkeit so spricht man im Deutschen von Allmende-Gütern. Allmende ist hierbei ein mittlerweile nicht mehr gebräuchliches Wort, das früher eine Weide der Wiese bezeichnete, die alle Landwirte für ihr Vieh nutzen konnten. Wie man sich vorstellen kann, wurden die Tiere zuerst auf dieses Allgemeingut zum weiden gebracht, bevor man die Wiesen im Eigentum zur Fütterung nutzte. Berühmt wurde in diesem Forschungsbereich die erste Nobelpreisträger\textit{in} für Wirtschaftswissenschaften, Elinor Ostrom. Sie argumentierte \parencite{Ostrom1990}, dass Allmendegüter am besten geschützt werden, wenn diese nur in regional stark eingeschränkten Bereichen genutzt werden dürfen. Dadurch ließen sich die üblichen negativen Folgen der Nicht-Ausschließbarkeit mit Hilfe regionaler Institutionen regeln, ohne dass es zu großen Effizienzverlusten kommt. \textcite{Ostrom1990} plädiert dabei für eine institutionelle Lösung, die weder volle Verstaatlichung noch volle Privatisierung der Allmendegüter vorsieht.

Liberale Ökonomen argumentierten zunehmend, dass öffentliche Güter und auch Allmende-Güter auch privatwirtschaftlich angeboten werden können, wenn versucht wird die Nicht-Ausschließbarkeit zu beheben. \textcite{Buchanan1965} entwickelte dazu das Konzept der Klubgüter. Diese zeichnen sich zwar wie öffentliche Güter durch Nicht-Rivalität im Konsum aus, allerdings wird künstliche eine Ausschließbarkeit geschaffen. Für die Nutzung öffentlicher Güter muss man also einer Art Klub beitreten, der nach marktwirtschaftlichen Prämissen arbeiten kann. Damit wird die Trittbrettfahrerproblematik abgestellt. Der Klub stellt sicher, dass niemand ein eigentlich öffentliches Gut nutzen kann, wenn er nicht einen bestimmten Preis, sozusagen den Klub-Mitgliedsbeitrag, bezahlt. Durch Variation des Preises kann der Klub außerdem eventuelle Übernutzung verhindern. Beispiele dafür sind zum Beispiel Mautstraßen, oder auch der Zugang zu Sehenswürdigkeiten und Stränden. Durch Privatisierungen kann man praktisch alle öffentlichen Güter zu Klubgütern machen. Gerade im Hinblick auf meritorische Güter bleibt dann aber die Frage, ob durch die Privatisierung nicht vulnerable Gruppen von der Nutzun öffentlicher Güter ausgeschlossen werden. 

Es ist bis heute eine zentrale Diskussion zwischen konservativ-liberalen und eher keynesianisch-linken Ökonomen, ob im Hinblick auf öffentliche Güter ein Markteingriff seitens öffentlicher Hand mit der Gefahr von Staatsversagen das größere Problem darstellt, oder doch Privatisierungen die größere Gefahr darstellen, weil dadurch gesamtwirtschaftlich unerwünschte Marktlösungen entstehen\footnote{Ganz ähnlich ist das Problem im eng verwandten Bereich der externen Effekte, das in Kapitel \ref{sec: Neue Inst} dargestellt wird. Im Prinzip ist die Argumentation bei negativen externen Effekten identisch: Man kann negative Externe Effekte durch staatliche Eingriffe im Sinne einer Pigou-Steuer vermeiden \parencite{Pigou1920}, oder aber durch Schaffung von Eigentumsrechten dafür sorgen, dass die freie Marktwirtschaft dafür sorgt, dass es keine negativen externen Effekte gibt \parencite{Coase1960}.}.


\section{Informationsasymmetrie}
\label{Info}

Einer der vielleicht berühmtesten Journalbeiträge ist jener von George Akerlof aus dem Jahr 1970. Es wird meist abgekürzt einfach "`The Market for Lemons"' genannt \parencite{Akerlof1970}. Er begründete damit eine Reihe von Arbeiten in denen gezeigt wurde, dass unter bestimmten Umständen - auf scheinbar ganz normalen, also kompetitiven Märkten - kein befriedigendes Marktgleichgewicht zustande kommt. Dieses Marktversagen kann dann auftreten, wenn zwischen Angebots- und Nachfrageseite asymmetrische Information herrscht. Eine Marktseite ist also über die Marktbedingungen besser informiert, als die andere. Selbst wenn, abgesehen von Informationsasymmetrien, ein vollkommener Markt vorliegt, tritt dieses Problem in einer freien Marktwirtschaft auf. \textcite{Akerlof1970} beschrieb das Problem anhand des Gebrauchtautomarktes. Die Verkäufer gebrauchter Autos kennen den Zustand ihres Wagens in der Regel recht gut. Verkäufer von "`Montagsautos"'  also Autos, die regelmäßig technische Probleme aufweisen, werden die Schwachstellen ihrer mangelhaften Fahrzeuge - die im amerikanischen Englisch häufig "`Lemons"' genannt werden - gerne unerwähnt lassen. Käufer haben nur wenig Möglichkeiten die Qualität eines Gebrauchtwagens zu bewerten. Dies führt zum Problem der Adversen Selektion (negative Risikoauslese). Wenn Käufer nicht zwischen guten und schlechten Gebrauchtwagen unterscheiden können, werden diese zum gleichen Preis gehandelt. Es ist aber jeden klar, dass ein Gebrauchtwagen guter Qualität mehr Wert ist als einer schlechter Qualität. Die Anbieter guter Gebrauchtwagen werden keinen fairen Preis angeboten bekommen, weil sie die hohe Qualität ihres Autos nicht beweisen können. Käufer wiederum werden nur den fairen Preis eines schlechten Autos bereit sein zu bezahlen, da sie nur in diesem Fall sicher sein können, nicht über den Tisch gezogen zu werden. Gute Autos werden von schlechten verdrängt. Als Resultat werden am Gebrauchtwagenmarkt ausschließlich Autos schlechter Qualität gehandelt. Der Markt für gute Gebrauchtwagen bricht zusammen \parencite[S. 490]{Akerlof1970}. Unterteilt man den Markt nicht in gute und schlechte Autos, sondern in ein kontinuierlich verlaufendes Qualitätsspektrum, so werden  ausgezeichnete Autos von guten verdrängt, gute von mittleren und schließlich Autos mittlerer Qualität von schlechten Autos - bis der Gebrauchtwagenmarkt komplett zusammenbricht. Trotz eines grundsätzlich perfekten Wettbewerbsmarktes mit rationalen Teilnehmern, kommt kein Gleichgewicht zustande.

Das Standardbeispiel von Akerlof wurde weltberühmt, wenn es auch nicht das beste Beispiel ist für einen Markt mit asymmetrischer Information. Bei den meisten materiellen Gütern ist eine Qualitätsprüfung in einem gewissen Ausmaß durchaus möglich, so auch bei Gebrauchtwagen. Schon \textcite[S. 492]{Akerlof1970} selbst nannte als weitere Beispiele für adverse Selektion vor allem immaterielle Güter. Insbesondere auf Versicherungsmärkten ist das Problem einer negativen Risikoauslese immanent. Welchem Unfall- oder Gesundheitsrisiko eine Person ausgesetzt ist, ist eine höchstpersönliche Angelegenheit und von Versicherungen nicht so einfach festzustellen. In einem weiteren bahnbrechenden Paper zeigen \textcite{Stiglitz1976a}, dass es auf Versicherungsmärkten tatsächlich zu adversen Selektionsprozessen und in weiterer Folge zu Marktversagen kommen wird, wenn Versicherungen versuchen allen Versicherungsnehmern den gleichen Vertrag, mit der gleichen Risikoprämie, anzubieten. Personen mit hoher Schadeneintrittswahrscheinlichkeit (hohe Risiken) werden so einen Vertrag gerne unterzeichnen. Personen mit geringer Schadeneintrittswahrscheinlichkeit (niedrige Risiken) werden hingegen die Prämie als zu hoch einstufen und den Vertragsabschluss ablehnen. Die notwendige Subventionierung der hohen Risiken durch die niedrigen Risiken bleibt damit aus. Der adverse Selektionsprozess kommt in Gang und der Markt versagt auf gleiche Weise wie im oben genannten Gebrauchtwagen-Beispiel. Ein Markt-Gleichgewicht mit einem Vertrag für alle unterschiedlichen Risikogruppen - genannt Pooling-Gleichgewicht - wird also nicht zustande kommen. Versicherungen könnten aber versuchen unterschiedliche Verträge für unterschiedliche Risikogruppen anzubieten. Sportliche Autofahrer wählen einen Vollversicherungsschutz selbst dann noch, wenn die Prämie höher, also risikoadäquat, ist. Vorsichtige Wenigfahrer verzichten auf einen vollumfänglichen Risikoschutz und genießen dafür die niedrigere, aber ebenfalls risikoadäquate, Prämie. \textcite[S. 634ff]{Stiglitz1976a} zeigen, dass solche "`Separating-Gleichgewichte"' durchaus möglich sind. Die Versicherungsnehmer handeln hierbei nutzenmaximierend, filtern sich jedoch selbst in die für sie passenden Tarifklassen, was auch "`Screening"' genannt wird.

In der Realität gibt es auch auf Versicherungsmärkten viele Möglichkeiten, wie man die Qualität seiner Kunden feststellen kann. Traditionell in der Kraftfahrzeug-versicherung mit Bonus-Malus-Stufen. Verursachte Schäden führen zu höheren Prämien. In der privaten Krankenversicherung mit verpflichtenden ärztlichen Untersuchungen vor Vertragsabschluss. Modernere Ansätze ermöglichen es KfZ-Versicherungsnehmern ihren sicheren Fahrstil in Form von GPS-Daten zu beweisen und der Versicherung damit ein geringes Schadeneintrittsrisiko zu signalisieren. Im Gesundheitsbereich kann man einen gesunden Lebensstil mit Smartphone-Apps, die den Aktivitätsgrad messen, signalisieren und damit die Prämie senken. Allesamt Maßnahmen, die Informationsasymmetrien abbauen, allerdings vielleicht zum Preis der totalen Überwachung?!  
Im Bereich der allgemeinen Gesundheits- und Unfallversicherung ist das Thema der adversen Selektion nach wie vor brandaktuell. In Kontinentaleuropa ging man den Weg der staatlichen Pflichtversicherung aller Erwerbstätigen, die einen bestimmten Teil ihres Einkommens, als Sozialversicherung abgeben müssen und im Sinne eines Solidarbeitrags somit die medizinische Versorgung aller Bürger finanzieren. Im angelsächsischen Raum ist dies noch immer als "`sozialistisches Gedankengut"' verpönt, hier setzt man auf privatwirtschaftliche Lösungen. Im Fall der medizinischen Versorgung sieht es aber so aus als wäre der staatliche Eingriff von Vorteil. So haben die USA das teuerste Gesundheitssystem der Welt und dennoch ist ein beträchtlicher Teil der Bevölkerung unversichert nach wie vor unversichert.

Bereits \textcite{Spence1973} zeigte ein effizientes Mittel, um die Probleme der adversen Selektion zu lösen: Das Signaling. Als Anwendungsbeispiel wählte \textcite{Spence1973} den Arbeitsmarkt. Die Suche nach guten Arbeitnehmern ist schwierig. Nicht zuletzt deswegen weil ein Arbeitgeber weniger Information zur Produktivität hat als die potenziellen Arbeitnehmer selbst. Letztgenannte stehen als Bewerber in Konkurrenz zur Stelle, die der Arbeitgeber anbietet. Diese können versuchen dem Arbeitgeber zu signalisieren, dass sie die beste Wahl für die ausgeschriebene Stelle sind. Das benötigen sie entsprechende Mittel, genannt Signale. Je schwieriger (ökonomisch: je kostenintensiver) ein Signal zu erwerben ist, desto besser ist das Signal. Ein schwaches Signal wäre es zum Beispiel adäquat gekleidet und freundlich beim Vorstellungsgespräch aufzutreten. Allerdings sollten das zumindest einige Bewerber schaffen. Somit kann sich ein einzelner dadurch nicht von den anderen abheben, es liegt ein schwaches Signal vor. Wesentlich schwieriger - weil zeit- und damit kostenintensiv - ist es eine fundierte Ausbildung zu absolvieren. Eine vollwertige Ausbildung dauert mehrere Jahre in denen man schlecht bezahlt an einem starken Signal arbeitet. Dieses Signal, zum Beispiel in Form eines Abschlusszeugnisses, kann man dann verwenden um beim Bewerbungsgespräch die asymmetrische Information des potenziellen Arbeitgebers zu verringern \parencite{Spence1973}
Es bleibt allerdings auch hier die Frage nach der Regulierung. Denn der Arbeitgeber muss ein schwaches Signal von einem starken Signal unterscheiden können. Kann er das nicht wird das Problem nur um eine Stufe verlagert: Die adverse Selektion findet dann auf Ebene der Signale statt. In Kontinentaleuropa waren Ausbildungen unter anderem deshalb lange Zeit staatlichen Institutionen vorbehalten. Mit der Privatisierung von Bildungsinstitutionen treten diese in Konkurrenz zueinander. Es ist also kurzfristig individuell rational, zum Beispiel als Privatuniversität, ein eigentlich starkes Signal, zum Beispiel einen Master-Abschluss, für einen verhältnismäßig geringen Aufwand zu verleihen. Die Nachfrage nach diesem Bildungsprodukt - und damit der Gewinn der Hochschule - werden hoch sein. Erst langfristig werden die Arbeitgeber die mangelnde Qualität der Ausbildung, durch die geringere Produktivität der Arbeitnehmer, feststellen. Das Signal "`Master-Abschluss"' reicht dann nicht mehr aus, das Problem der asymmetrischen Information kann durch dieses Signal nicht mehr behoben werden.

Ein weiteres Anwendungsbeispiel der Probleme asymmetrischer Information, das ebenfalls den Arbeitsmarkt betrifft, wird in der Effizienzlohnhypothese (Adverse Selektion) und im "`Shirking"'-Modell (Moral Hazard) behandelt. Die Folgen sind makroökonomisch bedeutsam und werden daher in Unterkapitel \ref{RR_AM} behandelt.

Adverse Selektion beschreibt das Problem asymmetrischer Information \textit{vor} Vertragsabschluss. Beim nun behandelten Problem des "`Moral Hazard"' (moralisches Risiko) tritt das Problem asymmetrischer Information erst \textit{nach} Vertragsabschluss auf. Das Problem, dass eine Person nach dem Abschluss einer Vereinbarung sein Verhalten ändert um sich besser zu stellen, ist jedem von uns seit Kindertagen bekannt. In den 1960er Jahren wurde dieses Verhalten allerdings erstmals ökonomisch analysiert \parencite{Arrow1963, Dickerson1963} und zwar am Beispiel medizinischer Versorgung: Je besser der Versicherungsschutz, desto umfangreicher waren die in Anspruch genommenen Leistungen. \textcite{Pauly1968} zeigte, dass nicht unmoralisches Verhalten der Auslöser für die Verhaltensänderung sein muss, sondern dass die Verhaltensänderung wirtschaftlich rationales Verhalten darstellen kann. Das ist nicht unwesentlich, da unmoralisches Verhalten - in Regeln formalisiert und in Gesetze gegossen - sanktioniert werden kann. Ökonomisch rationales Verhalten, das zu keinem stabilen Marktergebnis führt, ist hingegen Marktversagen. Vor allem im Versicherungsbereich ist dieses Problem wohlbekannt. Das Versicherungsunternehmen hat keine Möglichkeit sicher festzustellen, welches Ausmaß an Leistungen vom Versicherungsnehmer gerechtfertigt in Anspruch genommen werden darf und durch welche Verhaltensweisen der Versicherungsnehmer zusätzliche Versicherungsleistungen "`provoziert"'. Im Bereich der Versicherungen gibt es allerdings ein einfache Maßnahme, die Moral Hazard weitgehend einschränkt: Die Selbstbehalte. Wie Sie wahrscheinlich schon bei eigenen Versicherungsverträgen bemerkt haben, gibt es Selbstbehalte praktisch in jedem Versicherungsvertrag verankert, der hohen Versicherungsschutz umfasst.

Eine Ableitung aus dem Moral Hazard-Problem hat ist im Rahmen der "`Great Recession"', also der globalen Wirtschaftskrise nach 2008 in den Mittelpunkt öffentlicher Diskussion getreten: Das \textit{Principal Agent}-Problem. Dieses Problem zielt darauf ab, dass Eigentümer eines Unternehmens und dessen Manager unterschiedliche Ziele verfolgen. Die Aktionäre (="'Principals"'), also die Eigentümer, einer großen Bank haben das Ziel, dass das Unternehmen \textit{langfristig} seinen Wert maximiert. Die Manager (="'Agents"') haben hingegen befristete Verträge und damit Anreize \textit{kurzfristige} Gewinne zu erzielen, da diese die Höhe ihrer Prämie bestimmen. Die Aktionäre, als Arbeitgeber der Manager, sehen sich also dem Risiko ausgesetzt, dass die Manager nach Vertragsabschluss andere Ziele verfolgen, als ursprünglich vereinbart. Eine noch extremere Ausprägung resultiert im "`Too big to fail"'-Problem. Hier wird Managern vorgeworfen, bewusst sehr riskante Geschäfte einzugehen, weil sie im Wissen handeln, im Falle eines Defaults vom Staat finanziell unterstützt werden zu müssen, da andererseits systemweite Verwerfungen drohen. Dieses Problem ist eher dem "`Neuen Institutionalismus"' (Kapitel \ref{Neue Institut}) zuzuordnen und wurde erstmals von \textcite{Jensen1976} beschrieben. Ihre wissenschaftliche Abhandlung dazu erfuhr große Resonanz und gilt als einer der meist-zitierten Journalartikel in den Wirtschaftswissenschaften.


\section{Die Kostenkrankheit und angreifbare Märkte}
\label{Disease}
Ein extrem unkonventioneller Ökonom war William Baumol. Er lieferte bedeutende Beiträge in verschiedenen Disziplinen der Volkswirtschaft, vor allem aber in der hier dargestellten Theorie der öffentlichen Wirtschaft. Zwei wichtige Beiträge werden hier - in historisch umgekehrter Reihenfolge - dargestellt.

Eine in der praktischen Umsetzung sehr erfolgreich umgesetzte Idee ist Baumol's \textit{Theorie der angreifbaren Märkte}. Eine weitere der vier zentralen Marktversagensformen, ist jene der \textit{Natürlichen Monopole}. Ökonomen sprechen von einem natürlichen Monopol, wenn die Durchschnittskosten über den gesamten Mengenbereich über den Grenzkosten liegen. Anders ausgedrückt heißt das nichts anderes als, dass ein natürliches Monopol dann vorliegt, wenn die Fixkosten einen hohen Anteil der Gesamtkosten ausmachen. Dies ist überall dort der Fall wo eine große Infrastruktur geschaffen werden muss um das Produkt oder die Dienstleistung überhaupt anbieten zu können. Wenn die Infrastruktur aber einmal existiert, fallen nur mehr verhältnismäßig geringe Kosten für den laufenden Betrieb an. Beispielen dafür begegnen wir täglich. Das gesamte Verkehrsnetz, vor allem im Bereich der Eisenbahnen, ist ein Beispiel für ein natürliches Monopol. Aber auch das Strom- und Gasnetz, die Wasserversorgung oder das Kanalnetz, sowie das Telefonnetz und Postdienstleistungen sind Beispiele dafür. Stellen sie sich vor sie möchten als Privatunternehmen in den Eisenbahnverkehr einsteigen. Bevor sie auch nur eine Fahrt starten könnten, müssten sie Eisenbahnschienen verlegen. Ein eventuell bereits vorhandenes Schienennetz gehört schließlich nicht ihnen und sie können damit vom Gebrauch leicht ausgeschlossen werden. Jetzt ist es jedoch aus ökonomischen, aber auch aus raumplanerischen und nicht zuletzt ökologischen Gründen, völlig undenkbar, dass jeder potenzielle Anbieter sein eigenen Schienennetz erstellt. Ein einziges Schienennetz pro Strecke ist die einzig sinnvolle Lösung. Der Eigentümer dieses Schienennetzes ist per Definition ein Monopolist. Da er weder aus rechtlichen Gründen, noch aufgrund ökonomischer Überlegenheit zum Monopolisten wurde, sondern aufgrund der Eigenschaft Eigentümer der notwendigen Infrastruktur zu sein, nennt man so eine Situation ein \textit{Natürliches Monopol}. Aufmerksamen Lesern mag vielleicht aufgefallen sein, dass alle gerade oben genannten Dienstleistungen früher auch in den westlichen Marktwirtschaften fast ausschließlich von staatlichen Unternehmen angeboten wurden. Dass dies heute nur mehr zum Teil der Fall ist, ist nicht zuletzt auf die bahnbrechende Arbeit von \textcite{Baumol1982, Baumol1982b} zurückzuführen. Darin zeigen die Autoren die wesentliche Bedeutung von Markteintritts- und Marktaustrittsbeschränkungen.  Wenn man nun - eine zugegebenermaßen zunächst recht theoretisch wirkende Überlegung - diese Beschränkungen abschafft, so führt schon allein dies, laut \textcite{Baumol1982}, dazu, dass sich der bisherige Monopolist potenzieller Konkurrenz ausgesetzt sieht und in weiterer Folge seine Preissetzung nicht mehr wie ein Monopolist vornimmt, sondern wie ein Anbieter auf einem perfekten Konkurrenzmarkt. Alleine das Abschaffen von Markteintritts- und Marktaustrittsbeschränkungen führt also dazu, dass aus einem Monopolmarkt praktisch ein perfekter Konkurrenzmarkt wird \parencite[S. 2]{Baumol1982b}. Damit verbunden sind all die positiven Effekte: Niedrigerer Preis und höhere ausgebrachte Menge. Der Grund liegt einfach darin, dass die erhöhten Gewinnmöglichkeiten auf Monopolmärkten leicht erkannt und von Konkurrenten ausgenutzt werden können, wenn es keine Zugangsbeschränkungen gibt. Als Resultat verschwindet der Monopolvorteil aufgrund von Marktkräften und der Markt wird zum perfekten Konkurrenzmarkt. Der zweite Wohlfahrtseffekt ist ebenso bedeutend. Monopolmärkte tendieren dazu nicht ökonomisch effizient zu arbeiten. Wer der Chance hat eine Monopolrente abzuschöpfen und sich keinem Konkurrenzdruck ausgesetzt sieht, wird mit der Zeit immer weniger effizient arbeiten. Nach \textcite{Leibenstein1966} nennt man dieses Problem das Auftreten von \textit{X-Efficiency}. Wer früher einen Telefonanschluss haben wollte, musste diesen bei der staatlichen Behörde beantragen und war nicht selten deren Willkür und damit langen Wartezeiten ausgesetzt. Heute, am offen zugänglichen Telekommunikationsmarkt, wird man als potenzieller Kunde geradezu umgarnt von Anbietern\footnote{Das Beispiel hinkt zugegebenermaßen, weil im angesprochenen Bereich der technische Fortschritt wohl einen größeren Beitrag zur besseren Marktentwicklung beigetragen hat.}. 
Kommen wir zurück zum entscheidenden Punkt: Was sind Markteintritts- und Marktaustrittsbeschränkungen überhaupt? Gemeint sind damit Kosten, die ein Unternehmen leisten muss, bevor es überhaupt auf einem Markt als Anbieter auftreten kann. In einem natürlichen Monopol stellen diese Kosten also zum Beispiel die Herstellungskosten für das Schienennetz dar. Das Abschaffen dieser Markteintritts- und Marktaustrittsbeschränkungen bedeutet aber nicht, dass die Kosten auf Null reduziert werden, sondern, dass ein am Markteintritt interessiertes Unternehmen keinerlei Benachteiligungen haben darf gegenüber dem Monopolinhaber \parencite[S. 3f.]{Baumol1982b}. Ökonomisch ist das Thema mit dem Satz "`Abschaffen von Markteintritts- und Marktaustrittsbeschränkungen"' abgedeckt. Auf anderer - nämlich rechtlicher - Ebene wurde damit ein riesiges Feld geöffnet: Das Wettbewerbs- und Regulierungsrecht wurde damit wesentlich erweitert. Es muss nämlich ein Rahmen geschaffen werden, der den bisherigen Monopolisten und damit Inhaber der Infrastruktur dazu bringt, allen interessierten Mitbewerbern zu fairen Preisen Zutritt zum Markt zu gewähren. Dies funktioniert meist so, dass die Infrastruktur in ein eigenes staatliches Unternehmen ausgegliedert wird und eine neu geschaffenen Kontrollbehörde den Marktzutritt zu fairen Preisen zusichert. Auf sehr umkämpften Märkten, vor allem auf den mobilen Telekommunikationsmärkten, wurden in der Folge Lizenzen an die Höchstbieter vergeben, wobei die Vergabeverfahren ein eigenes Forschungsfeld aufmachten: Die sogenannten \textit{Auktionstheorie}, die vor allem durch spieltheoretische Überlegungen geprägt ist. In diesem Bereich wurde 2020 der Nobelpreis für Wirtschaftswissenschaften an \textit{Paul Milgrom} und \textit{Robert Wilson} vergeben. Ein anderes Forschungsfeld, das auch auf spieltheoretischen Überlegung basiert, ist jenes des sogenannten \textit{Marktdesigns}. Dabei geht es um die Gestaltung der Märkte, die ursprünglich natürliche Monopolmärkte waren. In diesem Bereich wurde bereits 2012 der Nobelpreis für Wirtschaftswissenschaften an \textit{Alvin Roth} und \textit{Lloyd Shapley} vergeben\footnote{Beide Themen werden im Kapitel \ref{cha: Spieltheorie} näher behandelt.}. Wie man sieht stieß das Konzept insgesamt einen riesigen Forschungsbereich an. Dahingehend ist es überraschend, dass William Baumol selbst niemals Nobelpreisträger wurde, obwohl er das hohe Alter von 95 Jahren erreichte. 

Insgesamt war das Modell theoretisch extrem einflussreich. Interessanterweise spielt es eher den polit-ökonomisch liberalen Tendenzen der 1980er Jahre in die Hände. Schließlich wird einer Form des Marktversagens nicht mehr durch staatliche Eingriffe entgegengetreten, sondern durch eine reine Marktlösung, gepaart mit gesetzlichen Vorgaben. Die Theorie passt damit eher zur \textit{Neuen Institutionsökonomik} (Kapitel \ref{Neue Institut}) oder sogar zur \textit{Neuen Klassischen Makroökonomie} (Kapitel \ref{Neue Makro}). Dabei ist Baumol zumindest letztgenannter Schule keineswegs zuzurechnen. Auch praktisch war die Umsetzung sofort ein Erfolgsmodell. Die Umsetzung erfolgte praktisch nahtlos an das Erscheinen des Buches \textcite{Baumol1982}. Vorreiter war Großbritannien, wo Margaret Thatcher noch in den 1980er Jahren Transportunternehmen privatisieren ließ. Anfang der 1990er Jahre erfolgte die große Privatisierungswelle in den westlichen Industriestaaten vor allem auf den Telekommunikationsmärkten, dem Eisenbahnwesen und der Versorgungsindustrie (vor allem Elektrizität). Aus heutiger Sich ist diese Umsetzung insgesamt wohl eine Erfolgsgeschichte. Vor allem wenn man auf sicherlich vorhandene X-Effizienzen in verkrusteten, staatlichen Unternehmen denkt. Mittlerweile kann man aber auch wesentliche Kritikpunkte nicht von der Hand weisen. So unterblieben in vielen Ländern, als Antwort auf die Liberalisierung, wichtige Investitionen in die Infrastruktur. Das traurigste Negativbeispiel ist wohl die Privatisierung der Eisenbahn in Großbritannien. Ende der 1990er-Jahre kam es dort zu zwei schweren Zugunglücken, die auf den schlechten Zustand der Infrastruktur und damit letztendlich auf die Liberalisierung des Eisenbahnverkehrs, zurückgeführt werden. Auch abgesehen davon funktionierte der private Eisenbahnmarkt in Großbritannien schlecht und so gibt es seit 2020 Tendenzen den Betrieb wieder gänzlich zu verstaatlichen. Es gibt aber auch den USA und in Kontinentaleuropa zahlreiche Negativbeispiel. Das Problem liegt hierbei häufig darin, dass die Umsetzung ganz wesentlich von der Schaffung eines rechtlichen Rahmenwerkes abhängt. Diese Regulierung zu schaffen ist schwierig und in der Praxis häufig gescheitert.

Einen weiteren, gänzlich anderen aber ebenso unkonventionellen, Beitrag zur Theorie der öffentlichen Wirtschaft lieferte \textit{William Baumol} bereits Mitte der 1960er Jahre \parencite{Baumol1965, Baumol1967}. Das exogene Wachstumsmodell von Robert Solow war schon als Standardmodell etabliert, als William Baumol einen interessanten Problempunkt darin aufzeigte. Er unterscheidet zwei Arten von Unternehmungen. Eine, die stark Technologie-getrieben ist und eine zweite, bei der Technologie nur eine untergeordnete Rolle spielt. Baumol selbst nannte diese "`stagnierenden Sektor"' und "`progressiven Sektor"' \parencite[S. XX]{Baumol2012}. Man könnte sie aber auch grob als Produktionsunternehmen und Dienstleistungsunternehmen bezeichnen. Entscheidend ist, dass erstgenannte vom technologischen Fortschritt profitieren. Mit besserer Technologie steigt die Produktivität in diesem Sektor an. Im zweitgenannten Sektor gibt es hingegen keine Produktivitätszugewinne durch verbesserte Technologie. Baumol's klassisches Beispiel dafür - er war ein bekennender Kunst- und Musikliebhaber \parencite[S. 228]{Krueger2001Interview} - war jenes vom Streichquartett, das für ein Musikstück heute noch immer so lange braucht wie vor 200 Jahren. Für die Herstellung eines Stahlträgers werden hingegen heute wesentlich weniger Arbeitsstunden benötigt, als im frühen 19. Jahrhundert. Daraus kann man ableiten, dass der Aufwand (und damit die Kosten) für ein Streichquartett gleich geblieben sind, während die Kosten für einen Stahlträger relativ dazu gesunken sind. Bei einer angenommenen Inflation von zum Beispiel 4\% würden Dienstleistungen dementsprechend eine höhere Inflation erfahren, als Produktionsgüter. Oder mit anderen Worten: Dienstleistungen wie medizinische Leistungen, Pflege und Ausbildung werden im Verhältnis zu Produktionsgütern wie Kleidung, Fernseher und Autos immer teurer. In der Ökonomie ist dieses Phänomen als die \textit{Kostenkrankheit}\footnote{Auch als \textit{Baumol's Disease} oder \textit{Bowen's curse} bezeichnet\parencite[S. 3]{Baumol2012}.} bekannt.
Die Folge der Kostenkrankheit ist, dass sich die Anteile an den Gesamtausgaben immer stärker von den Industriegütern zu den Dienstleistungen verschieben. Laut \textcite[S. 43]{Baumol2012} ist dies aber kein Problem. Wenn die Produktivität für einen Teil der geleisteten Arbeitsstunden steigt, für einen Teil konstant bleibt, aber für keinen Teil sinkt, dann steigt die Produktivität auch im Durchschnitt. Damit steigt insgesamt die Produktion und damit das GDP. Dass sich das Verhältnis zwischen Gütern und Dienstleistungen dadurch verschiebt und damit zum Beispiel der Anteil der Kosten für Gesundheitsdienstleistungen immer weiter steigt, ist zwar ein Faktum, aber im Endeffekt von sekundärer Bedeutung. Die Kostenkrankheit wäre demnach eher ein Verteilungsproblem als ein Problem stagnierender Produktivität. 

\textcite{Nordhaus2008} hat die möglichen Auswirkungen der Kostenkrankheit analysiert, zusammengefasst und empirisch untersucht. Er kam zu dem Schluss, dass sich die Baumolsche Kostenkrankheit in sechs Symptomen zeigt. Die Kosten und Preise müssten auf stagnierenden Märkten überdurchschnittlich stark steigen (1), der reale Output in diesen Sektoren sollte aber nur unterdurchschnittlich steigen (2). Wenn stagnierende Märkte Preis-unelastisch sind, dann müsste der Anteil dieser Märkte am Gesamt-BIP steigen (3), dies würde das Gesamtwachstum der Produktivität reduzieren (4). Unternehmen auf stagnierenden Märkten werden zunehmend Kosten- und Preisdruck ausgesetzt und schließlich vermehrt finanzielle Probleme haben (5). Zuletzt stellt sich die Frage, wie sich die Kostenkrankheit auf die Gesamtbeschäftigung auswirkt (6). \textcite{Nordhaus2008} kommt zu dem Ergebnis, dass für die USA seit 1948 die ersten drei Symptome eindeutig zu erkennen sind. Auch das Wachstum in der Produktivität hat sich seit 1948 verlangsamt. Interessanterweise könnte Nordhaus nicht bestätigen, dass vor allem Unternehmen in progressiven Sektoren vom technologischen Fortschritt profitieren und im Umkehrschluss Unternehmen im stagnierenden Sektor in Probleme geraten. Stattdessen werden die Vorteile, die in progressiven Sektoren beobachtet werden, tendenziell an den Endkunden weitergegeben. Das heißt Produkte im aus dem progressiven Sektor werden relativ gesehen immer günstiger. Der letzte Punkt ist nicht eindeutig zu beantworten. Es gibt Industrien, in denen technologischer Fortschritt zu einem Ersatz der Arbeitskräfte durch Maschinen führt. Eine relativ dazu steigende Anzahl an Personen ist dann in stagnierenden Sektoren tätig. Es gibt aber auch Industrien, wo der technologische Fortschritt zu einer steigenden Nachfrage nach Arbeitskräften führt \parencite{Nordhaus2008}.

Das Konzept hat damit eben auch spannende wirtschaftspolitische Auswirkungen. Da der Staat fast ausschließlich für die zur Verfügung-Stellung von Dienstleistungen zuständig ist, der private Sektor hingegen nach wie vor einen gehörigen Anteil an Produktionsunternehmen hat, müsste es dazu kommen, dass die staatlichen Leistungen im Verhältnis zu privatwirtschaftlichen Leistungen im Durchschnitt immer teurer werden. Das heißt, die Staatsquote müsste mit steigender Produktivität ebenfalls steigen, wenn die staatlichen Dienstleistungen in gleicher Qualität und Quantität aufrechterhalten werden sollen. Dies wäre auch eine Erklärung für das Wagner'sche Gesetz \parencite{Wagner1892}, das postuliert, dass mit steigendem Wohlstand auch die Staatsquote zunimmt. Es steht aber auch im Spannungsverhältnis mit wachsendem Budgetdruck und dem Trend zu sinkenden Staatsquoten.