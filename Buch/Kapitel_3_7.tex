%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Spieltheorie} \label{cha: Spieltheorie}
\label{Spieltheorie}

Sie wird häufig als Spezialfall und Weiterentwicklung der Entscheidungstheorie, oder als "`Interaktive Entscheidungstheorie"' bezeichnet und in der Ökonomie noch immer eher als Randthema behandelt, dabei ist sie wohl eine \textit{der} wesentlichen Weiterentwicklungen der Wirtschaftswissenschaften im 20. Jahrhundert: Die Spieltheorie. Ihre Bedeutung kann kaum überschätzt werden. Sowohl in der Mikroökonomie, als auch in der Makroökonomie ist die Spieltheorie Teil unzähliger Modelle. Auch diesbezüglich wandelte sich die Ökonomie: Ausgehend von den Neoklassikern, aber eben auch die Keynesianer und die Monetaristen, suchten nach "`Pareto-optimalen"' Lösungen. Deren Modelle gehen von vollkommenen Konkurrenzmärkten aus, alle Teilnehmer sind Preisnehmer. Sie optimieren also ihr individuelles Verhalten im Anbetracht eines Marktgleichgewichts. Vertreter der Neuen Neoklassischen Synthese hingegen sprechen stattdessen meist von "`Nash-Gleichgewichten"' - also einem spieltheoretischen Gleichgewichtszustand.  Diese neueren Modelle (vgl. Kapitel \ref{cha: Neu Keynes} und \ref{Neue Neoklassische Synthese}, aber auch der Bereich Politische Ökonomie) berücksichtigen, dass die Annahme vollkommener Konkurrenzmärkte häufig unrealistisch ist. Die entsprechenden Optimierungsaufgaben hängen also wechselseitig vom Verhalten der Marktgegenseite ab. 

Wie bereits beschrieben, fristet die Spieltheorie dennoch in gewisser Art und Weise eine Außenseiterrolle innerhalb der Ökonomie. Über die Gründe kann man hier nur spekulieren. Wahrscheinlich spielt es aber eine Rolle, dass die Spieltheorie keine volkswirtschaftliche Theorie im eigentlichen Sinne ist. Ganz im Gegenteil, ihre Aussagen sind auch in der Politik, Biologie - berühmt dazu: \textcite{Price1973} als ein Ausgangspunkt der Evolutionären Spieltheorie -, Betriebswirtschaft, Spiel und Sport von Interesse. Dazu passt auch, dass die Spieltheorie nicht von Ökonomen, sondern von Mathematikern entwickelt wurde. Tatsächlich findet man Vorlesungen zur Spieltheorie aber vor allem in wirtschaftswissenschaftlichen Curricula wieder. Zuletzt ist es wohl kaum zu bestreiten, dass die Spieltheorie - stärker als jede andere Disziplin - von bemerkenswerten und oft kontroversen Persönlichkeiten geprägt wurde, von denen uns in diesem Kapitel mehrere unterkommen werden. Auch was ihre Verbreitung angeht, war die Spieltheorie besonders. Die ersten Interessenten an spieltheoretischen Konzepten waren vor allem militärische Vertreter. Thomas Schelling zum Beispiel wurde mit der spieltheoretischen Analyse militärischer Konflikte berühmt \parencite{Schelling1960}, wobei seine Arbeiten wenig formal sind. John Nash lieferte zwar unbestritten einen der bis heute wichtigsten Beiträge der Spieltheorie, seine Arbeit wurde aber erst durch die hoch-theoretischen Weiterentwicklungen von Reinhard Selten und John Harsanyi in den 1960er und 1970er Jahren weitverbreitet bekannt. John Nash trug durch seine Erkrankung, natürlich unverschuldet, selbst wenig zur Verbreitung seiner Theorie bei. Reinhard Selten publizierte seine Beiträge lange Zeit in seiner Muttersprache Deutsch und noch dazu in wenig renommierten Journalen, weil ihn die Journal-Review-Prozesse störten \parencite[S. 215]{Frey2003}.

Was ist Spieltheorie grundsätzlich? \textcite[S. 136]{Harsanyi1994} bringt es in einem Satz auf den Punkt: "`Spieltheorie ist eine Theorie der strategischen Interaktion. Das heißt, sie ist eine Theorie des rationalen Verhaltens in Situationen, in denen jeder Spieler die wahrscheinlichen Gegenzüge seines Gegenspielers bedenkt und darauf basierend seine eigenen Züge setzt."' Das erinnert in erster Linie an wirkliche Spiele wie Mühle, Schach oder Poker. Tatsächlich berechnen Profis beim Poker mittels spieltheoretischer Ansätze die Gewinnwahrscheinlichkeit ihrer "`Hand"'. Der Name \textit{Spiel}theorie ist dennoch etwas irreführend, weil sie in der Realität auf verschiedene Situationen angewendet werden kann, wie individuelle soziale Interaktionen, politische Konflikte, oder eben in verschiedenen wirtschaftlichen Situationen. Die frühe Spieltheorie bei Von Neumann und Morgenstern behandelte sogenannte Nullsummen-Situationen. Das sind Situationen in denen die Gewinne des einen Spielers betragsmäßig den Verlusten seines Gegenspielers stets entsprechen. Eine Situation, die eben tatsächlich vor allem bei wirklichen Spielen auftritt: Wenn Weiß beim Schach einen Läufer verliert kann man auch vom Gewinn eines Läufers durch Schwarz sprechen. Eine wesentliche Erweiterung erfuhr die Spieltheorie Anfang der 1950er Jahre durch John Forbes Nash, dessen Arbeit die Spieltheorie auch auf Nicht-Nullsummen-Situationen ausweitete \parencite[S. 163]{Nash1994}. Wirtschaftliche Kooperation zum Beispiel kann dafür sorgen, dass \textit{beide} "`Spielteilnehmer"' ihre Position verbessern. Berühmt geworden sind aber vor allem jene Beispiele, bei denen individuelle Nutzenmaximierung zu gesamtwirtschaftlich schlechten Ergebnissen führen - dazu aber später mehr, Stichwort: Gefangenendilemma.

Vorab machen wir das abstrakte Feld der Spieltheorie ein bisschen greifbarer. Die nachstehende Grafik zeigt eine typische Darstellung eines spieltheoretischen Problems. Konkret handelt es sich um ein \textit{nicht kooperatives} (das sieht man nicht aus der Darstellung), \textit{zwei Personen, Nicht-Nullsummen}-Spiel. \textit{Spieler 1} kann aus seinen beiden Strategien wählen \textit{Leugnen, $S_{1,1}$} oder \textit{Gestehen, $S_{1,2}$}. Das Gleiche gilt hier für \textit{Spieler 2}. Es entsteht eine $2x2$-Matrix mit jeweils einem Auszahlungspaar, wobei die erste Zahl jeweils als der Nutzen für Spieler 1 gelesen werden kann. In diesem Fall ist der Nutzen negativ angegeben, was nur ausdrückt, dass man seinen Nutzen maximiert, indem man den geringsten negativen Betrag anstrebt. Vorweggenommen: Rein intuitiv ist klar, welche Lösung gesamtwirtschaftlich (Spieler 1 und Spieler 2 stellen die Gesamtwirtschaft dar) angestrebt wird: Beide sollten die Strategie \textit{Leugnen} wählen. Gesamtwirtschaftlich tritt dann der größte Nutzen (=kleinster Schaden) ein und die Situation keines Spielers könnte verbessert werden \textit{ohne} die Situation des anderen zu verschlechtern. Definitionsgemäß ist ein Pareto-Optimum erreicht. Aber zu welcher Lösung kommt man mit spieltheoretischen Ansätzen? - auch dazu im Laufe des Kapitels mehr.


\begin{tikzpicture}[element/.style={minimum width=3.0cm, minimum height=0.8cm}]
\matrix (m) [matrix of nodes,nodes={element},column sep=-\pgflinewidth, row sep=-\pgflinewidth,]{
	& Leugnen $S_{2,1}$  & Gestehen $S_{2,2}$  \\
	 Leugnen $S_{1,1}$ & |[draw]|-2 / -2 & |[draw]|-10 / -1 \\
	 Gestehen $S_{1,2}$ & |[draw]|-1 / -10 & |[draw]|-8 / -8 \\    };

\node[above=0.15cm] at ($(m-1-2)!0.5!(m-1-3)$){\textbf{Spieler 2}};
\node[rotate=90] at ($(m-2-1)!0.5!(m-3-1)+(-1.25,0)$){\textbf{Spieler 1}};
\end{tikzpicture}

Diese Form der Darstellung wird übrigens "`Normalform"' genannt. Die zweite übliche Darstellungsform nennt man "`extensive Form"'. Diese umfasst für den gesamten Spielverlauf alle notwendigen Informationen zu Entscheidungen und Auszahlungen und gleicht von der Darstellung her einem Entscheidungsbaum. Beide Formen werden laut \textcite{Selten2001} übrigens schon seit der Geburtsstunde der Spieltheorie so verwendet.


\section{Der Vater der Spieltheorie: John von Neumann}

Vereinzelte Ansätze, die Ideen der Spieltheorien vorwegnahmen, gab es bereits im 19. Jahrhundert. Das bekannteste Beispiel ist wohl die Duopol-Theorie von \textcite{Cournot1838}. Weithin gilt aber die Veröffentlichung des fundamentalen Werks "`Theory of Games and Economic Behavior"' im Jahr 1944 durch Oskar Morgenstern und John von Neumann als Ursprung der Spieltheorie. \textcite{VonNeumann1928} behandelte bereits einen speziellen Ansatz der Theorie, im Buch von 1944 wurde dieser verbreitert und verallgemeinert. In der zweiten Auflage im Jahr 1947 wurde der Beweis für die Axiome der Erwartungsnutzentheorie erbracht. Diese haben wir bereits im Kapitel \ref{Erwartungsnutzen} kennen gelernt und sind eigentlich mehr Voraussetzung für die Spieltheorie als Teil derselben \parencite[S. 3]{Selten2001}. 

Als "`Vater der Spieltheorie"' gilt also John von Neumann. Ein Mathematik-Genie, tätig in unzähligen Gebieten. Er gilt daneben als einer der Entwickler des modernen Computers, entwickelte eine binäre Programmiersprache,  arbeitete an der Entwicklung der Quantenmechanik, sowie bei der Entwicklung der Nuklearwaffen mit. \textcite[S. 232]{Bernstein1996} zitiert, dass er "`während seiner Zeit beim Militär Admiräle gegenüber Generälen bevorzugte, da diese trinkfester waren"' und weitere Geschichten, die ihn als lebenslustiges Genie darstellen. Der Beitrag seines Koautors Oskar Morgenstern - der in Österreich das Institut für Höhere Studien mitbegründete - wird in der modernen Literatur häufig als eher gering dargestellt. \textcite[S. 494]{Leonard1994} schreibt, dass Morgenstern, erstens unter Ökonomen-Kollegen in den USA recht unbeliebt\footnote{\textcite[S. 14]{Selten2001} stellt Morgenstern hingegen als einen offenen und ihn unterstützenden Forscher dar.} war und zweitens, einen \textit{inhaltlich} bescheidenen Beitrag zur hoch-mathematischen Spieltheorie von Neumann's geleistet hat. Insbesondere im Artikel \textcite{Morgenstern1976} stellt der Autor seinen eigenen Beitrag zur Entstehung der "`Theory of Games and Economic Behavior"' anders dar. Laut \textcite{Nash1994} ist es aber unzweifelhaft, dass dieses fundamentale Werk ohne die Zusammenarbeit von Oskar Morgenstern und John von Neumann in dieser Form nicht entstanden wäre.

Aus heutiger Sicht betrachteten \textcite{VonNeumann1944} ein sehr spezielles Problem, nämlich vor allem statische, zwei Personen Nullsummenspiele. Statisch bedeutet hierbei, dass die Spiele nur einmal durchgeführt werden, im Gegensatz zu den später spieltheoretisch analysierten "`wiederholten Spielen"'. Das ist wichtig, wenn man Gewinnwahrscheinlichkeiten in Verbindung mit dem individuellen Nutzen analysiert: Bei unendlich wiederholten Spielen wird sich der realisierte Gewinn dem Erwartungswert annähern. Wird nur einmal gespielt ist die Gewinnerwartung zwar identisch, aber die tatsächliche Realisation weicht deutlich in die eine oder andere Richtung ab.
Anhand eines konkreten Beispiels bedeutet dies folgendes: Beim Münzwurf ist die Wahrscheinlichkeit, dass "`Kopf"' erscheint ebenso 50\% wie dafür, dass "`Zahl"' erscheint. Spielt man nun mit einem Gegenspieler um einen identisch hohen Einsatz von beiden Seiten, so kann man mit einer rein \textit{zufälligen} Wahl zwischen "`Kopf"' oder "`Zahl"' eine Gewinneintrittswahrscheinlichkeit von 50\%, sowie einen Erwartungswert von 0 Euro erzielen. Wählt Spieler 1 eine bewusste Strategie, wie zum Beispiel immer "`Kopf"' zu wählen, besteht die Gefahr, dass diese Strategie dem Gegner bekannt wird. Ist dies der Fall wird der Gegner diese ausnutzen und für sich eine höhere Gewinneintrittswahrscheinlichkeit erreichen. Fazit: Für beide Seiten gibt es keine bessere Strategie als zufällig "`Kopf"' oder "`Zahl"' zu wählen. Diese Strategie ist ein Beispiel für eine "`Minimaxstrategie"'. Damit können sich beide Spieler ihr maximales Ergebnis - einen Erwartungswert von 0 -  sichern, wenn der andere ebenfalls eine Maximinstrategie anwendet. Das ergibt sich daraus, dass die Summe der beiden Werte Null ist. Wichtig ist aber, dass Erwartungswert von mindestens 0 auch dann erreicht, wenn sich der Gegenspieler irrational verhält und nicht die optimale Maximinstrategie anwendet \parencite{Selten2001}.  Dieses Spiel, sowie die Aussage, dass die Summe aller Auszahlungen in Zwei-Personen-Nullsummenspielen Null ist klingt banal. Die mathematische Beweisführung dafür in \textcite{VonNeumann1928} ist aber alles andere als banal und wird heute häufig als "`Hauptsatz der Spieltheorie"' bezeichnet. Das Buch von \textcite{VonNeumann1944}: "`Theory of Games and Economic Behavior"' gilt bis heute den Ausgangspunkt der Spieltheorie, auch wenn deren zentrales Konzept, die Maximinstrategie nur mehr geringe Bedeutung in der aktuellen Wissenschaft hat. Das Werk hat eine ganz neue Sparte der quantitativen Methoden begründet, die in den verschiedensten Wissenschaftsgebieten Anwendung findet. Wesentliche Konzepte, wie Bezeichnungen und Darstellungsformen sind bis heute "`State of the Art"' innerhalb der Spieltheorie. Interessant ist auch, dass die in der Mikroökonomie so wichtige Nutzentheorie - konkret die Bildung der formalen Axiome der Nutzentheorie und die Quantifizierbarkeit des Erwartungsnutzentheorie - quasi als Nebenprodukt von \textcite{VonNeumann1944} entscheidend weiterentwickelt wurde.


\section{John Nash: Das tragische Genie}
Berührend ist die Geschichte von John Forbes Nash, die durch den Film "`A Beautiful Mind"' weit über wissenschaftliche Kreise hinaus bekannt wurde. Nash verfasste 1950 eine geniale und nur großzügige \parencite[S. 164]{Nash1994} 27 Seiten lange Dissertation \parencite{Nash1950}, die später als Journalbeiträge publiziert wurde \parencite{Nash1951}, und mit der er die Spieltheorie entscheidend weiterentwickelte. Ende der 1950er Jahre erkrankte er aber schwer an Schizophrenie und war die folgenden 25 Jahre stark eingeschränkt. Erst in seinen Fünfzigern erholte er sich. 1994 wurde ihm gemeinsam mit Reinhard Selten und John Harsanyi der Nobelpreis für Ökonomie zugesprochen. In einem interessanten Interview \parencite{Nash2004}\footnote{https://www.nobelprize.org/prizes/economic-sciences/1994/nash/interview/} im Rahmen des Ersten Nobelpreisträgertreffens im Jahr 2004 erzählt er, dass die Verleihung des Nobelpreise einen enormen Einfluss auf sein Leben hatte, war er doch zuvor schon lange Zeit arbeitslos, obwohl er schon längere Zeit bei guter Gesundheit war und er daher mehr oder weniger kaum noch am öffentlichen Leben teilnahm. Die Tragik in seinem Leben setzte sich übrigens bis zu seinem Tod fort: Im Jahr 2015 erhielt er den Abel-Preis, eine Auszeichnung für Mathematiker. Bei der Rückkehr aus Norwegen, wo der Preis verliehen wird, war das Taxi, das ihn vom Flughafen nach Hause bringen sollte, in einen Autounfall verwickelt, der Nash und seiner Frau das Leben kostete. 

Nash erweiterte die Erweiterung in verschiedener Hinsicht. Am grundlegendsten ist wohl seine \textit{Unterscheidung} zwischen "`Kooperativer Spieltheorie"' und "`Nicht-kooperative Spieltheorie"'. In Letztgenannter geben Spieler kein Commitment zu einer bestimmten Strategie ab, während bei der "`Kooperativen Spieltheorie"' durchsetzbare Verträge vorhanden sein können.
Den größten nachhaltigen Beitrag stellt sicherlich seine Gleichgewichtslösung für nicht-kooperative Spiele dar \parencite{Nash1951, Nash1950b}. Studierende der Ökonomie kennen vor allem deshalb seinen Namen, selbst dann, wenn ihr Studium keine Vorlesung zur Spieltheorie enthält. Schließlich haben diese "`Nash-Gleichgewichte"' in der modernen Ökonomie einen Fixplatz in vielen Modellen eingenommen. Für "`Nicht-kooperative Spiele"' bewies Nash, dass es in solchen Situation immer zumindest ein Nash-Gleichgewicht gibt. Also ein Gleichgewicht, in dem kein Spieler seine Auszahlungen erhöhen kann, indem er einseitig seine Strategie verändert. Das Konzept des Nash-Gleichgewichtes ist grundsätzlich damit erklärt, in der Realität aber recht schwierig vollständig zu erfassen. Um ein Nash-Gleichgewicht zu finden, muss man in einem zwei-Personen Spiel zunächst die "`besten Antworten"' auf alle Strategien des Gegenspieler suchen. Angewendet auf die obenstehende Grafik würde das bedeuten Spieler 1 überlegt sich nacheinander, welche Strategie - Leugnen oder Gestehen - er spielen würde, gegeben Spieler 2 spielt seinerseits eine \textit{bestimmte} Strategie. Spieler 1 hat nun seine "`besten Antworten"' gefunden. Dies allein bringt aber noch gar nichts, denn entscheidend ist der zweite Schritt. Spieler 1 muss nämlich davon ausgehen, dass auch Spieler 2 in gleicher Weise vorgeht. Das heißt, Spieler 1 berücksichtigt, dass Spieler 2 seinerseits die besten Antworten auf die verschiedenen Strategien von Spieler 1 identifiziert. Findet sich nun ein Strategiepaar, von dem keiner der beiden Spieler ein Grund hat einseitig abzuweichen, liegen wechselseitig beste Antworten vor und somit ein Nash-Gleichgewicht.

Betrachten wir diese Vorgehensweise anhand der dargestellten Matrix: Spieler 1 betrachtet also nacheinander möglichen Strategien von Spieler 2. Sollte dieser "`Leugnen $S_{2,1}$"' (Beachten Sie nur Spalte 1), so müsste Spieler 1 zweifellos "`Gestehen $S_{1,2}$"' als "`beste Antwort"' wählen. Schließlich würde er so seinen Nutzen von -2 auf -1 erhöhen. Sollte Spieler 2 "`Gestehen $S_{2,2}$"' (Beachten Sie nur Spalte 2), so müsste Spieler 1 ebenfalls mit "`Gestehen $S_{1,2}$"' antworten, da der Nutzen von -10 auf -8 steigt. Die Betrachtung des Spiels aus Sicht von Spieler 2 sieht in diesem Fall genau identisch aus. Das Ergebnis ist also, dass beide Spiel jeweils "`Gestehen"' als "`wechselseitig beste Antwort"' identifizieren. 

Das dargelegte Beispiel ist das "`Gefangenendilemma"', welches der Doktorvater und Förderer von Nash, Albert Tucker, im Frühjahr 1950 für eine Psychologie(!)-Vorlesung in Stanford entwickelte \parencite[S. 161]{Nash1994}. Darin wird ein Verbrecherduo unabhängig voneinander verhört. Leugnen beide, kann man ihnen wenig nachweisen und beide kommen nach zwei Jahren aus dem Gefängnis. Leugnet nur einer, profitiert er von der Kronzeugenregelung und kommt nach einem Jahr frei, während sein Partner die Höchststrafe absitzen muss. Gestehen beide, erhalten zwar beide eine kleine Milderung, kommen aber erst nach acht Jahren frei. Bei Gesamt-Betrachtung wäre es natürlich am besten für beide zu Leugnen. Wir haben aber gerade gesehen, dass es individuell Nutzen-maximierend ist zu gestehen. Das gefundene Nash-Gleichgewicht (beide Gestehen) führt zu der paradoxen Lösung ist, dass das insgesamt schlechtest-mögliche Ergebnis - nämlich beide "`sitzen"' für jeweils acht Jahre - realisiert wird. Haben Sie schon mal überlegt, was eine Kronzeugenregelung bringen soll? - Ganz genau, formalisiert betrachtet ist die Kronzeugenregelung ein spieltheoretischer Ansatz Gesetzesbrecher dazu zu bringen aus individuell-rationalen Gründern zu gestehen. Bekannt wurde in diesem Zusammenhang auch das Beispiel von \textcite{Blinder1982}, in dem er eine entsprechende Dilemma-Situation in der Wirtschaftspolitik darlegte. So wäre es im Fall einer Wirtschaftskrise für den Staat rational expansive Fiskalpolitik zu betreiben. Eine unabhängige Zentralbank, die nur Preisstabilität als Ziel hat, müsste als (wechselseitig beste und strikt dominante) Antwort darauf eine restriktive Geldpolitik durchführen, weil sie steigende Inflation aufgrund der expansiven Fiskalpolitik befürchtet. Dieses Nash-Gleichgewicht wäre genau das Gegenteil vom eigentlich wünschenswerten Vorgehen, das laut \textcite{Blinder1982} eine expansive Geldpolitik bei restriktiver Fiskalpolitik wäre. Aber es gibt durchaus auch aktuelle und lebensnahe Beispiele: Haben Sie sich schon mal geärgert warum die Leute so "`dumm"' sind und ihren eigenen Planeten ausbeuten und die Umwelt zerstören? Menschen und auch Entscheidungsträger - also Politiker - sind keineswegs dumm. Aber wenn eine einzelne Person (oder Staat), für sich entscheidet "`Null-Emissionen"' zu verursachen, bewirkt dies für die gesamte Umwelt verschwindend wenig, vermindert aber die Lebensqualität des Einzelnen ganz erheblich. Nachdem wir das alle wissen, starten wir erst gar nicht damit "`Null-Emissionen"' anzustreben. Eben eine Dilemmata-Situation. Aber keine Dummheit, sondern individuell Nutzen-maximierendes Verhalten \parencite{Samuelson1954}\footnote{Moderne spieltheoretische Überlegungen (vgl. "`Mechanism Design"' im nächsten Unterkapitel) analysieren aber genau dieses Problem: Welcher Rahmen müsste geschaffen werden, dass es individuell-rational ist, die Umwelt zu schonen.}.

Das "`Gefangenendilemma"' wurde weltberühmt, wird in jedem Buch, welches Spieltheorie auch nur streift, erwähnt und gilt als \textit{das} Einführungsbeispiel schlechthin. Es ist aber in Wahrheit kein sehr gutes Beispiel, weil das Ergebnis durch "`strikt dominante Strategien"' der beiden Proponenten geprägt ist. Für beide Spieler gibt es nur eine optimale Strategie, \textit{unabhängig} davon was der andere Spieler macht. Diese Lösung ist also eine sehr einfache und derartige Spiele sind in der Realität selten. Das Beispiel neigt daher dazu die Komplexität der Spieltheorie zu unterschätzen. Interessante spieltheoretische Situationen entstehen erst, wenn die eigenen Erwartungen über das Verhalten der Gegenspieler miteinbezogen werden müssen. Die Lösungsfindung entspricht dann eben dem oben beschriebenen, zweistufigen Prozess. Allerdings führt der zweite Schritt nicht dazu, dass Spieler 1 eine Strategie findet, die er immer anwenden kann, weil sie strikt dominant ist. Stattdessen findet Spieler 1 heraus, dass er eine bestimmte Strategie spielen muss, damit er davon ausgehen kann, dass Spieler 2 ebenfalls keinen rationalen Grund findet von einer bestimmte Strategie abzuweichen. Wenn sich dadurch wechselseitig beste Antworten finden, handelt es sich um ein "`striktes Nash Gleichgewicht in reinen Strategien"'. Es sind auch Lösungen möglich, bei denen ein Spieler sich bei Abweichung weder verschlechtert noch verbessert, dann handelt es sich um ein "`schwaches Nash Gleichgewicht"'. Oftmals existieren schlicht keine "`wechselseitig besten Antworten"'. Dann existiert eben auch kein Nash-Gleichgewicht in \textit{reinen} Strategien. Dann müssen die Spieler sich "`zufällig"' für eine Strategie entscheiden. Formal werden dann die einzelnen Strategien mit Eintrittswahrscheinlichkeiten hinterlegt. Man spricht dann von einem "`Spiel mit gemischten Strategien"'. Ein typisches Beispiel hierfür wäre "`Stein, Schere, Papier"'. Es gibt keine optimale Strategie bei diesem Spiel. Im Gegenteil, jeder der beiden Spieler hat eine Gewinnchance von 50\%, wenn er \textit{rein zufällig} eine der drei Möglichkeiten wählt. Wenn ein Spieler systematisch immer "`Stein"' spielt, wird ein Gegenspieler dies erkennen und seine Handlung ausnutzen. Durch jede Abweichung vom reinen Zufall als Auswahlkriterium wird die eigene Gewinnchance also ausnahmslos verringert. \textcite{Nash1951} bewies, dass es in allen (endlichen) Spielen zumindest ein "`Nash-Gleichgewicht in gemischten Strategien"' gibt.

Das Nash-Gleichgewicht hat sich laut \textcite[S. 61]{Holler2005} aus zwei Gründen als die wesentliche Gleichgewichts-Strategie etabliert. Erstens, weil sich jeder Spieler darin rational verhält und zweitens, weil es der natürliche Endpunkt eines dynamischen Anpassungsprozesses ist, in dessen Verlauf die Spieler aus Enttäuschungen lernen. Gerade der zweite Punkt ist wichtig, denn häufig stößt man auf Unverständnis, wenn man das Nicht-Pareto-optimale Nash-Gleichgewichtsergebnis als Endzustand präsentiert, im Sinne von: "`Das gibt es doch nicht, dass die Spieler dieses Ergebnis akzeptieren, wenn doch alle wissen, es gäbe eine für alle bessere Lösung."'\footnote{Vor allem Pseudo-Wirtschaftswissenschaftliche Schulen, wie zum Beispiel die "`Gemeinwohl-Ökonomie"' verlocken mit solchen Argumenten.} Aber gerade der dynamische Anpassungsprozess ist das entscheidende, warum am Ende eben doch die suboptimale Nash-Lösung übrig bleibt. Angenommen sie wären einer von zwei Spielern im Gefangenendilemma und würden großmütig beschließen zu leugnen in der Überzeugung ihr Partner würde ebenso handeln. Erstens, kann sich ihr Partner nicht darauf verlassen, dass sie tatsächlich selbstlos handeln und müsste dementsprechend gestehen. Und zweitens - und das ist das entscheidende - wäre die Verlockung für ihren Partner nicht viel zu groß seine Strafe zu minimieren und selbst dann zu gestehen, wenn sie ihm versprechen zu leugnen? Beachten sie, dass sich im klassischen Gefangenendilemma-Beispiel die beiden Spieler offensichtlich kennen. In der Realität treffen aber Personen aufeinander, die sich, erstens, nicht kennen und zweitens, womöglich niemals wieder aufeinander treffen. In solchen Situationen wird der großmütige Partner solange ausgenutzt, bis er alle Ressource verloren hat, oder seine edle Strategie aufgibt. Die Spieltheorie im allgemeinen und Nash-Gleichgewichte im Speziellen, sind in diesem Zusammenhang keine rein akademischen Überlegungen, sondern das Ergebnis von täglich zu beobachtenden Situationen.

Laut einem Artikel von \textcite{Cassidy2015} war John von Neumann übrigens wenig beeindruckt von der Erweiterung "`seiner"' Spieltheorie durch Nash. Vielmehr sah er darin eine "`triviale Folge"' aus dem Fixpunkttheorem von \textcite{Brouwer1912}. Eine gewisse Paradoxie liegt aber schon darin, dass das 600-Seiten umfassende Monumentalwerk von \textcite{VonNeumann1944} durch die 27-seitige Dissertation von \textcite{Nash1950} so entscheidend weiterentwickelt wurde. Wichtige Wegbegleiter für Nash waren dessen Kommilitone Harold Kuhn und sein Doktorvater Albert Tucker, die in der Folge ebenfalls wichtige Beiträge zur Spieltheorie lieferten. Studierenden der Ökonomie sind die beiden aber vor allem für ihren Beitrag zur "`Nicht-linearen Optimierung"` und der dort verwendeten "`Kuhn-Tucker-Bedingung"' \parencite{Kuhn1951} bekannt. Vor allem Harold Kuhn soll laut \textcite{Rubinstein2003} das Nobelpreis-Komitee überzeugt haben, dass Nash's mentale Verfassung der Nobelpreis-Verleihung nicht im Wege stehen sollte. Diesen bekam Nash schließlich im Jahr 1994 tatsächlich verliehen, zusammen mit zwei Kollegen, die auf seinen Theorien aufbauend die Spieltheorie weiterentwickelten und im nächsten Unterkapitel behandelt werden.


\section{Die Etablierung der Spieltheorie durch Harsanyi, Selten, Aumann und Shapley}

Die Entwicklung der Spieltheorie fand mit den Arbeiten von Nash Anfang der 1950er Jahre zweifellos einen frühen Höhepunkt. Dies ist unter anderem daran festzumachen, dass "`Nash-Gleichgewichte"' wie oben dargestellt, noch immer ein wesentliches Entscheidungsinstrument in der modernen Ökonomie sind. Ein unmittelbarer Erfolg im Sinne einer breiten Wahrnehmung und öffentlichen Anerkennung, blieb Nash aber lange verwehrt (vgl.: \textcite{Nash2004}). Die Spieltheorie als Wissenschaft war zwar in der Folge durch die Arbeiten von Nash geprägt, allerdings war das Interesse zunächst auf einen relativ kleinen Forscherkreis beschränkt. Dieser verfeinerte und erweiterte die Spieltheorie in verschiedenen Bereichen. 

Ohne näher darauf einzugehen, wurde bislang angenommen, dass die zu spielenden Optionen (Strategiemengen der Spieler) und die daraus folgenden Ergebnisse (Auszahlungsfunktionen) jeweils allen Spielern bekannt sind. Wir sind also - ohne es so zu nennen - von einem "`Spiel mit vollständiger Information"' ausgegangen. Sämtliche Informationen sind dann gemeinsames Wissen ("`Common Knowledge"'), das \textcite{Aumann1976} formal beschrieben hat. Schon \textcite{VonNeumann1944} unterschieden zwischen "`Spielen mit vollständiger Information"' und solchen mit "`unvollständiger Information"', aber erst in den 1960er Jahren wurden letztgenannte tatsächlich spieltheoretisch analysiert \parencite[S. 137]{Harsanyi1994}. Damit wurde die Tatsache berücksichtigt, dass das Vorliegen vollständiger Information in der Realität häufig eher Ausnahme als Regel ist. "`Unvollständige Information"' bedeutet, dass die Spieler recht allgemein kein vollständiges Wissen über die Handlungen der Mitspieler, möglichen Strategien, Ressourcen oder Auszahlungsfunktionen der Gegner haben \parencite[S. 137]{Harsanyi1994}. Diese Unsicherheit besteht bereits vor Spielbeginn und ist das spieltheoretische Äquivalent zur "`Adversen Selection"', die in Kapitel \ref{Info} beschrieben wird. Neben der (Un)vollständigkeit der Information unterscheidet man weiters zwischen "`Perfekter"' und "`Imperfekter"' Information. Diese Unterscheidung schlug \textcite{Selten1965} erstmals vor \parencite[S. 166]{Nash1994}. Hier beschränkt sich der Informationsmangel auf konkrete, vergangene Handlungen der Gegenspieler.  Die Informationsasymmetrie tritt hier während des Spiels auf. Der Versuch diese Informationsvorteile einseitig zu nutzen kann als die spieltheoretische Analyse des "`Moral Hazards"' interpretiert werden, die in Kapitel \ref{Info} beschrieben wird. Man könnte diese Unterschiede auch so zusammenfassen: Bei unvollständiger Information wissen die Spieler nicht einmal die Regeln des Spiels. Bei vollständiger, aber imperfekter Information wissen alle Spieler die Regeln und auch die möglichen Strategien des Spiels, können aber während des Spiels die Züge des Gegenspielers nicht beobachten. Bei perfekter Information schließlich sind Regeln und alle Züge des Gegners bekannt. Schach, zum Beispiel, ist ein Spiel mit vollständiger, perfekter Information. Theoretische könnte man jeweils eine "`optimale Strategie"' berechnen. Die Faszination dieses Spiels liegt darin, dass es eine in der Praxis unendlich erscheinende Zahl an Kombination verschiedener Züge gibt. Bei Kartenspielen gibt es in der Regel wesentlich weniger Züge. Die Faszination dieser Spiele liegt dafür darin, dass man seine eigenen Karten und möglichen Züge vor dem Gegenspieler verbergen kann. Hier liegt ein Spiel mit imperfekter Information vor. In diesem Fall ist eine konkrete, optimale Strategie zu berechnen nicht möglich. Sehr wohl kann man aber aus den eigenen Karten berechnen, wie hoch die statistische Gewinn-Wahrscheinlichkeit mit dem Blatt ist. Geübte Pokerspieler benötigen zwar ein Poker-Face um sich nicht zu verraten, ihre wahre Stärke liegt aber darin, genau diese Gewinn-Wahrscheinlichkeiten rasch "`berechnen"' zu können.

\textcite{Harsanyi1967} zeigte nun, in drei aufgeteilten Artikeln, die aber alle im gleichen Journal erschienen sind, dass Spiele mit unvollständiger Information unter der Anwendung bedingter Wahrscheinlichkeiten wie Spiele mit vollständiger, aber imperfekter Information analysiert werden können. Aufgrund der Anwendung bedingter Wahrscheinlichkeiten werden diese Spiele "`Bayes'sche Spiele"' genannt. Der Trick, dass "`Bayes'sche Spiele"' äquivalent zu Spielen mit vollständiger, aber imperfekter Information sind, ist zwar theoretische wichtig, führt aber in der Praxis dazu, dass man nun zwar alle möglichen Strategien kennt, aber dazu auch entsprechende Eintrittswahrscheinlichkeiten hinterlegen muss. Lässt man alle möglichen Lösungen geht die Menge gegen unendlich. Daher wurde in weiterer Folge das Konzept der "`Common Priors"' entwickelt, das sind gemeinsame Annahmen über Eintrittswahrscheinlichkeiten, welche die Spieler aus "`der Natur"' ableiten. Diese "`natürlichen"' Informationen könnten zum Beispiel Marktpreise sein. Kann ein Spieler die Preiskalkulation seines Gegenspielers aus den Marktpreisen abschätzen, so kann er gewisse Preisstrategien des Gegners ausschließen. Welche Annahmen wiederum zu "`Common Priors"' gemacht werden können, wurde zu einem eigenen Forschungsgebiet in der Spieltheorie, dazu kommen wir später im Punkt "`Gleichgewicht in korrelierten Strategien"'.

Reinhard Selten, bis heute der einzige deutsche Ökonomie-Nobelpreisträger, erweiterte die Spieltheorie um interessante, weil recht unkonventionelle, Ansätze. Im Rahmen von Spielen mit "`Imperfekter Information"' lieferte \textcite{Selten1965} das Konzept des "`Teilspielperfekten Gleichgewichts"'. Diese sind eine direkte Verfeinerung von "`Nash-Gleichgewichten"'. In vielen Spielen lassen sich nämlich "`Nash-Gleichgewichte"' finden, deren Realisation in der Praxis recht unwahrscheinlich ist. Das Paradebeispiel ist die Drohung eines Monopolisten, einen Preiskampf zu starten, wenn ein Mitbewerber in den Markt eintritt. Zwar kann die "`Preiskampf-Lösung"' ein formales "`Nash-Gleichgewicht"' sein. Unter der Bedingung, dass der Mitbewerber aber tatsächlich in den Markt eintritt, wäre es irrational für den Monopolisten den Preiskampf tatsächlich zu starten, in diesem Fall wäre es wahrscheinlich, dass der Monopolist von seiner Strategie abweicht und stattdessen z.B. eine Preisabsprache anstrebt. \textcite{Selten1965} definierte in der Folge seine "`Teilspielperfekten Gleichgewichte"' als ausschließlich solche, bei denen ein Spieler in keiner einzigen Spielalternative von seiner Strategie abweichen wird. Mit \textcite{Selten1975} wurde die Idee noch weiter verfeinert und unter dem Namen "`Trembling-Hand-Perfektes Gleichgewicht"', also zitternde Hand, bekannt. Dies ist insofern interessant, als damit vom Konzept des rein rational denkenden Homo Oeconomicus abgewichen wurde. Reinhard Selten widmete sich übrigens in seinen späteren Jahren zunehmend der Verhaltensökonomie (vgl. Kapitel \ref{Behavioral}) insbesondere Experimenten zu eingeschränkter Rationalität ("`Bounded Rationality"') \parencite{Gigerenzer2002}. Das "`Trembling-Hand-Gleichgewicht"' schließt noch mehr Gleichgewichte aus. Der Grundansatz ist, dass man nicht ausschließen kann, dass der Gegenspieler einen "`Fehler"' macht und eine Strategie wählt, die für ihn nicht optimal ist. Der Gegenspieler hat bei der Strategieauswahl also eine "`zitternde Hand"' und wählt falsch - daher der Name. Das könnte dazu führen, dass die vom Spieler selbst gewählte Strategie dazu führt, dass das ursprünglich - also ohne den Fehler des Gegenspielers - vorberechnete Gleichgewicht dennoch erhalten bleibt. Der Fehler könnte aber auch zu einem ganz anderen - für den Spieler schlechteren - Gleichgewichtszustand führen. In diesem Fall wäre das ursprünglich vorberechnete Gleichgewicht nicht "`Trembling-Hand-Perfekt"' sein und dementsprechend als mögliche Lösung ausgeschlossen werden. \textcite{Myerson1978} entwickelte das ganze zu "`Properen Gleichgewichten"' noch weiter.

Das Buch \textcite{Harsanyi1988} schließt in gewisser Weise das spieltheoretische Lebenswerk von John Harsanyi und Reinhard Selten schön ab. Beide haben "`Nash-Gleichgewichte"' in verschiedener Art und Weise verfeinert. Denn wie wir gesehen haben, sind "`Nash-Gleichgewichte"', erstens, keineswegs per se auch realistische Gleichgewichte und liefern, zweitens, häufig keine eindeutige Lösung, weil es eben oft mehrere solche Gleichgewichte gibt. In \textcite{Harsanyi1988} liefern sie eine "`Theorie der Gleichgewichtsauswahl"', in der sie Kriterien formulieren, mit denen für jedes Spiel eine eindeutige Lösung gefunden werden soll. Dies gelingt ihnen laut \textcite[S. 134]{Holler2005} nicht ganz. Die Weiterentwicklungen von Selten und Harsanyi rundeten aber dennoch die fundamentale Arbeit von Nash soweit ab, dass das Gesamtkonzept des "`Nash-Gleichgewichts"' bis heute eines der wichtigsten Instrumente in der Ökonomie ist.

Zuletzt kommen wir in diesem Kapitel noch einmal auf die eigentlich fundamentalste Unterscheidung innerhalb der Spieltheorie zurück: Kooperative versus Nicht-kooperative Spieltheorie. Die Möglichkeit der Spieler miteinander zu kommunizieren und in weiterer Folge Verträge abzuschließen wird in der Kooperativen Spieltheorie analysiert. \textcite{Shapley1953} lieferte schon früh ein Konzept, dass bis heute als "`Shapley-Value"' die Grundlage für Konzepte der kooperativen Spieltheorie darstellt und Zudem ein "`Comeback"' im Rahmen der modernen Machine-Learning-Algorithmen feiert. Dort wird es herangezogen um den Erklärungsbeitrag einzelner Variablen zum Gesamtergebnis erklären zu können. In der Kooperativen Spieltheorie werden durch Absprachen Koalitionen gebildet. Jeder Spieler hat zunächst einen positiven Nutzen aus der Teilnahme an der Koalition. Aber natürlich sind sowohl Nutzen als auch Beitrag zu der Kooperation nicht für jeden Teilnehmer gleich hoch. Die stärksten "`Beitragsleister"' haben meist eine bessere Verhandlungsmacht und werden versuchen den Nutzen aus der Kooperation in ihre Richtung zu verschieben. Der Shapley-Wert liefert eine eindeutige Gleichgewichtslösung zur Verteilung des Nutzens. 

Im Bereich der Kooperativen Spieltheorie war auch Robert Aumann tätig. Er gilt als einer der einflussreichsten Lehrer und vielseitigsten Forscher im Bereich der Spieltheorie. Aumann wurde in Deutschland geboren, seine Familie flüchtete vor den Nazis in die USA, wo er 1955 seinen Doktortitel am MIT erlangte, danach aber zog er in das noch junge Israel und war als Professor in Jerusalem tätig. Sein akademisches Wirken war so fruchtbar, dass laut \textcite[S. 120]{Roth2019} dort Anfang der 1970er das weltweite akademische Zentrum der Spieltheorie lag. Als Forscher prägte er die heute noch gängigen Konzepte des "`Gemeinsamen Wissens"' (Common Knowledge) \parencite{Aumann1976}, sowie in \textcite{Aumann1987} das "`Gleichgewicht in korrelierten Spielen"' etabliert. Einer seiner ersten Beiträge zur Spieltheorie \parencite{Aumann1959} ist im Bereich der Kooperativen Spieltheorie anzusiedeln und begründete die spieltheoretische Analyse von wiederholten Spielen (repeated Games). Diese wiederum wurden später, in den 1980er Jahren, durch eine interessante, wenig technische, Reihe von Untersuchungen einem breiteren Publikum bekannt. \textcite{Axelrod1981, Axelrod1984} wollte darin empirisch die beste Strategie bei wiederholten Gefangenendilemma-Situationen herausfinden. Er veranstalte einen Bewerb zu dem Forscher aus den verschiedensten Bereichen Computer-Programme einreichen konnten. Diese Programme enthielten Algorithmen, die entschieden in welchen Situationen mit dem Gegner kooperiert bzw. defektiert wurde. Im Bewerb schließlich traten alle eingereichten gegeneinander an. Interessanterweise gewann die Einreichung mit dem kürzesten Programmiercode. Dieses war so programmiert, dass es mit Kooperation begann und danach stets die Antwort des Gegner wiederholte. Es wurde eingereicht vom Mathematiker Anatol Rapoport und als "`Tit for Tat"', also in etwa "`Wie du mir, so ich dir"', bezeichnet. Das Programm gewann zwar kein einziges Duell gegen ein konkretes anderes Programm, erreichte aber insgesamt dennoch die höchste Gesamtpunktezahl. \textcite{Axelrod1984} leitete daraus einfache Handlungsregelungen ab, die später in verschiedensten sozialwissenschaftlichen Bereichen zitiert wurden. Anatol Rapoport, der gegen Ende seiner Karriere in den frühen 1980er Jahren auch einige Jahre Leiter des Wiener Instituts für Höhere Studien war, gewann mit seinem unveränderten Programm übrigens auch die zweite Runde des oben beschriebenen Turniers. "`Tit for Tat"' war also selbst dann noch erfolgreich, als dessen Funktionsweise den Gegenspieler bereits bekannt war.

Zurück zur Kooperative Spieltheorie: Diese wurde später immer stärker als Spezialfall der Nicht-kooperativen Spieltheorie gesehen. Letztere schließt ja explizit \textit{nicht} aus, dass Kommunikation oder Kooperation stattfindet. Das heißt aber auch, dass Kooperative Spieltheorie als eine Form der nicht kooperativen Spieltheorie mit einer zusätzlichen "`Ebene"' dargestellt werden kann, auf der die entsprechenden Regeln festgeschrieben werden. \textcite{Nash1953} hatte diesen Zugang schon früh vorgeschlagen, der erst in den letzten Jahrzehnten populär wurde und heute unter dem Namen "`Nash-Programm"' angewendet wird.

Spieltheoretiker erkannten bald, dass es erstrebenswert wäre ein Framework zu schaffen, dass die Ergebnisse der nicht-kooperativen Spieltheorie korrigiert. Schließlich liefert diese häufig Lösungen, die nicht Pareto-effizient sind und damit aus ökonomischer Sicht nicht optimal. In der kooperativen Spieltheorie sind die Lösungen zwar häufig Pareto-effizient, allerdings kommen Kooperationen in der ökonomischen Realität nur unter Nebenbedingungen - also irgendeine Form von verpflichtenden Zusagen -  zustande. Insbesondere wenn "`Marktversagen"' auftritt, kommt es offensichtlich nicht zu optimalen Ergebnissen. In der Folge entstand bald eine neue Linie der Spieltheorie, die sich genau diesem Thema widmet: Wie müssen Regeln formuliert werden, damit die nicht-effizienten Marktlösungen aus der nicht-kooperativen Spieltheorie durch Koalitionen zu effizienten, kooperativen Lösungen werden? Das Forschungsgebiet des "`Mechanismus Design"' war geboren. Da es die Aufgabe von Wirtschaftspolitikern ist, solche Regeln zu designen, ist dieses Gebiet ein sehr praxisrelevantes.


\section{Angewandte Spieltheorie: Mechanismus Design}

Die im letzten Kapitel genanten Autoren haben die Spieltheorie vor allem theoretisch entwickelt. Natürlich nicht, ohne konkrete Anwendungsbeispiele zu verwenden. Doch waren auch diese meist wirkliche "`Spiele"', wie zum Beispiel "`Stein, Schere Papier"', oder konstruiert, wie das "`Gefangenendilemma"'. Zumindest waren diese Ansätze meist noch ohne konkrete wirtschaftswissenschaftliche Anwendung. Den wesentlich stärker anwendungsorientierten Zweig der Spieltheorie begründete bereits Ende der 1950er Jahre Leonid Hurwicz mit seinem "`Mechanism Design"'-Framework \parencite{Arrow1960}. diese Grundlage selbst war natürlich auch noch hochkomplex und theoretisch, allerdings bereits die Grundlage für spätere praktische Anwendung, die einige Jahrzehnte später als "`Market Design"' bekannt werden sollte. Mit Hilfe des Mechanism Designs kann zum Beispiel erklärt werden, warum selbst eine Konsenslösung bei Verhandlungen häufig nicht wirtschaftlich effektiv ist, oder aber warum es rational ist sich als Individuum nicht "`umweltfreundlich"' zu verhalten. Aber eins nach dem anderen. Der Rahmen des "`Mechanism Designs"' umfasst Spiele mit "`unvollständiger Information"'. Darin werden Spielregeln, also ein Mechanismus, festgelegt, nach denen die Teilnehmer Informationen miteinander austauschen. Dieser Ansatz einen Markt zu behandeln, war damals neu. Bis dahin machte man sich keine Gedanken darüber, wie konkret "`Angebot und Nachfrage"' tatsächlich zusammenfinden. Im "`marktwirtschaftlichen System"' wurde dieses "`Zusammenfinden"' als gegeben angenommen \parencite[S. 1]{Hurwicz1973}. Die allgemeinen Gleichgewichtstheorien (vgl. Kapitel \ref{Neoklassik}) initiiert von Walras und finalisiert von Arrow und Debreu, bzw. als Effizienzmarkthypothese von \textcite{Fama1970}, vertrauen alle darauf, dass Angebot und Nachfrage stets im Gleichgewicht zusammentreffen und machen sich keine Gedanken darüber \textit{wie} dieser Prozess stattfindet. Stattdessen wurde dieser "`Black-Box-Prozess"' der natürlichen Gleichgewichtsfindung als einer \textit{der} Vorteile gegenüber der Planwirtschaft gesehen, weil es eben \textit{keinen} zentralen Input-Output-Planer wie im Kommunismus geben muss. Aber auf vielen Märkten herrschen eben auch in einer  Marktwirtschaft keine optimalen Bedingungen, unter anderem im Bezug auf vollständige Information. Durch asymmetrische Informationsverteilung gibt es immer Potential für "`Moral Hazard"'-Probleme. Ein Auftraggeber ("`Principal"') möchte zum Beispiel von möglichen Auftragsnehmern ("`Agents"') Informationen im weitesten Sinne - zum Beispiel faire Preise für ein gewisses Gut - erfahren. Die "`Agents"' haben aber kein Interesse diese Informationen wahrheitsgemäß und kostenlos zur Verfügung zu stellen. Der Auftraggeber muss daher Anreize setzen diese Information zu erhalten. Diese Anreize kosten Geld. Als Nutzenmaximierer muss er also einen optimalen "`Mechanismus"' finden (oder, anders ausgedrückt, "`designen"'), um das bestmögliche Geschäft abzuschließen \parencite[S. 243]{Fudenberg1991}. In den 1970er Jahren wurde das Grundkonzept von Hurwicz weiterentwickelt und gewann schlagartig an Bedeutung. Der endgültige Durchbruch zur praktischen Relevanz folgte gegen Ende der 1970er Jahre. Gleich mehrere Autoren entwickelten nämlich das sogenannte "`Revelation Principle"' (dt.: Offenbarungsprizip). Dieses vereinfacht die hohe Komplexität von Mechanism-Design-Ansätzen zu einem mathematischen Konzept, dass eindeutig definiert und lösbar ist \parencite[S. 3]{Nobelpreis-Komitee2007}. Die erste Version stammt von \textcite{Gibbard1973}, bekannt geworden sind aber vor allem \textcite{Myerson1979} und \textcite{Maskin1979}, wobei letzterer auch noch die "`Implementation Theory"' zur Bestimmung des Optimums bei multiplen Gleichgewichten lieferte. Im Jahr 2007 erhielten Hurwicz, Maskin und Myerson schließlich den Ökonomie-Nobelpreis für ihre Beiträge zum "`Mechanism Design"'.

Einer breiten Öffentlichkeit wurde schließlich indirekt das Konzept des "`Market Design"' bekannt. Man könnte es auch als "`praktische Anwendung"' der Spieltheorie bezeichnen. Tatsächlich wurde "`Mechanism Design"' rasch verwendet um Fragen zu Problemen des Marktversagens zu bearbeiten. So ist meist der Bedarf für "`öffentlichen Güter"', also Gütern, von deren Nutzung man niemanden ausschließen kann, schwierig zu bestimmen. Häufig wird damit auch die Zahlungsbereitschaft von Kunden bei (natürlichen) Monopolen erhoben. Einer breiteren Öffentlichkeit bekannt geworden ist das Konzept aber durch dessen Anwendung bei Auktionen. Bei den in vielen Ländern der Welt durchgeführten, milliardenschweren Versteigerungen der Mobilfunk-Frequenzen, wurden die Konzepte des Mechanism Design angewendet. Konkret eine Weiterentwicklung, genannt "`Auction Theory"', die vor allem Paul Milgrom und Robert Wilson entwickelten und Alvin Roth mit empirischen Arbeiten untermauerte \parencite{Roth2019}. Bereits \textcite{Vickrey1961} machte sich Gedanken über den Gleichgewichtsfindungsprozess an sich und berücksichtigte dabei zwar die Tatsache, dass Information eben nicht "`vollständig"' sind, also für alle Marktteilnehmer verfügbar, sondern stattdessen "`privat"'. Aber er ging davon aus, dass diese Informationen unabhängig voneinander unter den Marktteilnehmern verteilt sind. \textcite{Wilson1967, Wilson1969} schuf einen spieltheoretischen Ansatz, der die Preisfindung als Auktion modellierte und den unterschiedlichen Informationsstand der Bieter als strategisches Element berücksichtigte. Diese Idee, dass die unrealistische Annahme "`vollständiger Information"' in Preisfindungsprozessen zu verzerrten Ergebnissen führt, ist heute als "`Wilson Doktrin"' bekannt \parencite{Roth2019}. \textcite{Wilson1977} bewies, dass sich mit steigender Anzahl von Bietern der erzielte Preis bei Auktionen seinem "`wahren"' Gleichgewichtspreis annähert. \textcite{Milgrom1979, Milgrom1981} und \textcite{Milgrom1982} verallgemeinerten und erweiterten die Erkenntnisse zu einem Framework, das schließlich bei den oben genannten Versteigerungen der Mobilfunk-Frequenzen erfolgreich zur praktischen Anwendung kam. Milgrom selbst war einer der Berater, der bei der Versteigerung der US-Lizenzen involviert war. Statt der üblichen geheimen Angebotsabgabe der Bieter mit anschließender Vergabe der Lizenz an den Höchstbietenden, wurden mehrere Bieterrunden durchgeführt. Nach jeder Runde wurden die Angebotshöhen öffentlich gemacht und anschließend eine neue Runde gestartet. Dies sollte auch den "`Fluch des Gewinners"' (Winner's Curse) verhindern. Schließlich kommt es wohl regelmäßig dazu, dass Unternehmen den "`wahren Preis"' überschätzen, einen zu hohen Preis bezahlen, den Zuschlag bekommen und in der Folge Verluste einfahren, oder sogar Pleite gehen. In diesem Fall würde man wohl kaum von einer erfolgreichen Auktion sprechen, auch wenn der erzielte Preis höher als der Gleichgewichtspreis war. Die Veröffentlichung der Preisangebote soll auch dazu dienen Mitbewerber, die eine zu optimistische Markteinschätzung vorgenommen haben, über ihren Fehler zu informieren. Erstmals wurde dieses Phänomen von \textcite{Capen1971} für die Versteigerung von Erdölfeldern beschrieben.

Der Bereich des "`Mechanismus Design"', bzw. des noch etwas enger definierten "`Market Designs"' ist heute wohl einer der Schlüssel zur Bewältigung der Klimakrise. Leider wird er in der öffentlichen Diskussion bislang weitgehend nicht als solcher wahrgenommen. Die Alternativen sind, dass erstens, die Menschen durch Aufklärung auf "`umweltschädliches"' Verhalten von sich aus verzichten oder zweitens, technologischer Fortschritt die Energieerzeugung von der $CO_2$-Produktion weitgehend entkoppelt. Ersteres ist unrealistisch, für zweiteres scheint uns die Zeit davonzulaufen. Die wohl einzige Lösung ist, dass sich die Politik international dazu durchringen kann "`Spielregeln"' zu erstellen, die es rational machen sich ökologisch zu verhalten. Diese fast schon verniedlicht als Spieltheorie bezeichnete ökonomische Schule könnte sich so als wichtiger Baustein bei der Bekämpfung der Klimakrise entpuppen.