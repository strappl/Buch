%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Sisyphus-Ökonomie}

Die Geschichte scheint sich auch für die Ökonomie immer wieder zu wiederholen. Kaum scheint es so als wären alle Fragen und Herausforderungen der Disziplin wären weitgehend gelöst, sorgt ein Ausnahme-Event für die Zerstörung dieser Illusion. So sprach man bei Marshall vom Vollender der Neoklassischen Ökonomie, bis die "`Great Depression"' Ende der 1920er Jahre deren Unzulänglichkeiten aufzeigte. In den frühen 1970er-Jahren gab es so etwas wie einen Konsens zwischen Keynesianern und Monetaristen. Wieder schien ökonomische Forschung alle relevanten Fragen beantwortet zu haben. Bis in den 1970er Jahren das Phänomen der "`Stagflation"' auftrat und die Lucas-Kritik für einen neuen Paukenschlag sorgte. Und gerade als die "`Neue neoklassische Synthese"' die früheren Konkurrenten der Neuklassik und der Neu-Keynesianer in den DSGE-Modellen vereinte und just nachdem Robert Lucas nach der Jahrtausendwende verkündete, "`alle wesentlichen Probleme der Makroökonomie seien auf Jahrzehnte hinaus gelöst"', erschütterte die "`Great Recession"' die Welt. Zwar muss man der modernen Makroökonomie zugute halten, dass ihre Methoden schlimmeres verhindert hat - sowohl BIP-Einbrüche als auch Arbeitslosenzahlen fielen wesentlich geringer aus als in der "`Great Depression"' - allerdings war das resultierende historisch einmalige Niedrigzinsniveau der Folgejahre mit keiner der modernen makroökonomischen Theorien erklärbar.


1:1 aus Blanchard

Anfang des neuen Jahrtausends aber schien sich eine Synthese herauszubilden.
Methodisch baute sie auf dem Ansatz der Real-Business-Cycle-Theorie auf mit ihrer
exakten Beschreibung des Optimierungsverhaltens von Haushalten und Unterneh-
men. Sie berücksichtigte die Bedeutung von Änderungen in der Rate des technischen
Fortschritts, die sowohl von der „RBC-Theorie“ wie von der Neuen Wachstumstheorie
betont wird. Aber sie integrierte auch wesentliche Elemente des neu-keynesianischen
Ansatzes – sie integrierte viele Friktionen wie Suchprozesse am Arbeitsmarkt, unvollständige
Information auf Kreditmärkten und die Rolle nominaler Rigiditäten für die
aggregierte Nachfrage. Es gab zwar keine Konvergenz zu einem einzigen einheitlichen
Modell oder einer einheitlichen Liste relevanter Friktionen, aber es herrschte Übereinstimmung
über den Forschungsrahmen und die analytische Vorgehensweise.
Ein gutes Beispiel dafür ist die Forschung von Michael Woodford (Columbia Universität
New York) und Jordi Gali (Pompeu Fabra in Barcelona). Sie entwickelten gemeinsam
mit Koautoren das Neue Keynesianische Modell, das Nutzen- und Gewinnmaximierung
mit nominalen Rigiditäten kombiniert – der Kern dieses Modells wurde in
einfacher Form in Kapitel 17 vorgestellt. Dieser Modellansatz hat sich als höchst einflussreich
bei der Neugestaltung der Geldpolitik erwiesen – angefangen von Inflationssteuerung
bis zu Zinsregeln, die in Kapitel 25 behandelt wurden. Der Ansatz bildet die
Basis einer neuen Klasse großer Modelle, die auf der einfachen Struktur aufbauen, aber
eine große Zahl von weiteren Friktionen einbauen. Sie lassen sich nur mehr numerisch
lösen. Diese Modelle, DSGE-Modelle (dynamic general equilibrium analysis) genannt,
sind mittlerweile zum Standardinstrument der Zentralbanken geworden.


\section{Die Great Recession}

Doug
Diamond (Universität Chicago) und Philip Dybvig (Universität Washington) erforschten
schon in den 1980er-Jahren die Mechanismen von Bank Runs (vgl. Kapitel 4): Weil
Aktiva illiquide, Passiva aber liquide sind, unterliegen selbst solvente Banken dem
Risiko eines Runs. Dieses Problem kann nur vermieden werden, wenn die Zentralbank
in einem solchen Fall Liquidität bereitstellt. Bengt Holmström (MIT) und Jean Tirole
Toulouse) zeigten, dass Fragen der Liquidität in modernen Volkswirtschaften zentrale
Bedeutung zukommt. Nicht nur Banken, selbst Unternehmen können durchaus in die
Lage geraten, zwar solvent, aber trotzdem illiquide zu sein – also nicht in der Lage, sich
zusätzliche Mittel zu beschaffen, um an sich rentable Projekte fertigzustellen. Andrej
Shleifer (Harvard Universität) und Robert Vishny (Universität Chicago) wiesen in ihrer
Arbeit über die Grenzen der Arbitrage nach, dass als Folge asymmetrischer Information
Investoren Arbitragemöglichkeiten nicht ausnutzen können, wenn der Vermögenswert
unter den Fundamentalwert sinkt. Im Gegenteil, sie können sogar genötigt werden, auch
selbst solche Vermögenswerte zu verkaufen und so zu einem Preisverfall beizutragen.
Die Forschungsrichtung der Verhaltensökonomie (etwa von Richard Thaler, Chicago
Universität) hat aufgezeigt, in welcher Weise Individuen vom Modell des rationalen
Agenten abweichen und welche Implikationen sich daraus für Finanzmärkte ergeben.





\section{After Great Recession}

\subsection{Grenzen der Geldpolitik}
Geldpolitik im Angesicht der "`Zero Lower Bound on the Nominal Interest Rate"'. Romer-Buch S. 615.
Krugman 1998




\subsection{Wiederauferstehung der Fiskalpolitik oder Austerität?}



Wirtschaftspolitisch Dominanz der Geldpolitik
Inhaltlich spielt in der Wirtschaftspolitik fast ausschließlich nur mehr die Geldpolitik eine Rolle. Zur Fiskalpolitik haben die Vertreter der "`neuen Neoklassischen Synthese"' praktisch ausschließlich eine ablehnende Haltung.
Fiskalpolitik selbst in Krisen umstritten (Paper zur empirischen Bestimmung der Wirksamkeit der Fiskalpolitik (Diskussion in der Europäischen Währungskrise zum Multiplikator (Blanchard änderte die Meinung))

\textcite[S. 130]{Christiano2018}



Buch "`What have we learned"'
Fiskalpolitik \textcite[S. 131]{Christiano2018}


Seite 409 (Snowdon/Vane)
\parencite{Woodford2011}
JEEA 2007 von Gali, Lopez-Salido und Valles 

Könnte neuen Schwung durch \textcite{Kaplan2018} erhalten



















